{
  "best_global_step": 56592,
  "best_metric": 0.8733424782807498,
  "best_model_checkpoint": "./results_bigvul_codebert\\checkpoint-56592",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 56592,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002650551314673452,
      "grad_norm": 14.974502563476562,
      "learning_rate": 1.9982683064744133e-05,
      "loss": 0.7162,
      "step": 50
    },
    {
      "epoch": 0.005301102629346904,
      "grad_norm": 20.080299377441406,
      "learning_rate": 1.9965012722646314e-05,
      "loss": 0.9218,
      "step": 100
    },
    {
      "epoch": 0.007951653944020356,
      "grad_norm": 20.733192443847656,
      "learning_rate": 1.9947342380548487e-05,
      "loss": 1.1968,
      "step": 150
    },
    {
      "epoch": 0.010602205258693808,
      "grad_norm": 0.3235536813735962,
      "learning_rate": 1.9929672038450668e-05,
      "loss": 0.936,
      "step": 200
    },
    {
      "epoch": 0.013252756573367261,
      "grad_norm": 0.32387199997901917,
      "learning_rate": 1.991200169635284e-05,
      "loss": 0.7566,
      "step": 250
    },
    {
      "epoch": 0.015903307888040712,
      "grad_norm": 0.2855727970600128,
      "learning_rate": 1.989433135425502e-05,
      "loss": 1.0749,
      "step": 300
    },
    {
      "epoch": 0.018553859202714164,
      "grad_norm": 0.5843639373779297,
      "learning_rate": 1.9876661012157195e-05,
      "loss": 1.1768,
      "step": 350
    },
    {
      "epoch": 0.021204410517387615,
      "grad_norm": 0.24441224336624146,
      "learning_rate": 1.9858990670059376e-05,
      "loss": 1.016,
      "step": 400
    },
    {
      "epoch": 0.02385496183206107,
      "grad_norm": 21.264446258544922,
      "learning_rate": 1.984132032796155e-05,
      "loss": 1.3145,
      "step": 450
    },
    {
      "epoch": 0.026505513146734522,
      "grad_norm": 19.445785522460938,
      "learning_rate": 1.982364998586373e-05,
      "loss": 0.9028,
      "step": 500
    },
    {
      "epoch": 0.029156064461407973,
      "grad_norm": 20.203815460205078,
      "learning_rate": 1.9805979643765903e-05,
      "loss": 1.0537,
      "step": 550
    },
    {
      "epoch": 0.031806615776081425,
      "grad_norm": 0.13273221254348755,
      "learning_rate": 1.9788309301668083e-05,
      "loss": 0.6877,
      "step": 600
    },
    {
      "epoch": 0.03445716709075488,
      "grad_norm": 1.2460756301879883,
      "learning_rate": 1.9770638959570257e-05,
      "loss": 1.0196,
      "step": 650
    },
    {
      "epoch": 0.03710771840542833,
      "grad_norm": 0.8007256984710693,
      "learning_rate": 1.9752968617472437e-05,
      "loss": 0.8598,
      "step": 700
    },
    {
      "epoch": 0.03975826972010178,
      "grad_norm": 0.056271858513355255,
      "learning_rate": 1.973529827537461e-05,
      "loss": 0.4855,
      "step": 750
    },
    {
      "epoch": 0.04240882103477523,
      "grad_norm": 0.90376877784729,
      "learning_rate": 1.971762793327679e-05,
      "loss": 1.0066,
      "step": 800
    },
    {
      "epoch": 0.045059372349448686,
      "grad_norm": 33.249267578125,
      "learning_rate": 1.9699957591178965e-05,
      "loss": 0.6346,
      "step": 850
    },
    {
      "epoch": 0.04770992366412214,
      "grad_norm": 0.06274548172950745,
      "learning_rate": 1.9682287249081145e-05,
      "loss": 0.4374,
      "step": 900
    },
    {
      "epoch": 0.05036047497879559,
      "grad_norm": 20.144357681274414,
      "learning_rate": 1.966461690698332e-05,
      "loss": 0.7261,
      "step": 950
    },
    {
      "epoch": 0.053011026293469043,
      "grad_norm": 0.04393935203552246,
      "learning_rate": 1.96469465648855e-05,
      "loss": 0.4415,
      "step": 1000
    },
    {
      "epoch": 0.05566157760814249,
      "grad_norm": 0.07504791021347046,
      "learning_rate": 1.9629276222787673e-05,
      "loss": 0.7057,
      "step": 1050
    },
    {
      "epoch": 0.058312128922815946,
      "grad_norm": 38.69824981689453,
      "learning_rate": 1.9611605880689853e-05,
      "loss": 0.4794,
      "step": 1100
    },
    {
      "epoch": 0.060962680237489394,
      "grad_norm": 0.23145222663879395,
      "learning_rate": 1.9593935538592027e-05,
      "loss": 0.5038,
      "step": 1150
    },
    {
      "epoch": 0.06361323155216285,
      "grad_norm": 0.22742067277431488,
      "learning_rate": 1.9576265196494207e-05,
      "loss": 0.912,
      "step": 1200
    },
    {
      "epoch": 0.0662637828668363,
      "grad_norm": 0.13113752007484436,
      "learning_rate": 1.955859485439638e-05,
      "loss": 0.8501,
      "step": 1250
    },
    {
      "epoch": 0.06891433418150976,
      "grad_norm": 21.913070678710938,
      "learning_rate": 1.954092451229856e-05,
      "loss": 0.4955,
      "step": 1300
    },
    {
      "epoch": 0.0715648854961832,
      "grad_norm": 0.07345233857631683,
      "learning_rate": 1.9523254170200734e-05,
      "loss": 0.6859,
      "step": 1350
    },
    {
      "epoch": 0.07421543681085666,
      "grad_norm": 13.169872283935547,
      "learning_rate": 1.9505583828102915e-05,
      "loss": 0.7896,
      "step": 1400
    },
    {
      "epoch": 0.07686598812553011,
      "grad_norm": 24.125713348388672,
      "learning_rate": 1.948791348600509e-05,
      "loss": 0.8404,
      "step": 1450
    },
    {
      "epoch": 0.07951653944020357,
      "grad_norm": 0.0707593634724617,
      "learning_rate": 1.947024314390727e-05,
      "loss": 0.545,
      "step": 1500
    },
    {
      "epoch": 0.08216709075487702,
      "grad_norm": 0.09379474073648453,
      "learning_rate": 1.9452572801809442e-05,
      "loss": 0.5479,
      "step": 1550
    },
    {
      "epoch": 0.08481764206955046,
      "grad_norm": 0.1251213401556015,
      "learning_rate": 1.9434902459711623e-05,
      "loss": 0.6266,
      "step": 1600
    },
    {
      "epoch": 0.08746819338422392,
      "grad_norm": 4.007030963897705,
      "learning_rate": 1.9417232117613796e-05,
      "loss": 0.5473,
      "step": 1650
    },
    {
      "epoch": 0.09011874469889737,
      "grad_norm": 0.4611836075782776,
      "learning_rate": 1.9399561775515977e-05,
      "loss": 0.5811,
      "step": 1700
    },
    {
      "epoch": 0.09276929601357083,
      "grad_norm": 0.22164388000965118,
      "learning_rate": 1.938189143341815e-05,
      "loss": 0.6888,
      "step": 1750
    },
    {
      "epoch": 0.09541984732824428,
      "grad_norm": 0.3506993353366852,
      "learning_rate": 1.936422109132033e-05,
      "loss": 0.616,
      "step": 1800
    },
    {
      "epoch": 0.09807039864291772,
      "grad_norm": 0.2950572371482849,
      "learning_rate": 1.9346550749222507e-05,
      "loss": 0.5671,
      "step": 1850
    },
    {
      "epoch": 0.10072094995759118,
      "grad_norm": 0.06038421392440796,
      "learning_rate": 1.9328880407124684e-05,
      "loss": 0.5264,
      "step": 1900
    },
    {
      "epoch": 0.10337150127226463,
      "grad_norm": 0.17382243275642395,
      "learning_rate": 1.931121006502686e-05,
      "loss": 0.5077,
      "step": 1950
    },
    {
      "epoch": 0.10602205258693809,
      "grad_norm": 0.13614359498023987,
      "learning_rate": 1.929353972292904e-05,
      "loss": 0.5458,
      "step": 2000
    },
    {
      "epoch": 0.10867260390161154,
      "grad_norm": 0.11444398760795593,
      "learning_rate": 1.9275869380831215e-05,
      "loss": 0.7032,
      "step": 2050
    },
    {
      "epoch": 0.11132315521628498,
      "grad_norm": 0.09607723355293274,
      "learning_rate": 1.9258199038733392e-05,
      "loss": 0.5437,
      "step": 2100
    },
    {
      "epoch": 0.11397370653095844,
      "grad_norm": 0.09413900971412659,
      "learning_rate": 1.924052869663557e-05,
      "loss": 0.5093,
      "step": 2150
    },
    {
      "epoch": 0.11662425784563189,
      "grad_norm": 0.1395530253648758,
      "learning_rate": 1.9222858354537746e-05,
      "loss": 0.5308,
      "step": 2200
    },
    {
      "epoch": 0.11927480916030535,
      "grad_norm": 0.0633937269449234,
      "learning_rate": 1.9205188012439923e-05,
      "loss": 0.524,
      "step": 2250
    },
    {
      "epoch": 0.12192536047497879,
      "grad_norm": 0.11853579431772232,
      "learning_rate": 1.91875176703421e-05,
      "loss": 0.6696,
      "step": 2300
    },
    {
      "epoch": 0.12457591178965224,
      "grad_norm": 0.07170556485652924,
      "learning_rate": 1.9169847328244277e-05,
      "loss": 0.6992,
      "step": 2350
    },
    {
      "epoch": 0.1272264631043257,
      "grad_norm": 0.03644486144185066,
      "learning_rate": 1.9152176986146454e-05,
      "loss": 0.4021,
      "step": 2400
    },
    {
      "epoch": 0.12987701441899915,
      "grad_norm": 0.07061529904603958,
      "learning_rate": 1.913450664404863e-05,
      "loss": 0.5441,
      "step": 2450
    },
    {
      "epoch": 0.1325275657336726,
      "grad_norm": 0.15341447293758392,
      "learning_rate": 1.9116836301950808e-05,
      "loss": 0.3544,
      "step": 2500
    },
    {
      "epoch": 0.13517811704834606,
      "grad_norm": 1.8548836708068848,
      "learning_rate": 1.9099165959852985e-05,
      "loss": 0.6729,
      "step": 2550
    },
    {
      "epoch": 0.13782866836301952,
      "grad_norm": 0.10714949667453766,
      "learning_rate": 1.9081495617755162e-05,
      "loss": 0.4544,
      "step": 2600
    },
    {
      "epoch": 0.14047921967769297,
      "grad_norm": 0.14608225226402283,
      "learning_rate": 1.906382527565734e-05,
      "loss": 0.4894,
      "step": 2650
    },
    {
      "epoch": 0.1431297709923664,
      "grad_norm": 0.25800853967666626,
      "learning_rate": 1.9046154933559516e-05,
      "loss": 0.6169,
      "step": 2700
    },
    {
      "epoch": 0.14578032230703986,
      "grad_norm": 29.306673049926758,
      "learning_rate": 1.9028484591461693e-05,
      "loss": 0.6437,
      "step": 2750
    },
    {
      "epoch": 0.1484308736217133,
      "grad_norm": 3.223219633102417,
      "learning_rate": 1.901081424936387e-05,
      "loss": 0.8538,
      "step": 2800
    },
    {
      "epoch": 0.15108142493638677,
      "grad_norm": 0.09792998433113098,
      "learning_rate": 1.8993143907266047e-05,
      "loss": 0.4912,
      "step": 2850
    },
    {
      "epoch": 0.15373197625106022,
      "grad_norm": 0.14405259490013123,
      "learning_rate": 1.8975473565168224e-05,
      "loss": 0.5613,
      "step": 2900
    },
    {
      "epoch": 0.15638252756573368,
      "grad_norm": 21.40311050415039,
      "learning_rate": 1.89578032230704e-05,
      "loss": 0.6315,
      "step": 2950
    },
    {
      "epoch": 0.15903307888040713,
      "grad_norm": 0.0989687442779541,
      "learning_rate": 1.8940132880972578e-05,
      "loss": 0.3316,
      "step": 3000
    },
    {
      "epoch": 0.16168363019508059,
      "grad_norm": 4.1882734298706055,
      "learning_rate": 1.8922462538874755e-05,
      "loss": 0.57,
      "step": 3050
    },
    {
      "epoch": 0.16433418150975404,
      "grad_norm": 0.028042467311024666,
      "learning_rate": 1.890479219677693e-05,
      "loss": 0.5856,
      "step": 3100
    },
    {
      "epoch": 0.16698473282442747,
      "grad_norm": 0.08892840892076492,
      "learning_rate": 1.888712185467911e-05,
      "loss": 0.6929,
      "step": 3150
    },
    {
      "epoch": 0.16963528413910092,
      "grad_norm": 25.60531997680664,
      "learning_rate": 1.8869451512581285e-05,
      "loss": 0.7937,
      "step": 3200
    },
    {
      "epoch": 0.17228583545377438,
      "grad_norm": 5.772478103637695,
      "learning_rate": 1.8851781170483462e-05,
      "loss": 0.4814,
      "step": 3250
    },
    {
      "epoch": 0.17493638676844783,
      "grad_norm": 0.06631959974765778,
      "learning_rate": 1.883411082838564e-05,
      "loss": 0.6189,
      "step": 3300
    },
    {
      "epoch": 0.1775869380831213,
      "grad_norm": 0.08383335173130035,
      "learning_rate": 1.8816440486287816e-05,
      "loss": 0.6527,
      "step": 3350
    },
    {
      "epoch": 0.18023748939779474,
      "grad_norm": 0.07020489126443863,
      "learning_rate": 1.8798770144189993e-05,
      "loss": 0.3009,
      "step": 3400
    },
    {
      "epoch": 0.1828880407124682,
      "grad_norm": 0.14251358807086945,
      "learning_rate": 1.878109980209217e-05,
      "loss": 0.6482,
      "step": 3450
    },
    {
      "epoch": 0.18553859202714165,
      "grad_norm": 0.10224201530218124,
      "learning_rate": 1.8763429459994347e-05,
      "loss": 0.381,
      "step": 3500
    },
    {
      "epoch": 0.1881891433418151,
      "grad_norm": 0.22031712532043457,
      "learning_rate": 1.8745759117896524e-05,
      "loss": 0.3674,
      "step": 3550
    },
    {
      "epoch": 0.19083969465648856,
      "grad_norm": 0.022633474320173264,
      "learning_rate": 1.87280887757987e-05,
      "loss": 0.429,
      "step": 3600
    },
    {
      "epoch": 0.193490245971162,
      "grad_norm": 28.803457260131836,
      "learning_rate": 1.8710418433700878e-05,
      "loss": 0.7306,
      "step": 3650
    },
    {
      "epoch": 0.19614079728583544,
      "grad_norm": 0.15774653851985931,
      "learning_rate": 1.8692748091603055e-05,
      "loss": 0.3909,
      "step": 3700
    },
    {
      "epoch": 0.1987913486005089,
      "grad_norm": 0.36033138632774353,
      "learning_rate": 1.8675077749505232e-05,
      "loss": 0.3458,
      "step": 3750
    },
    {
      "epoch": 0.20144189991518235,
      "grad_norm": 0.028119314461946487,
      "learning_rate": 1.865740740740741e-05,
      "loss": 0.3375,
      "step": 3800
    },
    {
      "epoch": 0.2040924512298558,
      "grad_norm": 0.04442092031240463,
      "learning_rate": 1.8639737065309586e-05,
      "loss": 0.2776,
      "step": 3850
    },
    {
      "epoch": 0.20674300254452926,
      "grad_norm": 0.27127668261528015,
      "learning_rate": 1.8622066723211763e-05,
      "loss": 0.6041,
      "step": 3900
    },
    {
      "epoch": 0.20939355385920272,
      "grad_norm": 24.370838165283203,
      "learning_rate": 1.860439638111394e-05,
      "loss": 0.641,
      "step": 3950
    },
    {
      "epoch": 0.21204410517387617,
      "grad_norm": 0.24050317704677582,
      "learning_rate": 1.8586726039016117e-05,
      "loss": 0.6265,
      "step": 4000
    },
    {
      "epoch": 0.21469465648854963,
      "grad_norm": 0.11859100311994553,
      "learning_rate": 1.8569055696918294e-05,
      "loss": 0.6128,
      "step": 4050
    },
    {
      "epoch": 0.21734520780322308,
      "grad_norm": 106.4012451171875,
      "learning_rate": 1.855138535482047e-05,
      "loss": 0.5677,
      "step": 4100
    },
    {
      "epoch": 0.2199957591178965,
      "grad_norm": 0.07642590254545212,
      "learning_rate": 1.8533715012722648e-05,
      "loss": 0.5145,
      "step": 4150
    },
    {
      "epoch": 0.22264631043256997,
      "grad_norm": 20.364337921142578,
      "learning_rate": 1.8516044670624825e-05,
      "loss": 0.8638,
      "step": 4200
    },
    {
      "epoch": 0.22529686174724342,
      "grad_norm": 0.3268960118293762,
      "learning_rate": 1.8498374328527002e-05,
      "loss": 0.5739,
      "step": 4250
    },
    {
      "epoch": 0.22794741306191688,
      "grad_norm": 17.786806106567383,
      "learning_rate": 1.848070398642918e-05,
      "loss": 0.3674,
      "step": 4300
    },
    {
      "epoch": 0.23059796437659033,
      "grad_norm": 0.06658079475164413,
      "learning_rate": 1.8463033644331356e-05,
      "loss": 0.3855,
      "step": 4350
    },
    {
      "epoch": 0.23324851569126379,
      "grad_norm": 0.051299817860126495,
      "learning_rate": 1.8445363302233533e-05,
      "loss": 0.3452,
      "step": 4400
    },
    {
      "epoch": 0.23589906700593724,
      "grad_norm": 0.1013621985912323,
      "learning_rate": 1.842769296013571e-05,
      "loss": 0.2882,
      "step": 4450
    },
    {
      "epoch": 0.2385496183206107,
      "grad_norm": 0.11970023810863495,
      "learning_rate": 1.8410022618037887e-05,
      "loss": 0.7196,
      "step": 4500
    },
    {
      "epoch": 0.24120016963528415,
      "grad_norm": 0.16071367263793945,
      "learning_rate": 1.8392352275940063e-05,
      "loss": 0.4884,
      "step": 4550
    },
    {
      "epoch": 0.24385072094995758,
      "grad_norm": 21.400243759155273,
      "learning_rate": 1.837468193384224e-05,
      "loss": 0.3032,
      "step": 4600
    },
    {
      "epoch": 0.24650127226463103,
      "grad_norm": 0.1611553132534027,
      "learning_rate": 1.8357011591744417e-05,
      "loss": 0.5403,
      "step": 4650
    },
    {
      "epoch": 0.2491518235793045,
      "grad_norm": 0.3972422778606415,
      "learning_rate": 1.8339341249646594e-05,
      "loss": 0.4139,
      "step": 4700
    },
    {
      "epoch": 0.25180237489397794,
      "grad_norm": 0.03683130815625191,
      "learning_rate": 1.832167090754877e-05,
      "loss": 0.241,
      "step": 4750
    },
    {
      "epoch": 0.2544529262086514,
      "grad_norm": 0.20334240794181824,
      "learning_rate": 1.830400056545095e-05,
      "loss": 0.369,
      "step": 4800
    },
    {
      "epoch": 0.25710347752332485,
      "grad_norm": 0.08984055370092392,
      "learning_rate": 1.8286330223353125e-05,
      "loss": 0.453,
      "step": 4850
    },
    {
      "epoch": 0.2597540288379983,
      "grad_norm": 0.2735224962234497,
      "learning_rate": 1.8268659881255302e-05,
      "loss": 0.5741,
      "step": 4900
    },
    {
      "epoch": 0.26240458015267176,
      "grad_norm": 298.172607421875,
      "learning_rate": 1.825098953915748e-05,
      "loss": 0.7277,
      "step": 4950
    },
    {
      "epoch": 0.2650551314673452,
      "grad_norm": 40.19725036621094,
      "learning_rate": 1.8233319197059656e-05,
      "loss": 0.3049,
      "step": 5000
    },
    {
      "epoch": 0.2677056827820187,
      "grad_norm": 35.89594650268555,
      "learning_rate": 1.8215648854961833e-05,
      "loss": 0.6862,
      "step": 5050
    },
    {
      "epoch": 0.2703562340966921,
      "grad_norm": 0.09811850637197495,
      "learning_rate": 1.819797851286401e-05,
      "loss": 0.323,
      "step": 5100
    },
    {
      "epoch": 0.2730067854113656,
      "grad_norm": 0.4389669597148895,
      "learning_rate": 1.8180308170766187e-05,
      "loss": 0.433,
      "step": 5150
    },
    {
      "epoch": 0.27565733672603904,
      "grad_norm": 0.11621709167957306,
      "learning_rate": 1.8162637828668364e-05,
      "loss": 0.3182,
      "step": 5200
    },
    {
      "epoch": 0.2783078880407125,
      "grad_norm": 0.1143670305609703,
      "learning_rate": 1.814496748657054e-05,
      "loss": 0.6015,
      "step": 5250
    },
    {
      "epoch": 0.28095843935538595,
      "grad_norm": 0.04946861416101456,
      "learning_rate": 1.8127297144472718e-05,
      "loss": 0.4185,
      "step": 5300
    },
    {
      "epoch": 0.28360899067005935,
      "grad_norm": 0.1172412559390068,
      "learning_rate": 1.8109626802374895e-05,
      "loss": 0.5632,
      "step": 5350
    },
    {
      "epoch": 0.2862595419847328,
      "grad_norm": 0.10720709711313248,
      "learning_rate": 1.8091956460277072e-05,
      "loss": 0.3567,
      "step": 5400
    },
    {
      "epoch": 0.28891009329940626,
      "grad_norm": 0.18756061792373657,
      "learning_rate": 1.807428611817925e-05,
      "loss": 0.5699,
      "step": 5450
    },
    {
      "epoch": 0.2915606446140797,
      "grad_norm": 25.0347957611084,
      "learning_rate": 1.8056615776081426e-05,
      "loss": 0.6061,
      "step": 5500
    },
    {
      "epoch": 0.29421119592875317,
      "grad_norm": 0.39942267537117004,
      "learning_rate": 1.8038945433983603e-05,
      "loss": 0.6118,
      "step": 5550
    },
    {
      "epoch": 0.2968617472434266,
      "grad_norm": 12.706851959228516,
      "learning_rate": 1.802127509188578e-05,
      "loss": 0.3717,
      "step": 5600
    },
    {
      "epoch": 0.2995122985581001,
      "grad_norm": 0.2179727554321289,
      "learning_rate": 1.8003604749787957e-05,
      "loss": 0.5843,
      "step": 5650
    },
    {
      "epoch": 0.30216284987277353,
      "grad_norm": 20.491025924682617,
      "learning_rate": 1.7985934407690137e-05,
      "loss": 0.6586,
      "step": 5700
    },
    {
      "epoch": 0.304813401187447,
      "grad_norm": 53.79124450683594,
      "learning_rate": 1.796826406559231e-05,
      "loss": 0.4798,
      "step": 5750
    },
    {
      "epoch": 0.30746395250212044,
      "grad_norm": 0.10003940761089325,
      "learning_rate": 1.795059372349449e-05,
      "loss": 0.2584,
      "step": 5800
    },
    {
      "epoch": 0.3101145038167939,
      "grad_norm": 23.994640350341797,
      "learning_rate": 1.7932923381396665e-05,
      "loss": 0.5313,
      "step": 5850
    },
    {
      "epoch": 0.31276505513146735,
      "grad_norm": 0.06532292068004608,
      "learning_rate": 1.7915253039298845e-05,
      "loss": 0.4251,
      "step": 5900
    },
    {
      "epoch": 0.3154156064461408,
      "grad_norm": 10.979084014892578,
      "learning_rate": 1.789758269720102e-05,
      "loss": 0.6676,
      "step": 5950
    },
    {
      "epoch": 0.31806615776081426,
      "grad_norm": 0.1070590689778328,
      "learning_rate": 1.78799123551032e-05,
      "loss": 0.3378,
      "step": 6000
    },
    {
      "epoch": 0.3207167090754877,
      "grad_norm": 0.036189254373311996,
      "learning_rate": 1.7862242013005372e-05,
      "loss": 0.4719,
      "step": 6050
    },
    {
      "epoch": 0.32336726039016117,
      "grad_norm": 0.26292410492897034,
      "learning_rate": 1.7844571670907553e-05,
      "loss": 0.4984,
      "step": 6100
    },
    {
      "epoch": 0.3260178117048346,
      "grad_norm": 0.03718981519341469,
      "learning_rate": 1.7826901328809726e-05,
      "loss": 0.2541,
      "step": 6150
    },
    {
      "epoch": 0.3286683630195081,
      "grad_norm": 0.14927025139331818,
      "learning_rate": 1.7809230986711907e-05,
      "loss": 0.5345,
      "step": 6200
    },
    {
      "epoch": 0.33131891433418154,
      "grad_norm": 0.07890313118696213,
      "learning_rate": 1.779156064461408e-05,
      "loss": 0.4764,
      "step": 6250
    },
    {
      "epoch": 0.33396946564885494,
      "grad_norm": 0.25493356585502625,
      "learning_rate": 1.777389030251626e-05,
      "loss": 0.3671,
      "step": 6300
    },
    {
      "epoch": 0.3366200169635284,
      "grad_norm": 0.05624896660447121,
      "learning_rate": 1.7756219960418434e-05,
      "loss": 0.3718,
      "step": 6350
    },
    {
      "epoch": 0.33927056827820185,
      "grad_norm": 159.79888916015625,
      "learning_rate": 1.7738549618320615e-05,
      "loss": 0.4178,
      "step": 6400
    },
    {
      "epoch": 0.3419211195928753,
      "grad_norm": 0.10695523768663406,
      "learning_rate": 1.7720879276222788e-05,
      "loss": 0.379,
      "step": 6450
    },
    {
      "epoch": 0.34457167090754875,
      "grad_norm": 0.016992732882499695,
      "learning_rate": 1.770320893412497e-05,
      "loss": 0.3438,
      "step": 6500
    },
    {
      "epoch": 0.3472222222222222,
      "grad_norm": 22.17030143737793,
      "learning_rate": 1.7685538592027142e-05,
      "loss": 0.4642,
      "step": 6550
    },
    {
      "epoch": 0.34987277353689566,
      "grad_norm": 20.08949089050293,
      "learning_rate": 1.7667868249929322e-05,
      "loss": 0.325,
      "step": 6600
    },
    {
      "epoch": 0.3525233248515691,
      "grad_norm": 25.738826751708984,
      "learning_rate": 1.7650197907831496e-05,
      "loss": 0.4998,
      "step": 6650
    },
    {
      "epoch": 0.3551738761662426,
      "grad_norm": 0.08207166939973831,
      "learning_rate": 1.7632527565733676e-05,
      "loss": 0.2724,
      "step": 6700
    },
    {
      "epoch": 0.35782442748091603,
      "grad_norm": 23.364408493041992,
      "learning_rate": 1.761485722363585e-05,
      "loss": 0.3743,
      "step": 6750
    },
    {
      "epoch": 0.3604749787955895,
      "grad_norm": 0.02815944515168667,
      "learning_rate": 1.759718688153803e-05,
      "loss": 0.2835,
      "step": 6800
    },
    {
      "epoch": 0.36312553011026294,
      "grad_norm": 0.10000527650117874,
      "learning_rate": 1.7579516539440204e-05,
      "loss": 0.5727,
      "step": 6850
    },
    {
      "epoch": 0.3657760814249364,
      "grad_norm": 0.04272594302892685,
      "learning_rate": 1.7561846197342384e-05,
      "loss": 0.4536,
      "step": 6900
    },
    {
      "epoch": 0.36842663273960985,
      "grad_norm": 3.319481372833252,
      "learning_rate": 1.7544175855244558e-05,
      "loss": 0.782,
      "step": 6950
    },
    {
      "epoch": 0.3710771840542833,
      "grad_norm": 0.07699166238307953,
      "learning_rate": 1.7526505513146738e-05,
      "loss": 0.6049,
      "step": 7000
    },
    {
      "epoch": 0.37372773536895676,
      "grad_norm": 12.656485557556152,
      "learning_rate": 1.750883517104891e-05,
      "loss": 0.4793,
      "step": 7050
    },
    {
      "epoch": 0.3763782866836302,
      "grad_norm": 0.08706163614988327,
      "learning_rate": 1.7491164828951092e-05,
      "loss": 0.4402,
      "step": 7100
    },
    {
      "epoch": 0.37902883799830367,
      "grad_norm": 0.10588246583938599,
      "learning_rate": 1.7473494486853266e-05,
      "loss": 0.4898,
      "step": 7150
    },
    {
      "epoch": 0.3816793893129771,
      "grad_norm": 0.12025608122348785,
      "learning_rate": 1.7455824144755446e-05,
      "loss": 0.4541,
      "step": 7200
    },
    {
      "epoch": 0.3843299406276505,
      "grad_norm": 0.04645923525094986,
      "learning_rate": 1.743815380265762e-05,
      "loss": 0.3399,
      "step": 7250
    },
    {
      "epoch": 0.386980491942324,
      "grad_norm": 0.02505912445485592,
      "learning_rate": 1.74204834605598e-05,
      "loss": 0.2218,
      "step": 7300
    },
    {
      "epoch": 0.38963104325699743,
      "grad_norm": 0.8689190745353699,
      "learning_rate": 1.7402813118461973e-05,
      "loss": 0.5751,
      "step": 7350
    },
    {
      "epoch": 0.3922815945716709,
      "grad_norm": 0.09058253467082977,
      "learning_rate": 1.7385142776364154e-05,
      "loss": 0.6021,
      "step": 7400
    },
    {
      "epoch": 0.39493214588634434,
      "grad_norm": 0.6634911298751831,
      "learning_rate": 1.7367472434266327e-05,
      "loss": 0.4011,
      "step": 7450
    },
    {
      "epoch": 0.3975826972010178,
      "grad_norm": 0.039885785430669785,
      "learning_rate": 1.7349802092168508e-05,
      "loss": 0.6169,
      "step": 7500
    },
    {
      "epoch": 0.40023324851569125,
      "grad_norm": 0.0341402031481266,
      "learning_rate": 1.733213175007068e-05,
      "loss": 0.3925,
      "step": 7550
    },
    {
      "epoch": 0.4028837998303647,
      "grad_norm": 0.8938062787055969,
      "learning_rate": 1.731446140797286e-05,
      "loss": 0.3443,
      "step": 7600
    },
    {
      "epoch": 0.40553435114503816,
      "grad_norm": 3.2076597213745117,
      "learning_rate": 1.7296791065875035e-05,
      "loss": 0.172,
      "step": 7650
    },
    {
      "epoch": 0.4081849024597116,
      "grad_norm": 0.17080332338809967,
      "learning_rate": 1.7279120723777216e-05,
      "loss": 0.5654,
      "step": 7700
    },
    {
      "epoch": 0.4108354537743851,
      "grad_norm": 0.29388970136642456,
      "learning_rate": 1.726145038167939e-05,
      "loss": 0.5241,
      "step": 7750
    },
    {
      "epoch": 0.41348600508905853,
      "grad_norm": 5.295661926269531,
      "learning_rate": 1.724378003958157e-05,
      "loss": 0.3033,
      "step": 7800
    },
    {
      "epoch": 0.416136556403732,
      "grad_norm": 0.13748134672641754,
      "learning_rate": 1.7226109697483743e-05,
      "loss": 0.3454,
      "step": 7850
    },
    {
      "epoch": 0.41878710771840544,
      "grad_norm": 32.65890884399414,
      "learning_rate": 1.7208439355385923e-05,
      "loss": 0.3686,
      "step": 7900
    },
    {
      "epoch": 0.4214376590330789,
      "grad_norm": 28.55992317199707,
      "learning_rate": 1.7190769013288097e-05,
      "loss": 0.6581,
      "step": 7950
    },
    {
      "epoch": 0.42408821034775235,
      "grad_norm": 1.8620505332946777,
      "learning_rate": 1.7173098671190277e-05,
      "loss": 0.4957,
      "step": 8000
    },
    {
      "epoch": 0.4267387616624258,
      "grad_norm": 0.02338731661438942,
      "learning_rate": 1.715542832909245e-05,
      "loss": 0.3622,
      "step": 8050
    },
    {
      "epoch": 0.42938931297709926,
      "grad_norm": 0.10211028158664703,
      "learning_rate": 1.713775798699463e-05,
      "loss": 0.3029,
      "step": 8100
    },
    {
      "epoch": 0.4320398642917727,
      "grad_norm": 0.2655240297317505,
      "learning_rate": 1.7120087644896805e-05,
      "loss": 0.464,
      "step": 8150
    },
    {
      "epoch": 0.43469041560644617,
      "grad_norm": 4.53641939163208,
      "learning_rate": 1.7102417302798985e-05,
      "loss": 0.4171,
      "step": 8200
    },
    {
      "epoch": 0.43734096692111957,
      "grad_norm": 0.3651372492313385,
      "learning_rate": 1.708474696070116e-05,
      "loss": 0.5257,
      "step": 8250
    },
    {
      "epoch": 0.439991518235793,
      "grad_norm": 0.41989079117774963,
      "learning_rate": 1.706707661860334e-05,
      "loss": 0.4841,
      "step": 8300
    },
    {
      "epoch": 0.4426420695504665,
      "grad_norm": 0.13754622638225555,
      "learning_rate": 1.7049406276505513e-05,
      "loss": 0.3683,
      "step": 8350
    },
    {
      "epoch": 0.44529262086513993,
      "grad_norm": 0.3407730460166931,
      "learning_rate": 1.7031735934407693e-05,
      "loss": 0.451,
      "step": 8400
    },
    {
      "epoch": 0.4479431721798134,
      "grad_norm": 47.27229690551758,
      "learning_rate": 1.7014065592309867e-05,
      "loss": 0.6539,
      "step": 8450
    },
    {
      "epoch": 0.45059372349448684,
      "grad_norm": 0.07396094501018524,
      "learning_rate": 1.6996395250212047e-05,
      "loss": 0.5664,
      "step": 8500
    },
    {
      "epoch": 0.4532442748091603,
      "grad_norm": 0.10521042346954346,
      "learning_rate": 1.6978724908114224e-05,
      "loss": 0.4831,
      "step": 8550
    },
    {
      "epoch": 0.45589482612383375,
      "grad_norm": 0.11137785017490387,
      "learning_rate": 1.69610545660164e-05,
      "loss": 0.3284,
      "step": 8600
    },
    {
      "epoch": 0.4585453774385072,
      "grad_norm": 0.09645861387252808,
      "learning_rate": 1.6943384223918578e-05,
      "loss": 0.3858,
      "step": 8650
    },
    {
      "epoch": 0.46119592875318066,
      "grad_norm": 0.013949895277619362,
      "learning_rate": 1.6925713881820755e-05,
      "loss": 0.2917,
      "step": 8700
    },
    {
      "epoch": 0.4638464800678541,
      "grad_norm": 0.04806521534919739,
      "learning_rate": 1.6908043539722932e-05,
      "loss": 0.2405,
      "step": 8750
    },
    {
      "epoch": 0.46649703138252757,
      "grad_norm": 0.14794601500034332,
      "learning_rate": 1.689037319762511e-05,
      "loss": 0.5056,
      "step": 8800
    },
    {
      "epoch": 0.469147582697201,
      "grad_norm": 0.26897984743118286,
      "learning_rate": 1.6872702855527286e-05,
      "loss": 0.5081,
      "step": 8850
    },
    {
      "epoch": 0.4717981340118745,
      "grad_norm": 0.06430159509181976,
      "learning_rate": 1.6855032513429463e-05,
      "loss": 0.3767,
      "step": 8900
    },
    {
      "epoch": 0.47444868532654794,
      "grad_norm": 0.15569891035556793,
      "learning_rate": 1.683736217133164e-05,
      "loss": 0.4429,
      "step": 8950
    },
    {
      "epoch": 0.4770992366412214,
      "grad_norm": 0.052333541214466095,
      "learning_rate": 1.6819691829233817e-05,
      "loss": 0.2647,
      "step": 9000
    },
    {
      "epoch": 0.47974978795589485,
      "grad_norm": 12.755046844482422,
      "learning_rate": 1.6802021487135994e-05,
      "loss": 0.3915,
      "step": 9050
    },
    {
      "epoch": 0.4824003392705683,
      "grad_norm": 0.05865934118628502,
      "learning_rate": 1.678435114503817e-05,
      "loss": 0.6809,
      "step": 9100
    },
    {
      "epoch": 0.48505089058524176,
      "grad_norm": 0.20608532428741455,
      "learning_rate": 1.6766680802940348e-05,
      "loss": 0.6078,
      "step": 9150
    },
    {
      "epoch": 0.48770144189991516,
      "grad_norm": 1.4532575607299805,
      "learning_rate": 1.6749010460842525e-05,
      "loss": 0.35,
      "step": 9200
    },
    {
      "epoch": 0.4903519932145886,
      "grad_norm": 0.17545606195926666,
      "learning_rate": 1.67313401187447e-05,
      "loss": 0.4725,
      "step": 9250
    },
    {
      "epoch": 0.49300254452926207,
      "grad_norm": 0.12757812440395355,
      "learning_rate": 1.671366977664688e-05,
      "loss": 0.5861,
      "step": 9300
    },
    {
      "epoch": 0.4956530958439355,
      "grad_norm": 0.14133961498737335,
      "learning_rate": 1.6695999434549055e-05,
      "loss": 0.3472,
      "step": 9350
    },
    {
      "epoch": 0.498303647158609,
      "grad_norm": 0.21248236298561096,
      "learning_rate": 1.6678329092451232e-05,
      "loss": 0.385,
      "step": 9400
    },
    {
      "epoch": 0.5009541984732825,
      "grad_norm": 0.04085339605808258,
      "learning_rate": 1.666065875035341e-05,
      "loss": 0.461,
      "step": 9450
    },
    {
      "epoch": 0.5036047497879559,
      "grad_norm": 0.034115251153707504,
      "learning_rate": 1.6642988408255586e-05,
      "loss": 0.3168,
      "step": 9500
    },
    {
      "epoch": 0.5062553011026294,
      "grad_norm": 0.06321335583925247,
      "learning_rate": 1.6625318066157763e-05,
      "loss": 0.4548,
      "step": 9550
    },
    {
      "epoch": 0.5089058524173028,
      "grad_norm": 7.204468250274658,
      "learning_rate": 1.660764772405994e-05,
      "loss": 0.4443,
      "step": 9600
    },
    {
      "epoch": 0.5115564037319763,
      "grad_norm": 0.08349519968032837,
      "learning_rate": 1.6589977381962117e-05,
      "loss": 0.4369,
      "step": 9650
    },
    {
      "epoch": 0.5142069550466497,
      "grad_norm": 0.16552387177944183,
      "learning_rate": 1.6572307039864294e-05,
      "loss": 0.4753,
      "step": 9700
    },
    {
      "epoch": 0.5168575063613231,
      "grad_norm": 0.10038068145513535,
      "learning_rate": 1.655463669776647e-05,
      "loss": 0.4517,
      "step": 9750
    },
    {
      "epoch": 0.5195080576759966,
      "grad_norm": 0.19529443979263306,
      "learning_rate": 1.6536966355668648e-05,
      "loss": 0.574,
      "step": 9800
    },
    {
      "epoch": 0.52215860899067,
      "grad_norm": 0.2745306193828583,
      "learning_rate": 1.6519296013570825e-05,
      "loss": 0.4437,
      "step": 9850
    },
    {
      "epoch": 0.5248091603053435,
      "grad_norm": 60.109107971191406,
      "learning_rate": 1.6501625671473002e-05,
      "loss": 0.4665,
      "step": 9900
    },
    {
      "epoch": 0.5274597116200169,
      "grad_norm": 0.10489045828580856,
      "learning_rate": 1.648395532937518e-05,
      "loss": 0.4909,
      "step": 9950
    },
    {
      "epoch": 0.5301102629346904,
      "grad_norm": 0.01563193090260029,
      "learning_rate": 1.6466284987277356e-05,
      "loss": 0.3799,
      "step": 10000
    },
    {
      "epoch": 0.5327608142493638,
      "grad_norm": 0.3984542489051819,
      "learning_rate": 1.6448614645179533e-05,
      "loss": 0.6162,
      "step": 10050
    },
    {
      "epoch": 0.5354113655640373,
      "grad_norm": 27.487056732177734,
      "learning_rate": 1.643094430308171e-05,
      "loss": 0.1977,
      "step": 10100
    },
    {
      "epoch": 0.5380619168787107,
      "grad_norm": 0.06042666360735893,
      "learning_rate": 1.6413273960983887e-05,
      "loss": 0.3896,
      "step": 10150
    },
    {
      "epoch": 0.5407124681933843,
      "grad_norm": 0.03426885977387428,
      "learning_rate": 1.6395603618886064e-05,
      "loss": 0.4622,
      "step": 10200
    },
    {
      "epoch": 0.5433630195080577,
      "grad_norm": 0.25741368532180786,
      "learning_rate": 1.637793327678824e-05,
      "loss": 0.5076,
      "step": 10250
    },
    {
      "epoch": 0.5460135708227312,
      "grad_norm": 59.73685836791992,
      "learning_rate": 1.6360262934690418e-05,
      "loss": 0.2894,
      "step": 10300
    },
    {
      "epoch": 0.5486641221374046,
      "grad_norm": 0.032308291643857956,
      "learning_rate": 1.6342592592592595e-05,
      "loss": 0.5125,
      "step": 10350
    },
    {
      "epoch": 0.5513146734520781,
      "grad_norm": 0.053710710257291794,
      "learning_rate": 1.632492225049477e-05,
      "loss": 0.2347,
      "step": 10400
    },
    {
      "epoch": 0.5539652247667515,
      "grad_norm": 0.14000509679317474,
      "learning_rate": 1.630725190839695e-05,
      "loss": 0.2771,
      "step": 10450
    },
    {
      "epoch": 0.556615776081425,
      "grad_norm": 0.5473117828369141,
      "learning_rate": 1.6289581566299126e-05,
      "loss": 0.4616,
      "step": 10500
    },
    {
      "epoch": 0.5592663273960984,
      "grad_norm": 0.3113363981246948,
      "learning_rate": 1.6271911224201303e-05,
      "loss": 0.4224,
      "step": 10550
    },
    {
      "epoch": 0.5619168787107719,
      "grad_norm": 0.08289414644241333,
      "learning_rate": 1.625424088210348e-05,
      "loss": 0.3906,
      "step": 10600
    },
    {
      "epoch": 0.5645674300254453,
      "grad_norm": 0.028613034635782242,
      "learning_rate": 1.6236570540005656e-05,
      "loss": 0.7096,
      "step": 10650
    },
    {
      "epoch": 0.5672179813401187,
      "grad_norm": 31.623254776000977,
      "learning_rate": 1.6218900197907833e-05,
      "loss": 0.4468,
      "step": 10700
    },
    {
      "epoch": 0.5698685326547922,
      "grad_norm": 0.09690122306346893,
      "learning_rate": 1.620122985581001e-05,
      "loss": 0.4044,
      "step": 10750
    },
    {
      "epoch": 0.5725190839694656,
      "grad_norm": 0.14872148633003235,
      "learning_rate": 1.6183559513712187e-05,
      "loss": 0.5866,
      "step": 10800
    },
    {
      "epoch": 0.5751696352841391,
      "grad_norm": 0.12826010584831238,
      "learning_rate": 1.6165889171614364e-05,
      "loss": 0.455,
      "step": 10850
    },
    {
      "epoch": 0.5778201865988125,
      "grad_norm": 0.0376630499958992,
      "learning_rate": 1.614821882951654e-05,
      "loss": 0.2819,
      "step": 10900
    },
    {
      "epoch": 0.580470737913486,
      "grad_norm": 0.12138102948665619,
      "learning_rate": 1.6130548487418718e-05,
      "loss": 0.6393,
      "step": 10950
    },
    {
      "epoch": 0.5831212892281594,
      "grad_norm": 0.24420122802257538,
      "learning_rate": 1.6112878145320895e-05,
      "loss": 0.4827,
      "step": 11000
    },
    {
      "epoch": 0.5857718405428329,
      "grad_norm": 11.117049217224121,
      "learning_rate": 1.6095207803223072e-05,
      "loss": 0.6052,
      "step": 11050
    },
    {
      "epoch": 0.5884223918575063,
      "grad_norm": 0.07601470500230789,
      "learning_rate": 1.607753746112525e-05,
      "loss": 0.4157,
      "step": 11100
    },
    {
      "epoch": 0.5910729431721798,
      "grad_norm": 0.14538507163524628,
      "learning_rate": 1.6059867119027426e-05,
      "loss": 0.4705,
      "step": 11150
    },
    {
      "epoch": 0.5937234944868532,
      "grad_norm": 0.0753573626279831,
      "learning_rate": 1.6042196776929603e-05,
      "loss": 0.2896,
      "step": 11200
    },
    {
      "epoch": 0.5963740458015268,
      "grad_norm": 39.614933013916016,
      "learning_rate": 1.602452643483178e-05,
      "loss": 0.2093,
      "step": 11250
    },
    {
      "epoch": 0.5990245971162002,
      "grad_norm": 32.01744079589844,
      "learning_rate": 1.6006856092733957e-05,
      "loss": 0.6959,
      "step": 11300
    },
    {
      "epoch": 0.6016751484308737,
      "grad_norm": 0.5613874793052673,
      "learning_rate": 1.5989185750636134e-05,
      "loss": 0.6243,
      "step": 11350
    },
    {
      "epoch": 0.6043256997455471,
      "grad_norm": 22.302623748779297,
      "learning_rate": 1.597151540853831e-05,
      "loss": 0.3363,
      "step": 11400
    },
    {
      "epoch": 0.6069762510602206,
      "grad_norm": 0.2989545166492462,
      "learning_rate": 1.5953845066440488e-05,
      "loss": 0.5501,
      "step": 11450
    },
    {
      "epoch": 0.609626802374894,
      "grad_norm": 0.13135920464992523,
      "learning_rate": 1.5936174724342665e-05,
      "loss": 0.4542,
      "step": 11500
    },
    {
      "epoch": 0.6122773536895675,
      "grad_norm": 0.18966315686702728,
      "learning_rate": 1.5918504382244842e-05,
      "loss": 0.495,
      "step": 11550
    },
    {
      "epoch": 0.6149279050042409,
      "grad_norm": 0.21369801461696625,
      "learning_rate": 1.590083404014702e-05,
      "loss": 0.2928,
      "step": 11600
    },
    {
      "epoch": 0.6175784563189143,
      "grad_norm": 19.686107635498047,
      "learning_rate": 1.5883163698049196e-05,
      "loss": 0.5034,
      "step": 11650
    },
    {
      "epoch": 0.6202290076335878,
      "grad_norm": 0.04990014806389809,
      "learning_rate": 1.5865493355951373e-05,
      "loss": 0.3203,
      "step": 11700
    },
    {
      "epoch": 0.6228795589482612,
      "grad_norm": 0.05538341775536537,
      "learning_rate": 1.584782301385355e-05,
      "loss": 0.2558,
      "step": 11750
    },
    {
      "epoch": 0.6255301102629347,
      "grad_norm": 0.8674327731132507,
      "learning_rate": 1.5830152671755727e-05,
      "loss": 0.5668,
      "step": 11800
    },
    {
      "epoch": 0.6281806615776081,
      "grad_norm": 0.23621870577335358,
      "learning_rate": 1.5812482329657904e-05,
      "loss": 0.3734,
      "step": 11850
    },
    {
      "epoch": 0.6308312128922816,
      "grad_norm": 0.026730848476290703,
      "learning_rate": 1.579481198756008e-05,
      "loss": 0.2444,
      "step": 11900
    },
    {
      "epoch": 0.633481764206955,
      "grad_norm": 0.03148990869522095,
      "learning_rate": 1.5777141645462258e-05,
      "loss": 0.2876,
      "step": 11950
    },
    {
      "epoch": 0.6361323155216285,
      "grad_norm": 0.10365951806306839,
      "learning_rate": 1.5759471303364434e-05,
      "loss": 0.4206,
      "step": 12000
    },
    {
      "epoch": 0.6387828668363019,
      "grad_norm": 0.04820242524147034,
      "learning_rate": 1.574180096126661e-05,
      "loss": 0.3506,
      "step": 12050
    },
    {
      "epoch": 0.6414334181509754,
      "grad_norm": 13.859939575195312,
      "learning_rate": 1.572413061916879e-05,
      "loss": 0.5256,
      "step": 12100
    },
    {
      "epoch": 0.6440839694656488,
      "grad_norm": 0.048084791749715805,
      "learning_rate": 1.5706460277070965e-05,
      "loss": 0.2973,
      "step": 12150
    },
    {
      "epoch": 0.6467345207803223,
      "grad_norm": 0.03179746866226196,
      "learning_rate": 1.5688789934973142e-05,
      "loss": 0.373,
      "step": 12200
    },
    {
      "epoch": 0.6493850720949957,
      "grad_norm": 0.6287967562675476,
      "learning_rate": 1.567111959287532e-05,
      "loss": 0.5151,
      "step": 12250
    },
    {
      "epoch": 0.6520356234096693,
      "grad_norm": 0.03754310682415962,
      "learning_rate": 1.5653449250777496e-05,
      "loss": 0.4085,
      "step": 12300
    },
    {
      "epoch": 0.6546861747243427,
      "grad_norm": 0.31185582280158997,
      "learning_rate": 1.5635778908679673e-05,
      "loss": 0.6182,
      "step": 12350
    },
    {
      "epoch": 0.6573367260390162,
      "grad_norm": 0.056870050728321075,
      "learning_rate": 1.561810856658185e-05,
      "loss": 0.5022,
      "step": 12400
    },
    {
      "epoch": 0.6599872773536896,
      "grad_norm": 0.10139492899179459,
      "learning_rate": 1.5600438224484027e-05,
      "loss": 0.262,
      "step": 12450
    },
    {
      "epoch": 0.6626378286683631,
      "grad_norm": 0.03885289654135704,
      "learning_rate": 1.5582767882386204e-05,
      "loss": 0.2736,
      "step": 12500
    },
    {
      "epoch": 0.6652883799830365,
      "grad_norm": 27.499120712280273,
      "learning_rate": 1.556509754028838e-05,
      "loss": 0.6949,
      "step": 12550
    },
    {
      "epoch": 0.6679389312977099,
      "grad_norm": 0.05901829153299332,
      "learning_rate": 1.5547427198190558e-05,
      "loss": 0.2196,
      "step": 12600
    },
    {
      "epoch": 0.6705894826123834,
      "grad_norm": 0.03674859181046486,
      "learning_rate": 1.5529756856092735e-05,
      "loss": 0.4379,
      "step": 12650
    },
    {
      "epoch": 0.6732400339270568,
      "grad_norm": 0.042830388993024826,
      "learning_rate": 1.5512086513994912e-05,
      "loss": 0.3659,
      "step": 12700
    },
    {
      "epoch": 0.6758905852417303,
      "grad_norm": 14.436840057373047,
      "learning_rate": 1.549441617189709e-05,
      "loss": 0.408,
      "step": 12750
    },
    {
      "epoch": 0.6785411365564037,
      "grad_norm": 0.0444907546043396,
      "learning_rate": 1.5476745829799266e-05,
      "loss": 0.3763,
      "step": 12800
    },
    {
      "epoch": 0.6811916878710772,
      "grad_norm": 73.05332946777344,
      "learning_rate": 1.5459075487701443e-05,
      "loss": 0.489,
      "step": 12850
    },
    {
      "epoch": 0.6838422391857506,
      "grad_norm": 0.026230230927467346,
      "learning_rate": 1.544140514560362e-05,
      "loss": 0.2562,
      "step": 12900
    },
    {
      "epoch": 0.6864927905004241,
      "grad_norm": 0.03958544135093689,
      "learning_rate": 1.5423734803505797e-05,
      "loss": 0.26,
      "step": 12950
    },
    {
      "epoch": 0.6891433418150975,
      "grad_norm": 0.10683184117078781,
      "learning_rate": 1.5406064461407974e-05,
      "loss": 0.5086,
      "step": 13000
    },
    {
      "epoch": 0.691793893129771,
      "grad_norm": 0.18102623522281647,
      "learning_rate": 1.538839411931015e-05,
      "loss": 0.4746,
      "step": 13050
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 0.22467520833015442,
      "learning_rate": 1.5370723777212328e-05,
      "loss": 0.5742,
      "step": 13100
    },
    {
      "epoch": 0.6970949957591179,
      "grad_norm": 0.15342679619789124,
      "learning_rate": 1.5353053435114505e-05,
      "loss": 0.5015,
      "step": 13150
    },
    {
      "epoch": 0.6997455470737913,
      "grad_norm": 3.094364643096924,
      "learning_rate": 1.533538309301668e-05,
      "loss": 0.3822,
      "step": 13200
    },
    {
      "epoch": 0.7023960983884648,
      "grad_norm": 0.029568146914243698,
      "learning_rate": 1.531771275091886e-05,
      "loss": 0.2181,
      "step": 13250
    },
    {
      "epoch": 0.7050466497031382,
      "grad_norm": 0.17653948068618774,
      "learning_rate": 1.5300042408821036e-05,
      "loss": 0.509,
      "step": 13300
    },
    {
      "epoch": 0.7076972010178118,
      "grad_norm": 0.04554581269621849,
      "learning_rate": 1.5282372066723212e-05,
      "loss": 0.3451,
      "step": 13350
    },
    {
      "epoch": 0.7103477523324851,
      "grad_norm": 0.16293323040008545,
      "learning_rate": 1.526470172462539e-05,
      "loss": 0.4565,
      "step": 13400
    },
    {
      "epoch": 0.7129983036471587,
      "grad_norm": 0.05012844130396843,
      "learning_rate": 1.5247031382527566e-05,
      "loss": 0.4524,
      "step": 13450
    },
    {
      "epoch": 0.7156488549618321,
      "grad_norm": 42.10750961303711,
      "learning_rate": 1.5229361040429745e-05,
      "loss": 0.4028,
      "step": 13500
    },
    {
      "epoch": 0.7182994062765055,
      "grad_norm": 0.4454154968261719,
      "learning_rate": 1.521169069833192e-05,
      "loss": 0.3627,
      "step": 13550
    },
    {
      "epoch": 0.720949957591179,
      "grad_norm": 38.82859420776367,
      "learning_rate": 1.5194020356234099e-05,
      "loss": 0.4275,
      "step": 13600
    },
    {
      "epoch": 0.7236005089058524,
      "grad_norm": 30.188013076782227,
      "learning_rate": 1.5176350014136274e-05,
      "loss": 0.7018,
      "step": 13650
    },
    {
      "epoch": 0.7262510602205259,
      "grad_norm": 41.64137649536133,
      "learning_rate": 1.5158679672038453e-05,
      "loss": 0.3817,
      "step": 13700
    },
    {
      "epoch": 0.7289016115351993,
      "grad_norm": 1.0084115266799927,
      "learning_rate": 1.5141009329940628e-05,
      "loss": 0.4409,
      "step": 13750
    },
    {
      "epoch": 0.7315521628498728,
      "grad_norm": 0.09965116530656815,
      "learning_rate": 1.5123338987842807e-05,
      "loss": 0.5074,
      "step": 13800
    },
    {
      "epoch": 0.7342027141645462,
      "grad_norm": 19.150291442871094,
      "learning_rate": 1.5105668645744982e-05,
      "loss": 0.5437,
      "step": 13850
    },
    {
      "epoch": 0.7368532654792197,
      "grad_norm": 5.540347576141357,
      "learning_rate": 1.508799830364716e-05,
      "loss": 0.573,
      "step": 13900
    },
    {
      "epoch": 0.7395038167938931,
      "grad_norm": 181.59361267089844,
      "learning_rate": 1.5070327961549336e-05,
      "loss": 0.2973,
      "step": 13950
    },
    {
      "epoch": 0.7421543681085666,
      "grad_norm": 0.03562284633517265,
      "learning_rate": 1.5052657619451515e-05,
      "loss": 0.3592,
      "step": 14000
    },
    {
      "epoch": 0.74480491942324,
      "grad_norm": 0.09424233436584473,
      "learning_rate": 1.503498727735369e-05,
      "loss": 0.2633,
      "step": 14050
    },
    {
      "epoch": 0.7474554707379135,
      "grad_norm": 0.021487848833203316,
      "learning_rate": 1.5017316935255869e-05,
      "loss": 0.1706,
      "step": 14100
    },
    {
      "epoch": 0.7501060220525869,
      "grad_norm": 0.06516492366790771,
      "learning_rate": 1.4999646593158044e-05,
      "loss": 0.5181,
      "step": 14150
    },
    {
      "epoch": 0.7527565733672604,
      "grad_norm": 22.956024169921875,
      "learning_rate": 1.4981976251060223e-05,
      "loss": 0.2971,
      "step": 14200
    },
    {
      "epoch": 0.7554071246819338,
      "grad_norm": 55.50893020629883,
      "learning_rate": 1.4964305908962398e-05,
      "loss": 0.5976,
      "step": 14250
    },
    {
      "epoch": 0.7580576759966073,
      "grad_norm": 0.10494580119848251,
      "learning_rate": 1.4946635566864577e-05,
      "loss": 0.506,
      "step": 14300
    },
    {
      "epoch": 0.7607082273112807,
      "grad_norm": 0.05514579638838768,
      "learning_rate": 1.4928965224766753e-05,
      "loss": 0.362,
      "step": 14350
    },
    {
      "epoch": 0.7633587786259542,
      "grad_norm": 0.1047600507736206,
      "learning_rate": 1.491129488266893e-05,
      "loss": 0.2239,
      "step": 14400
    },
    {
      "epoch": 0.7660093299406276,
      "grad_norm": 0.14284466207027435,
      "learning_rate": 1.4893624540571107e-05,
      "loss": 0.5466,
      "step": 14450
    },
    {
      "epoch": 0.768659881255301,
      "grad_norm": 0.06725621968507767,
      "learning_rate": 1.4875954198473284e-05,
      "loss": 0.4331,
      "step": 14500
    },
    {
      "epoch": 0.7713104325699746,
      "grad_norm": 0.10335991531610489,
      "learning_rate": 1.4858283856375461e-05,
      "loss": 0.2862,
      "step": 14550
    },
    {
      "epoch": 0.773960983884648,
      "grad_norm": 3.0903022289276123,
      "learning_rate": 1.4840613514277638e-05,
      "loss": 0.434,
      "step": 14600
    },
    {
      "epoch": 0.7766115351993215,
      "grad_norm": 0.22599707543849945,
      "learning_rate": 1.4822943172179815e-05,
      "loss": 0.3897,
      "step": 14650
    },
    {
      "epoch": 0.7792620865139949,
      "grad_norm": 0.15427479147911072,
      "learning_rate": 1.4805272830081992e-05,
      "loss": 0.3112,
      "step": 14700
    },
    {
      "epoch": 0.7819126378286684,
      "grad_norm": 0.030951643362641335,
      "learning_rate": 1.478760248798417e-05,
      "loss": 0.458,
      "step": 14750
    },
    {
      "epoch": 0.7845631891433418,
      "grad_norm": 0.01918906904757023,
      "learning_rate": 1.4769932145886346e-05,
      "loss": 0.3213,
      "step": 14800
    },
    {
      "epoch": 0.7872137404580153,
      "grad_norm": 0.04387274757027626,
      "learning_rate": 1.4752261803788523e-05,
      "loss": 0.5011,
      "step": 14850
    },
    {
      "epoch": 0.7898642917726887,
      "grad_norm": 1.1282432079315186,
      "learning_rate": 1.47345914616907e-05,
      "loss": 0.2663,
      "step": 14900
    },
    {
      "epoch": 0.7925148430873622,
      "grad_norm": 0.06293296068906784,
      "learning_rate": 1.4716921119592877e-05,
      "loss": 0.4232,
      "step": 14950
    },
    {
      "epoch": 0.7951653944020356,
      "grad_norm": 0.08594267070293427,
      "learning_rate": 1.4699250777495054e-05,
      "loss": 0.4403,
      "step": 15000
    },
    {
      "epoch": 0.7978159457167091,
      "grad_norm": 0.06315647810697556,
      "learning_rate": 1.4681580435397231e-05,
      "loss": 0.5174,
      "step": 15050
    },
    {
      "epoch": 0.8004664970313825,
      "grad_norm": 0.030891483649611473,
      "learning_rate": 1.4663910093299408e-05,
      "loss": 0.2445,
      "step": 15100
    },
    {
      "epoch": 0.803117048346056,
      "grad_norm": 0.16029982268810272,
      "learning_rate": 1.4646239751201585e-05,
      "loss": 0.2224,
      "step": 15150
    },
    {
      "epoch": 0.8057675996607294,
      "grad_norm": 0.03154367581009865,
      "learning_rate": 1.4628569409103762e-05,
      "loss": 0.3425,
      "step": 15200
    },
    {
      "epoch": 0.8084181509754029,
      "grad_norm": 0.11783932149410248,
      "learning_rate": 1.4610899067005939e-05,
      "loss": 0.317,
      "step": 15250
    },
    {
      "epoch": 0.8110687022900763,
      "grad_norm": 0.39888322353363037,
      "learning_rate": 1.4593228724908116e-05,
      "loss": 0.5009,
      "step": 15300
    },
    {
      "epoch": 0.8137192536047498,
      "grad_norm": 0.014381468296051025,
      "learning_rate": 1.4575558382810293e-05,
      "loss": 0.2912,
      "step": 15350
    },
    {
      "epoch": 0.8163698049194232,
      "grad_norm": 43.1275634765625,
      "learning_rate": 1.455788804071247e-05,
      "loss": 0.3484,
      "step": 15400
    },
    {
      "epoch": 0.8190203562340967,
      "grad_norm": 0.09502504765987396,
      "learning_rate": 1.4540217698614647e-05,
      "loss": 0.3395,
      "step": 15450
    },
    {
      "epoch": 0.8216709075487701,
      "grad_norm": 0.01020414475351572,
      "learning_rate": 1.4522547356516824e-05,
      "loss": 0.2341,
      "step": 15500
    },
    {
      "epoch": 0.8243214588634435,
      "grad_norm": 14.417999267578125,
      "learning_rate": 1.4504877014419e-05,
      "loss": 0.6102,
      "step": 15550
    },
    {
      "epoch": 0.8269720101781171,
      "grad_norm": 0.20736105740070343,
      "learning_rate": 1.4487206672321178e-05,
      "loss": 0.2204,
      "step": 15600
    },
    {
      "epoch": 0.8296225614927905,
      "grad_norm": 0.0977332666516304,
      "learning_rate": 1.4469536330223355e-05,
      "loss": 0.2742,
      "step": 15650
    },
    {
      "epoch": 0.832273112807464,
      "grad_norm": 0.009428529068827629,
      "learning_rate": 1.4451865988125531e-05,
      "loss": 0.2607,
      "step": 15700
    },
    {
      "epoch": 0.8349236641221374,
      "grad_norm": 0.16528446972370148,
      "learning_rate": 1.4434195646027708e-05,
      "loss": 0.3842,
      "step": 15750
    },
    {
      "epoch": 0.8375742154368109,
      "grad_norm": 0.05942896753549576,
      "learning_rate": 1.4416525303929885e-05,
      "loss": 0.4437,
      "step": 15800
    },
    {
      "epoch": 0.8402247667514843,
      "grad_norm": 40.79334259033203,
      "learning_rate": 1.4398854961832062e-05,
      "loss": 0.5638,
      "step": 15850
    },
    {
      "epoch": 0.8428753180661578,
      "grad_norm": 0.02487006038427353,
      "learning_rate": 1.438118461973424e-05,
      "loss": 0.416,
      "step": 15900
    },
    {
      "epoch": 0.8455258693808312,
      "grad_norm": 0.061098430305719376,
      "learning_rate": 1.4363514277636416e-05,
      "loss": 0.4653,
      "step": 15950
    },
    {
      "epoch": 0.8481764206955047,
      "grad_norm": 0.07236039638519287,
      "learning_rate": 1.4345843935538593e-05,
      "loss": 0.5794,
      "step": 16000
    },
    {
      "epoch": 0.8508269720101781,
      "grad_norm": 0.5707778930664062,
      "learning_rate": 1.432817359344077e-05,
      "loss": 0.3774,
      "step": 16050
    },
    {
      "epoch": 0.8534775233248516,
      "grad_norm": 0.09607328474521637,
      "learning_rate": 1.4310503251342947e-05,
      "loss": 0.4373,
      "step": 16100
    },
    {
      "epoch": 0.856128074639525,
      "grad_norm": 0.16475246846675873,
      "learning_rate": 1.4292832909245124e-05,
      "loss": 0.3768,
      "step": 16150
    },
    {
      "epoch": 0.8587786259541985,
      "grad_norm": 176.07305908203125,
      "learning_rate": 1.4275162567147301e-05,
      "loss": 0.402,
      "step": 16200
    },
    {
      "epoch": 0.8614291772688719,
      "grad_norm": 0.10477802157402039,
      "learning_rate": 1.4257492225049478e-05,
      "loss": 0.5799,
      "step": 16250
    },
    {
      "epoch": 0.8640797285835454,
      "grad_norm": 0.5099291801452637,
      "learning_rate": 1.4239821882951655e-05,
      "loss": 0.2419,
      "step": 16300
    },
    {
      "epoch": 0.8667302798982188,
      "grad_norm": 0.023498661816120148,
      "learning_rate": 1.4222151540853832e-05,
      "loss": 0.2232,
      "step": 16350
    },
    {
      "epoch": 0.8693808312128923,
      "grad_norm": 0.06222500652074814,
      "learning_rate": 1.4204481198756009e-05,
      "loss": 0.51,
      "step": 16400
    },
    {
      "epoch": 0.8720313825275657,
      "grad_norm": 0.14758913218975067,
      "learning_rate": 1.4186810856658186e-05,
      "loss": 0.3582,
      "step": 16450
    },
    {
      "epoch": 0.8746819338422391,
      "grad_norm": 0.0984174832701683,
      "learning_rate": 1.4169140514560363e-05,
      "loss": 0.3372,
      "step": 16500
    },
    {
      "epoch": 0.8773324851569126,
      "grad_norm": 0.5714910626411438,
      "learning_rate": 1.415147017246254e-05,
      "loss": 0.2946,
      "step": 16550
    },
    {
      "epoch": 0.879983036471586,
      "grad_norm": 0.03640422224998474,
      "learning_rate": 1.4133799830364717e-05,
      "loss": 0.4033,
      "step": 16600
    },
    {
      "epoch": 0.8826335877862596,
      "grad_norm": 25.22773551940918,
      "learning_rate": 1.4116129488266894e-05,
      "loss": 0.3751,
      "step": 16650
    },
    {
      "epoch": 0.885284139100933,
      "grad_norm": 0.09657871723175049,
      "learning_rate": 1.409845914616907e-05,
      "loss": 0.271,
      "step": 16700
    },
    {
      "epoch": 0.8879346904156065,
      "grad_norm": 0.17979571223258972,
      "learning_rate": 1.4080788804071248e-05,
      "loss": 0.2483,
      "step": 16750
    },
    {
      "epoch": 0.8905852417302799,
      "grad_norm": 20.235151290893555,
      "learning_rate": 1.4063118461973425e-05,
      "loss": 0.7456,
      "step": 16800
    },
    {
      "epoch": 0.8932357930449534,
      "grad_norm": 0.05145391821861267,
      "learning_rate": 1.4045448119875602e-05,
      "loss": 0.3909,
      "step": 16850
    },
    {
      "epoch": 0.8958863443596268,
      "grad_norm": 18.44902992248535,
      "learning_rate": 1.4027777777777779e-05,
      "loss": 0.3706,
      "step": 16900
    },
    {
      "epoch": 0.8985368956743003,
      "grad_norm": 32.32838821411133,
      "learning_rate": 1.4010107435679956e-05,
      "loss": 0.4843,
      "step": 16950
    },
    {
      "epoch": 0.9011874469889737,
      "grad_norm": 0.0634525939822197,
      "learning_rate": 1.3992437093582133e-05,
      "loss": 0.3945,
      "step": 17000
    },
    {
      "epoch": 0.9038379983036472,
      "grad_norm": 1.268149971961975,
      "learning_rate": 1.397476675148431e-05,
      "loss": 0.5661,
      "step": 17050
    },
    {
      "epoch": 0.9064885496183206,
      "grad_norm": 0.048963893204927444,
      "learning_rate": 1.3957096409386486e-05,
      "loss": 0.4001,
      "step": 17100
    },
    {
      "epoch": 0.9091391009329941,
      "grad_norm": 0.0894053652882576,
      "learning_rate": 1.3939426067288663e-05,
      "loss": 0.4146,
      "step": 17150
    },
    {
      "epoch": 0.9117896522476675,
      "grad_norm": 38.60215759277344,
      "learning_rate": 1.392175572519084e-05,
      "loss": 0.5485,
      "step": 17200
    },
    {
      "epoch": 0.914440203562341,
      "grad_norm": 0.17273584008216858,
      "learning_rate": 1.3904085383093017e-05,
      "loss": 0.5492,
      "step": 17250
    },
    {
      "epoch": 0.9170907548770144,
      "grad_norm": 0.24043504893779755,
      "learning_rate": 1.3886415040995196e-05,
      "loss": 0.5157,
      "step": 17300
    },
    {
      "epoch": 0.9197413061916879,
      "grad_norm": 0.07412831485271454,
      "learning_rate": 1.3868744698897371e-05,
      "loss": 0.1787,
      "step": 17350
    },
    {
      "epoch": 0.9223918575063613,
      "grad_norm": 22.416702270507812,
      "learning_rate": 1.385107435679955e-05,
      "loss": 0.5491,
      "step": 17400
    },
    {
      "epoch": 0.9250424088210347,
      "grad_norm": 0.42727130651474,
      "learning_rate": 1.3833404014701725e-05,
      "loss": 0.2738,
      "step": 17450
    },
    {
      "epoch": 0.9276929601357082,
      "grad_norm": 35.9871826171875,
      "learning_rate": 1.3815733672603904e-05,
      "loss": 0.3962,
      "step": 17500
    },
    {
      "epoch": 0.9303435114503816,
      "grad_norm": 0.15129022300243378,
      "learning_rate": 1.3798063330506079e-05,
      "loss": 0.4098,
      "step": 17550
    },
    {
      "epoch": 0.9329940627650551,
      "grad_norm": 53.14334487915039,
      "learning_rate": 1.3780392988408258e-05,
      "loss": 0.611,
      "step": 17600
    },
    {
      "epoch": 0.9356446140797285,
      "grad_norm": 4.752200603485107,
      "learning_rate": 1.3762722646310433e-05,
      "loss": 0.2103,
      "step": 17650
    },
    {
      "epoch": 0.938295165394402,
      "grad_norm": 0.03381134197115898,
      "learning_rate": 1.3745052304212612e-05,
      "loss": 0.5041,
      "step": 17700
    },
    {
      "epoch": 0.9409457167090755,
      "grad_norm": 0.13657274842262268,
      "learning_rate": 1.3727381962114787e-05,
      "loss": 0.5397,
      "step": 17750
    },
    {
      "epoch": 0.943596268023749,
      "grad_norm": 17.102014541625977,
      "learning_rate": 1.3709711620016966e-05,
      "loss": 0.4223,
      "step": 17800
    },
    {
      "epoch": 0.9462468193384224,
      "grad_norm": 0.4324413537979126,
      "learning_rate": 1.3692041277919141e-05,
      "loss": 0.3508,
      "step": 17850
    },
    {
      "epoch": 0.9488973706530959,
      "grad_norm": 0.2195427417755127,
      "learning_rate": 1.367437093582132e-05,
      "loss": 0.4449,
      "step": 17900
    },
    {
      "epoch": 0.9515479219677693,
      "grad_norm": 0.02446099743247032,
      "learning_rate": 1.3656700593723495e-05,
      "loss": 0.1708,
      "step": 17950
    },
    {
      "epoch": 0.9541984732824428,
      "grad_norm": 0.10112250596284866,
      "learning_rate": 1.3639030251625674e-05,
      "loss": 0.4718,
      "step": 18000
    },
    {
      "epoch": 0.9568490245971162,
      "grad_norm": 0.021553467959165573,
      "learning_rate": 1.3621359909527849e-05,
      "loss": 0.196,
      "step": 18050
    },
    {
      "epoch": 0.9594995759117897,
      "grad_norm": 0.01116793043911457,
      "learning_rate": 1.3603689567430027e-05,
      "loss": 0.2795,
      "step": 18100
    },
    {
      "epoch": 0.9621501272264631,
      "grad_norm": 0.25530070066452026,
      "learning_rate": 1.3586019225332203e-05,
      "loss": 0.4091,
      "step": 18150
    },
    {
      "epoch": 0.9648006785411366,
      "grad_norm": 0.13867461681365967,
      "learning_rate": 1.3568348883234381e-05,
      "loss": 0.2936,
      "step": 18200
    },
    {
      "epoch": 0.96745122985581,
      "grad_norm": 0.01913764886558056,
      "learning_rate": 1.3550678541136557e-05,
      "loss": 0.2172,
      "step": 18250
    },
    {
      "epoch": 0.9701017811704835,
      "grad_norm": 0.025576021522283554,
      "learning_rate": 1.3533008199038735e-05,
      "loss": 0.2855,
      "step": 18300
    },
    {
      "epoch": 0.9727523324851569,
      "grad_norm": 0.0734676718711853,
      "learning_rate": 1.351533785694091e-05,
      "loss": 0.3827,
      "step": 18350
    },
    {
      "epoch": 0.9754028837998303,
      "grad_norm": 0.036216266453266144,
      "learning_rate": 1.349766751484309e-05,
      "loss": 0.2509,
      "step": 18400
    },
    {
      "epoch": 0.9780534351145038,
      "grad_norm": 0.09406982362270355,
      "learning_rate": 1.3479997172745264e-05,
      "loss": 0.481,
      "step": 18450
    },
    {
      "epoch": 0.9807039864291772,
      "grad_norm": 0.1315160095691681,
      "learning_rate": 1.3462326830647443e-05,
      "loss": 0.4531,
      "step": 18500
    },
    {
      "epoch": 0.9833545377438507,
      "grad_norm": 0.1211610659956932,
      "learning_rate": 1.3444656488549618e-05,
      "loss": 0.594,
      "step": 18550
    },
    {
      "epoch": 0.9860050890585241,
      "grad_norm": 0.0698687881231308,
      "learning_rate": 1.3426986146451797e-05,
      "loss": 0.3092,
      "step": 18600
    },
    {
      "epoch": 0.9886556403731976,
      "grad_norm": 41.4399299621582,
      "learning_rate": 1.3409315804353972e-05,
      "loss": 0.3875,
      "step": 18650
    },
    {
      "epoch": 0.991306191687871,
      "grad_norm": 0.03501236438751221,
      "learning_rate": 1.3391645462256151e-05,
      "loss": 0.327,
      "step": 18700
    },
    {
      "epoch": 0.9939567430025446,
      "grad_norm": 0.021430546417832375,
      "learning_rate": 1.3373975120158326e-05,
      "loss": 0.3601,
      "step": 18750
    },
    {
      "epoch": 0.996607294317218,
      "grad_norm": 0.02320144884288311,
      "learning_rate": 1.3356304778060505e-05,
      "loss": 0.4731,
      "step": 18800
    },
    {
      "epoch": 0.9992578456318915,
      "grad_norm": 25.27300453186035,
      "learning_rate": 1.333863443596268e-05,
      "loss": 0.5426,
      "step": 18850
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9863233380737693,
      "eval_f1": 0.7710233029381965,
      "eval_loss": 0.2571679353713989,
      "eval_precision": 0.9291819291819292,
      "eval_recall": 0.6588744588744588,
      "eval_runtime": 829.3703,
      "eval_samples_per_second": 39.848,
      "eval_steps_per_second": 4.982,
      "step": 18864
    },
    {
      "epoch": 1.001908396946565,
      "grad_norm": 0.09482313692569733,
      "learning_rate": 1.3320964093864859e-05,
      "loss": 0.3203,
      "step": 18900
    },
    {
      "epoch": 1.0045589482612383,
      "grad_norm": 0.016774743795394897,
      "learning_rate": 1.3303293751767034e-05,
      "loss": 0.3993,
      "step": 18950
    },
    {
      "epoch": 1.0072094995759118,
      "grad_norm": 0.3354422450065613,
      "learning_rate": 1.3285623409669213e-05,
      "loss": 0.5427,
      "step": 19000
    },
    {
      "epoch": 1.0098600508905853,
      "grad_norm": 0.07556262612342834,
      "learning_rate": 1.3267953067571388e-05,
      "loss": 0.5174,
      "step": 19050
    },
    {
      "epoch": 1.0125106022052588,
      "grad_norm": 0.13111664354801178,
      "learning_rate": 1.3250282725473567e-05,
      "loss": 0.2915,
      "step": 19100
    },
    {
      "epoch": 1.015161153519932,
      "grad_norm": 0.46098804473876953,
      "learning_rate": 1.3232612383375742e-05,
      "loss": 0.4656,
      "step": 19150
    },
    {
      "epoch": 1.0178117048346056,
      "grad_norm": 0.03877880796790123,
      "learning_rate": 1.321494204127792e-05,
      "loss": 0.4876,
      "step": 19200
    },
    {
      "epoch": 1.020462256149279,
      "grad_norm": 0.022077228873968124,
      "learning_rate": 1.3197271699180096e-05,
      "loss": 0.1231,
      "step": 19250
    },
    {
      "epoch": 1.0231128074639524,
      "grad_norm": 0.03833428770303726,
      "learning_rate": 1.3179601357082275e-05,
      "loss": 0.4736,
      "step": 19300
    },
    {
      "epoch": 1.025763358778626,
      "grad_norm": 0.15030759572982788,
      "learning_rate": 1.316193101498445e-05,
      "loss": 0.3759,
      "step": 19350
    },
    {
      "epoch": 1.0284139100932994,
      "grad_norm": 0.882312536239624,
      "learning_rate": 1.3144260672886629e-05,
      "loss": 0.4367,
      "step": 19400
    },
    {
      "epoch": 1.031064461407973,
      "grad_norm": 0.05671675503253937,
      "learning_rate": 1.3126590330788804e-05,
      "loss": 0.2785,
      "step": 19450
    },
    {
      "epoch": 1.0337150127226462,
      "grad_norm": 0.024538109079003334,
      "learning_rate": 1.3108919988690982e-05,
      "loss": 0.2612,
      "step": 19500
    },
    {
      "epoch": 1.0363655640373197,
      "grad_norm": 30.854827880859375,
      "learning_rate": 1.3091249646593158e-05,
      "loss": 0.219,
      "step": 19550
    },
    {
      "epoch": 1.0390161153519932,
      "grad_norm": 0.1009133830666542,
      "learning_rate": 1.3073579304495336e-05,
      "loss": 0.3243,
      "step": 19600
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 0.04278290271759033,
      "learning_rate": 1.3055908962397512e-05,
      "loss": 0.1909,
      "step": 19650
    },
    {
      "epoch": 1.04431721798134,
      "grad_norm": 0.36949899792671204,
      "learning_rate": 1.303823862029969e-05,
      "loss": 0.4008,
      "step": 19700
    },
    {
      "epoch": 1.0469677692960135,
      "grad_norm": 0.13682445883750916,
      "learning_rate": 1.3020568278201866e-05,
      "loss": 0.6058,
      "step": 19750
    },
    {
      "epoch": 1.049618320610687,
      "grad_norm": 32.04625701904297,
      "learning_rate": 1.3002897936104044e-05,
      "loss": 0.3244,
      "step": 19800
    },
    {
      "epoch": 1.0522688719253606,
      "grad_norm": 0.06263972073793411,
      "learning_rate": 1.298522759400622e-05,
      "loss": 0.2997,
      "step": 19850
    },
    {
      "epoch": 1.0549194232400338,
      "grad_norm": 18.55306625366211,
      "learning_rate": 1.2967557251908398e-05,
      "loss": 0.4904,
      "step": 19900
    },
    {
      "epoch": 1.0575699745547074,
      "grad_norm": 0.04990535229444504,
      "learning_rate": 1.2949886909810573e-05,
      "loss": 0.1263,
      "step": 19950
    },
    {
      "epoch": 1.0602205258693809,
      "grad_norm": 0.01757322996854782,
      "learning_rate": 1.2932216567712752e-05,
      "loss": 0.3181,
      "step": 20000
    },
    {
      "epoch": 1.0628710771840544,
      "grad_norm": 0.18117408454418182,
      "learning_rate": 1.2914546225614927e-05,
      "loss": 0.2783,
      "step": 20050
    },
    {
      "epoch": 1.0655216284987277,
      "grad_norm": 0.09168089926242828,
      "learning_rate": 1.2896875883517106e-05,
      "loss": 0.3322,
      "step": 20100
    },
    {
      "epoch": 1.0681721798134012,
      "grad_norm": 0.10195913165807724,
      "learning_rate": 1.2879205541419285e-05,
      "loss": 0.4252,
      "step": 20150
    },
    {
      "epoch": 1.0708227311280747,
      "grad_norm": 0.03906341269612312,
      "learning_rate": 1.286153519932146e-05,
      "loss": 0.4399,
      "step": 20200
    },
    {
      "epoch": 1.0734732824427482,
      "grad_norm": 0.11670199781656265,
      "learning_rate": 1.2843864857223639e-05,
      "loss": 0.2947,
      "step": 20250
    },
    {
      "epoch": 1.0761238337574215,
      "grad_norm": 21.893159866333008,
      "learning_rate": 1.2826194515125814e-05,
      "loss": 0.1985,
      "step": 20300
    },
    {
      "epoch": 1.078774385072095,
      "grad_norm": 0.3399621546268463,
      "learning_rate": 1.2808524173027993e-05,
      "loss": 0.3104,
      "step": 20350
    },
    {
      "epoch": 1.0814249363867685,
      "grad_norm": 0.15203337371349335,
      "learning_rate": 1.2790853830930168e-05,
      "loss": 0.5477,
      "step": 20400
    },
    {
      "epoch": 1.0840754877014418,
      "grad_norm": 0.1331849843263626,
      "learning_rate": 1.2773183488832346e-05,
      "loss": 0.4047,
      "step": 20450
    },
    {
      "epoch": 1.0867260390161153,
      "grad_norm": 0.1852058619260788,
      "learning_rate": 1.2755513146734522e-05,
      "loss": 0.5962,
      "step": 20500
    },
    {
      "epoch": 1.0893765903307888,
      "grad_norm": 0.126662015914917,
      "learning_rate": 1.27378428046367e-05,
      "loss": 0.4243,
      "step": 20550
    },
    {
      "epoch": 1.0920271416454623,
      "grad_norm": 43.701576232910156,
      "learning_rate": 1.2720172462538876e-05,
      "loss": 0.4943,
      "step": 20600
    },
    {
      "epoch": 1.0946776929601356,
      "grad_norm": 0.8118380904197693,
      "learning_rate": 1.2702502120441054e-05,
      "loss": 0.4338,
      "step": 20650
    },
    {
      "epoch": 1.0973282442748091,
      "grad_norm": 0.0902060717344284,
      "learning_rate": 1.268483177834323e-05,
      "loss": 0.6022,
      "step": 20700
    },
    {
      "epoch": 1.0999787955894826,
      "grad_norm": 0.039737265557050705,
      "learning_rate": 1.2667161436245408e-05,
      "loss": 0.3002,
      "step": 20750
    },
    {
      "epoch": 1.1026293469041561,
      "grad_norm": 0.019456930458545685,
      "learning_rate": 1.2649491094147583e-05,
      "loss": 0.2935,
      "step": 20800
    },
    {
      "epoch": 1.1052798982188294,
      "grad_norm": 0.7812156081199646,
      "learning_rate": 1.2631820752049762e-05,
      "loss": 0.5785,
      "step": 20850
    },
    {
      "epoch": 1.107930449533503,
      "grad_norm": 0.03751193359494209,
      "learning_rate": 1.2614150409951937e-05,
      "loss": 0.3096,
      "step": 20900
    },
    {
      "epoch": 1.1105810008481765,
      "grad_norm": 0.052664972841739655,
      "learning_rate": 1.2596480067854116e-05,
      "loss": 0.5511,
      "step": 20950
    },
    {
      "epoch": 1.11323155216285,
      "grad_norm": 0.25508227944374084,
      "learning_rate": 1.2578809725756291e-05,
      "loss": 0.3555,
      "step": 21000
    },
    {
      "epoch": 1.1158821034775233,
      "grad_norm": 0.03735252842307091,
      "learning_rate": 1.256113938365847e-05,
      "loss": 0.2852,
      "step": 21050
    },
    {
      "epoch": 1.1185326547921968,
      "grad_norm": 0.06373529136180878,
      "learning_rate": 1.2543469041560645e-05,
      "loss": 0.4015,
      "step": 21100
    },
    {
      "epoch": 1.1211832061068703,
      "grad_norm": 0.18973101675510406,
      "learning_rate": 1.2525798699462824e-05,
      "loss": 0.3739,
      "step": 21150
    },
    {
      "epoch": 1.1238337574215436,
      "grad_norm": 0.12614944577217102,
      "learning_rate": 1.2508128357365e-05,
      "loss": 0.3096,
      "step": 21200
    },
    {
      "epoch": 1.126484308736217,
      "grad_norm": 0.03199014067649841,
      "learning_rate": 1.2490458015267178e-05,
      "loss": 0.2795,
      "step": 21250
    },
    {
      "epoch": 1.1291348600508906,
      "grad_norm": 0.07154353708028793,
      "learning_rate": 1.2472787673169353e-05,
      "loss": 0.4009,
      "step": 21300
    },
    {
      "epoch": 1.131785411365564,
      "grad_norm": 0.13030999898910522,
      "learning_rate": 1.2455117331071532e-05,
      "loss": 0.554,
      "step": 21350
    },
    {
      "epoch": 1.1344359626802376,
      "grad_norm": 0.06655016541481018,
      "learning_rate": 1.2437446988973707e-05,
      "loss": 0.2102,
      "step": 21400
    },
    {
      "epoch": 1.137086513994911,
      "grad_norm": 65.93588256835938,
      "learning_rate": 1.2419776646875886e-05,
      "loss": 0.2979,
      "step": 21450
    },
    {
      "epoch": 1.1397370653095844,
      "grad_norm": 0.016895879060029984,
      "learning_rate": 1.2402106304778061e-05,
      "loss": 0.3161,
      "step": 21500
    },
    {
      "epoch": 1.142387616624258,
      "grad_norm": 616.27783203125,
      "learning_rate": 1.238443596268024e-05,
      "loss": 0.3785,
      "step": 21550
    },
    {
      "epoch": 1.1450381679389312,
      "grad_norm": 62.24679183959961,
      "learning_rate": 1.2366765620582415e-05,
      "loss": 0.4249,
      "step": 21600
    },
    {
      "epoch": 1.1476887192536047,
      "grad_norm": 47.47822952270508,
      "learning_rate": 1.2349095278484594e-05,
      "loss": 0.4368,
      "step": 21650
    },
    {
      "epoch": 1.1503392705682782,
      "grad_norm": 0.04196106269955635,
      "learning_rate": 1.2331424936386769e-05,
      "loss": 0.3698,
      "step": 21700
    },
    {
      "epoch": 1.1529898218829517,
      "grad_norm": 42.93783950805664,
      "learning_rate": 1.2313754594288947e-05,
      "loss": 0.615,
      "step": 21750
    },
    {
      "epoch": 1.155640373197625,
      "grad_norm": 0.12268281728029251,
      "learning_rate": 1.2296084252191123e-05,
      "loss": 0.4339,
      "step": 21800
    },
    {
      "epoch": 1.1582909245122985,
      "grad_norm": 0.14519016444683075,
      "learning_rate": 1.2278413910093301e-05,
      "loss": 0.3025,
      "step": 21850
    },
    {
      "epoch": 1.160941475826972,
      "grad_norm": 0.061037637293338776,
      "learning_rate": 1.2260743567995477e-05,
      "loss": 0.1987,
      "step": 21900
    },
    {
      "epoch": 1.1635920271416456,
      "grad_norm": 0.2669963240623474,
      "learning_rate": 1.2243073225897655e-05,
      "loss": 0.3759,
      "step": 21950
    },
    {
      "epoch": 1.1662425784563188,
      "grad_norm": 0.08401039242744446,
      "learning_rate": 1.222540288379983e-05,
      "loss": 0.4982,
      "step": 22000
    },
    {
      "epoch": 1.1688931297709924,
      "grad_norm": 0.7054412961006165,
      "learning_rate": 1.220773254170201e-05,
      "loss": 0.1911,
      "step": 22050
    },
    {
      "epoch": 1.1715436810856659,
      "grad_norm": 0.10368093848228455,
      "learning_rate": 1.2190062199604185e-05,
      "loss": 0.4328,
      "step": 22100
    },
    {
      "epoch": 1.1741942324003394,
      "grad_norm": 46.11371994018555,
      "learning_rate": 1.2172391857506363e-05,
      "loss": 0.594,
      "step": 22150
    },
    {
      "epoch": 1.1768447837150127,
      "grad_norm": 255.77618408203125,
      "learning_rate": 1.2154721515408538e-05,
      "loss": 0.329,
      "step": 22200
    },
    {
      "epoch": 1.1794953350296862,
      "grad_norm": 84.79077911376953,
      "learning_rate": 1.2137051173310717e-05,
      "loss": 0.1833,
      "step": 22250
    },
    {
      "epoch": 1.1821458863443597,
      "grad_norm": 0.02429129183292389,
      "learning_rate": 1.2119380831212892e-05,
      "loss": 0.2732,
      "step": 22300
    },
    {
      "epoch": 1.184796437659033,
      "grad_norm": 0.08529569953680038,
      "learning_rate": 1.2101710489115071e-05,
      "loss": 0.2523,
      "step": 22350
    },
    {
      "epoch": 1.1874469889737065,
      "grad_norm": 15.756219863891602,
      "learning_rate": 1.2084040147017246e-05,
      "loss": 0.2925,
      "step": 22400
    },
    {
      "epoch": 1.19009754028838,
      "grad_norm": 1.6172126531600952,
      "learning_rate": 1.2066369804919425e-05,
      "loss": 0.3239,
      "step": 22450
    },
    {
      "epoch": 1.1927480916030535,
      "grad_norm": 0.009798599407076836,
      "learning_rate": 1.20486994628216e-05,
      "loss": 0.2665,
      "step": 22500
    },
    {
      "epoch": 1.1953986429177268,
      "grad_norm": 0.09668134152889252,
      "learning_rate": 1.2031029120723779e-05,
      "loss": 0.343,
      "step": 22550
    },
    {
      "epoch": 1.1980491942324003,
      "grad_norm": 0.028414128348231316,
      "learning_rate": 1.2013358778625954e-05,
      "loss": 0.6968,
      "step": 22600
    },
    {
      "epoch": 1.2006997455470738,
      "grad_norm": 43.11881637573242,
      "learning_rate": 1.1995688436528133e-05,
      "loss": 0.5041,
      "step": 22650
    },
    {
      "epoch": 1.2033502968617473,
      "grad_norm": 0.05948249250650406,
      "learning_rate": 1.1978018094430308e-05,
      "loss": 0.3852,
      "step": 22700
    },
    {
      "epoch": 1.2060008481764206,
      "grad_norm": 0.12330567091703415,
      "learning_rate": 1.1960347752332487e-05,
      "loss": 0.5144,
      "step": 22750
    },
    {
      "epoch": 1.2086513994910941,
      "grad_norm": 0.04926928132772446,
      "learning_rate": 1.1942677410234662e-05,
      "loss": 0.4329,
      "step": 22800
    },
    {
      "epoch": 1.2113019508057676,
      "grad_norm": 0.08786927908658981,
      "learning_rate": 1.192500706813684e-05,
      "loss": 0.357,
      "step": 22850
    },
    {
      "epoch": 1.2139525021204411,
      "grad_norm": 9.405667304992676,
      "learning_rate": 1.1907336726039016e-05,
      "loss": 0.2897,
      "step": 22900
    },
    {
      "epoch": 1.2166030534351144,
      "grad_norm": 0.01619281992316246,
      "learning_rate": 1.1889666383941195e-05,
      "loss": 0.4167,
      "step": 22950
    },
    {
      "epoch": 1.219253604749788,
      "grad_norm": 34.813865661621094,
      "learning_rate": 1.187199604184337e-05,
      "loss": 0.312,
      "step": 23000
    },
    {
      "epoch": 1.2219041560644615,
      "grad_norm": 0.1524806022644043,
      "learning_rate": 1.1854325699745549e-05,
      "loss": 0.3916,
      "step": 23050
    },
    {
      "epoch": 1.2245547073791347,
      "grad_norm": 0.012513690628111362,
      "learning_rate": 1.1836655357647726e-05,
      "loss": 0.0608,
      "step": 23100
    },
    {
      "epoch": 1.2272052586938083,
      "grad_norm": 35.942665100097656,
      "learning_rate": 1.1818985015549902e-05,
      "loss": 0.3823,
      "step": 23150
    },
    {
      "epoch": 1.2298558100084818,
      "grad_norm": 3.019031524658203,
      "learning_rate": 1.180131467345208e-05,
      "loss": 0.2021,
      "step": 23200
    },
    {
      "epoch": 1.2325063613231553,
      "grad_norm": 0.015930451452732086,
      "learning_rate": 1.1783644331354256e-05,
      "loss": 0.1932,
      "step": 23250
    },
    {
      "epoch": 1.2351569126378288,
      "grad_norm": 0.03754530847072601,
      "learning_rate": 1.1765973989256433e-05,
      "loss": 0.1966,
      "step": 23300
    },
    {
      "epoch": 1.237807463952502,
      "grad_norm": 0.10410137474536896,
      "learning_rate": 1.174830364715861e-05,
      "loss": 0.2305,
      "step": 23350
    },
    {
      "epoch": 1.2404580152671756,
      "grad_norm": 0.0270878653973341,
      "learning_rate": 1.1730633305060787e-05,
      "loss": 0.1972,
      "step": 23400
    },
    {
      "epoch": 1.243108566581849,
      "grad_norm": 0.055215395987033844,
      "learning_rate": 1.1712962962962964e-05,
      "loss": 0.1855,
      "step": 23450
    },
    {
      "epoch": 1.2457591178965224,
      "grad_norm": 0.2352556586265564,
      "learning_rate": 1.1695292620865141e-05,
      "loss": 0.3854,
      "step": 23500
    },
    {
      "epoch": 1.248409669211196,
      "grad_norm": 0.13514025509357452,
      "learning_rate": 1.1677622278767318e-05,
      "loss": 0.3649,
      "step": 23550
    },
    {
      "epoch": 1.2510602205258694,
      "grad_norm": 0.11538810282945633,
      "learning_rate": 1.1659951936669495e-05,
      "loss": 0.5539,
      "step": 23600
    },
    {
      "epoch": 1.253710771840543,
      "grad_norm": 0.030324308201670647,
      "learning_rate": 1.1642281594571672e-05,
      "loss": 0.2847,
      "step": 23650
    },
    {
      "epoch": 1.2563613231552162,
      "grad_norm": 0.05834343656897545,
      "learning_rate": 1.1624611252473849e-05,
      "loss": 0.5586,
      "step": 23700
    },
    {
      "epoch": 1.2590118744698897,
      "grad_norm": 4.736113548278809,
      "learning_rate": 1.1606940910376026e-05,
      "loss": 0.3366,
      "step": 23750
    },
    {
      "epoch": 1.2616624257845632,
      "grad_norm": 0.08914167433977127,
      "learning_rate": 1.1589270568278203e-05,
      "loss": 0.2305,
      "step": 23800
    },
    {
      "epoch": 1.2643129770992365,
      "grad_norm": 1.2630234956741333,
      "learning_rate": 1.157160022618038e-05,
      "loss": 0.3647,
      "step": 23850
    },
    {
      "epoch": 1.26696352841391,
      "grad_norm": 0.05594385787844658,
      "learning_rate": 1.1553929884082557e-05,
      "loss": 0.3039,
      "step": 23900
    },
    {
      "epoch": 1.2696140797285835,
      "grad_norm": 0.0436396487057209,
      "learning_rate": 1.1536259541984734e-05,
      "loss": 0.4178,
      "step": 23950
    },
    {
      "epoch": 1.272264631043257,
      "grad_norm": 0.12333423644304276,
      "learning_rate": 1.1518589199886911e-05,
      "loss": 0.3667,
      "step": 24000
    },
    {
      "epoch": 1.2749151823579306,
      "grad_norm": 23.576326370239258,
      "learning_rate": 1.1500918857789088e-05,
      "loss": 0.3995,
      "step": 24050
    },
    {
      "epoch": 1.2775657336726038,
      "grad_norm": 0.03175772354006767,
      "learning_rate": 1.1483248515691265e-05,
      "loss": 0.331,
      "step": 24100
    },
    {
      "epoch": 1.2802162849872774,
      "grad_norm": 279.1334533691406,
      "learning_rate": 1.1465578173593442e-05,
      "loss": 0.1711,
      "step": 24150
    },
    {
      "epoch": 1.2828668363019509,
      "grad_norm": 31.520870208740234,
      "learning_rate": 1.1447907831495619e-05,
      "loss": 0.5049,
      "step": 24200
    },
    {
      "epoch": 1.2855173876166242,
      "grad_norm": 0.0897635966539383,
      "learning_rate": 1.1430237489397796e-05,
      "loss": 0.1503,
      "step": 24250
    },
    {
      "epoch": 1.2881679389312977,
      "grad_norm": 0.04172782972455025,
      "learning_rate": 1.1412567147299973e-05,
      "loss": 0.1805,
      "step": 24300
    },
    {
      "epoch": 1.2908184902459712,
      "grad_norm": 0.22305648028850555,
      "learning_rate": 1.139489680520215e-05,
      "loss": 0.2759,
      "step": 24350
    },
    {
      "epoch": 1.2934690415606447,
      "grad_norm": 0.04634798318147659,
      "learning_rate": 1.1377226463104327e-05,
      "loss": 0.2232,
      "step": 24400
    },
    {
      "epoch": 1.2961195928753182,
      "grad_norm": 0.09301470965147018,
      "learning_rate": 1.1359556121006504e-05,
      "loss": 0.4566,
      "step": 24450
    },
    {
      "epoch": 1.2987701441899915,
      "grad_norm": 0.013560023158788681,
      "learning_rate": 1.134188577890868e-05,
      "loss": 0.3,
      "step": 24500
    },
    {
      "epoch": 1.301420695504665,
      "grad_norm": 0.09509722143411636,
      "learning_rate": 1.1324215436810857e-05,
      "loss": 0.355,
      "step": 24550
    },
    {
      "epoch": 1.3040712468193385,
      "grad_norm": 1.3700706958770752,
      "learning_rate": 1.1306545094713034e-05,
      "loss": 0.1106,
      "step": 24600
    },
    {
      "epoch": 1.3067217981340118,
      "grad_norm": 0.054779864847660065,
      "learning_rate": 1.1288874752615211e-05,
      "loss": 0.3316,
      "step": 24650
    },
    {
      "epoch": 1.3093723494486853,
      "grad_norm": 44.289710998535156,
      "learning_rate": 1.1271204410517388e-05,
      "loss": 0.2379,
      "step": 24700
    },
    {
      "epoch": 1.3120229007633588,
      "grad_norm": 0.18055090308189392,
      "learning_rate": 1.1253534068419565e-05,
      "loss": 0.4554,
      "step": 24750
    },
    {
      "epoch": 1.3146734520780323,
      "grad_norm": 49.06398010253906,
      "learning_rate": 1.1235863726321742e-05,
      "loss": 0.4571,
      "step": 24800
    },
    {
      "epoch": 1.3173240033927056,
      "grad_norm": 0.09226632118225098,
      "learning_rate": 1.121819338422392e-05,
      "loss": 0.11,
      "step": 24850
    },
    {
      "epoch": 1.3199745547073791,
      "grad_norm": 42.44157028198242,
      "learning_rate": 1.1200523042126096e-05,
      "loss": 0.4835,
      "step": 24900
    },
    {
      "epoch": 1.3226251060220526,
      "grad_norm": 48.74794006347656,
      "learning_rate": 1.1182852700028273e-05,
      "loss": 0.2718,
      "step": 24950
    },
    {
      "epoch": 1.325275657336726,
      "grad_norm": 0.08715556561946869,
      "learning_rate": 1.116518235793045e-05,
      "loss": 0.5922,
      "step": 25000
    },
    {
      "epoch": 1.3279262086513994,
      "grad_norm": 0.031264759600162506,
      "learning_rate": 1.1147512015832627e-05,
      "loss": 0.0919,
      "step": 25050
    },
    {
      "epoch": 1.330576759966073,
      "grad_norm": 0.0511893704533577,
      "learning_rate": 1.1129841673734804e-05,
      "loss": 0.3295,
      "step": 25100
    },
    {
      "epoch": 1.3332273112807465,
      "grad_norm": 0.18814197182655334,
      "learning_rate": 1.1112171331636981e-05,
      "loss": 0.5557,
      "step": 25150
    },
    {
      "epoch": 1.33587786259542,
      "grad_norm": 26.031330108642578,
      "learning_rate": 1.1094500989539158e-05,
      "loss": 0.2734,
      "step": 25200
    },
    {
      "epoch": 1.3385284139100933,
      "grad_norm": 32.182559967041016,
      "learning_rate": 1.1076830647441335e-05,
      "loss": 0.3961,
      "step": 25250
    },
    {
      "epoch": 1.3411789652247668,
      "grad_norm": 0.06686954200267792,
      "learning_rate": 1.1059160305343512e-05,
      "loss": 0.3432,
      "step": 25300
    },
    {
      "epoch": 1.3438295165394403,
      "grad_norm": 0.12183386832475662,
      "learning_rate": 1.1041489963245689e-05,
      "loss": 0.3035,
      "step": 25350
    },
    {
      "epoch": 1.3464800678541136,
      "grad_norm": 0.014794105663895607,
      "learning_rate": 1.1023819621147866e-05,
      "loss": 0.3093,
      "step": 25400
    },
    {
      "epoch": 1.349130619168787,
      "grad_norm": 0.03270598128437996,
      "learning_rate": 1.1006149279050043e-05,
      "loss": 0.3613,
      "step": 25450
    },
    {
      "epoch": 1.3517811704834606,
      "grad_norm": 0.019897975027561188,
      "learning_rate": 1.098847893695222e-05,
      "loss": 0.2263,
      "step": 25500
    },
    {
      "epoch": 1.354431721798134,
      "grad_norm": 0.1614912748336792,
      "learning_rate": 1.0970808594854397e-05,
      "loss": 0.3114,
      "step": 25550
    },
    {
      "epoch": 1.3570822731128076,
      "grad_norm": 0.11852365732192993,
      "learning_rate": 1.0953138252756574e-05,
      "loss": 0.5372,
      "step": 25600
    },
    {
      "epoch": 1.359732824427481,
      "grad_norm": 0.2509644329547882,
      "learning_rate": 1.093546791065875e-05,
      "loss": 0.3139,
      "step": 25650
    },
    {
      "epoch": 1.3623833757421544,
      "grad_norm": 0.42777079343795776,
      "learning_rate": 1.0917797568560928e-05,
      "loss": 0.2942,
      "step": 25700
    },
    {
      "epoch": 1.3650339270568277,
      "grad_norm": 0.30322402715682983,
      "learning_rate": 1.0900127226463105e-05,
      "loss": 0.4075,
      "step": 25750
    },
    {
      "epoch": 1.3676844783715012,
      "grad_norm": 0.07234766334295273,
      "learning_rate": 1.0882456884365282e-05,
      "loss": 0.4705,
      "step": 25800
    },
    {
      "epoch": 1.3703350296861747,
      "grad_norm": 0.0243290513753891,
      "learning_rate": 1.0864786542267459e-05,
      "loss": 0.1895,
      "step": 25850
    },
    {
      "epoch": 1.3729855810008482,
      "grad_norm": 0.7657188177108765,
      "learning_rate": 1.0847116200169635e-05,
      "loss": 0.3797,
      "step": 25900
    },
    {
      "epoch": 1.3756361323155217,
      "grad_norm": 0.03241077437996864,
      "learning_rate": 1.0829445858071814e-05,
      "loss": 0.1752,
      "step": 25950
    },
    {
      "epoch": 1.378286683630195,
      "grad_norm": 0.037945494055747986,
      "learning_rate": 1.081177551597399e-05,
      "loss": 0.2937,
      "step": 26000
    },
    {
      "epoch": 1.3809372349448685,
      "grad_norm": 0.023255188018083572,
      "learning_rate": 1.0794105173876168e-05,
      "loss": 0.6281,
      "step": 26050
    },
    {
      "epoch": 1.383587786259542,
      "grad_norm": 0.043590448796749115,
      "learning_rate": 1.0776434831778343e-05,
      "loss": 0.1211,
      "step": 26100
    },
    {
      "epoch": 1.3862383375742153,
      "grad_norm": 0.04698336124420166,
      "learning_rate": 1.0758764489680522e-05,
      "loss": 0.087,
      "step": 26150
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.32938992977142334,
      "learning_rate": 1.0741094147582697e-05,
      "loss": 0.3097,
      "step": 26200
    },
    {
      "epoch": 1.3915394402035624,
      "grad_norm": 0.1498878300189972,
      "learning_rate": 1.0723423805484876e-05,
      "loss": 0.5316,
      "step": 26250
    },
    {
      "epoch": 1.3941899915182359,
      "grad_norm": 0.08918055891990662,
      "learning_rate": 1.0705753463387051e-05,
      "loss": 0.3692,
      "step": 26300
    },
    {
      "epoch": 1.3968405428329094,
      "grad_norm": 0.08853178471326828,
      "learning_rate": 1.068808312128923e-05,
      "loss": 0.4497,
      "step": 26350
    },
    {
      "epoch": 1.3994910941475827,
      "grad_norm": 6.088857173919678,
      "learning_rate": 1.0670412779191405e-05,
      "loss": 0.2112,
      "step": 26400
    },
    {
      "epoch": 1.4021416454622562,
      "grad_norm": 0.04287125915288925,
      "learning_rate": 1.0652742437093584e-05,
      "loss": 0.2208,
      "step": 26450
    },
    {
      "epoch": 1.4047921967769297,
      "grad_norm": 0.04945378378033638,
      "learning_rate": 1.0635072094995759e-05,
      "loss": 0.338,
      "step": 26500
    },
    {
      "epoch": 1.407442748091603,
      "grad_norm": 33.78754425048828,
      "learning_rate": 1.0617401752897938e-05,
      "loss": 0.41,
      "step": 26550
    },
    {
      "epoch": 1.4100932994062765,
      "grad_norm": 0.06280959397554398,
      "learning_rate": 1.0599731410800113e-05,
      "loss": 0.2411,
      "step": 26600
    },
    {
      "epoch": 1.41274385072095,
      "grad_norm": 0.054620884358882904,
      "learning_rate": 1.0582061068702292e-05,
      "loss": 0.4537,
      "step": 26650
    },
    {
      "epoch": 1.4153944020356235,
      "grad_norm": 0.0213156770914793,
      "learning_rate": 1.0564390726604467e-05,
      "loss": 0.3827,
      "step": 26700
    },
    {
      "epoch": 1.4180449533502968,
      "grad_norm": 0.05421452969312668,
      "learning_rate": 1.0546720384506646e-05,
      "loss": 0.4638,
      "step": 26750
    },
    {
      "epoch": 1.4206955046649703,
      "grad_norm": 0.028588419780135155,
      "learning_rate": 1.052905004240882e-05,
      "loss": 0.2525,
      "step": 26800
    },
    {
      "epoch": 1.4233460559796438,
      "grad_norm": 0.06336416304111481,
      "learning_rate": 1.0511379700311e-05,
      "loss": 0.2533,
      "step": 26850
    },
    {
      "epoch": 1.425996607294317,
      "grad_norm": 0.13720177114009857,
      "learning_rate": 1.0493709358213175e-05,
      "loss": 0.4071,
      "step": 26900
    },
    {
      "epoch": 1.4286471586089906,
      "grad_norm": 15.383088111877441,
      "learning_rate": 1.0476039016115353e-05,
      "loss": 0.4125,
      "step": 26950
    },
    {
      "epoch": 1.4312977099236641,
      "grad_norm": 0.0898381918668747,
      "learning_rate": 1.0458368674017529e-05,
      "loss": 0.3074,
      "step": 27000
    },
    {
      "epoch": 1.4339482612383376,
      "grad_norm": 0.04394083097577095,
      "learning_rate": 1.0440698331919707e-05,
      "loss": 0.3761,
      "step": 27050
    },
    {
      "epoch": 1.4365988125530111,
      "grad_norm": 0.14305739104747772,
      "learning_rate": 1.0423027989821883e-05,
      "loss": 0.2692,
      "step": 27100
    },
    {
      "epoch": 1.4392493638676844,
      "grad_norm": 0.022686906158924103,
      "learning_rate": 1.0405357647724061e-05,
      "loss": 0.2384,
      "step": 27150
    },
    {
      "epoch": 1.441899915182358,
      "grad_norm": 0.10222116857767105,
      "learning_rate": 1.0387687305626237e-05,
      "loss": 0.4058,
      "step": 27200
    },
    {
      "epoch": 1.4445504664970314,
      "grad_norm": 0.17712929844856262,
      "learning_rate": 1.0370016963528415e-05,
      "loss": 0.3657,
      "step": 27250
    },
    {
      "epoch": 1.4472010178117047,
      "grad_norm": 0.21850185096263885,
      "learning_rate": 1.035234662143059e-05,
      "loss": 0.4694,
      "step": 27300
    },
    {
      "epoch": 1.4498515691263782,
      "grad_norm": 0.03305457532405853,
      "learning_rate": 1.0334676279332769e-05,
      "loss": 0.3076,
      "step": 27350
    },
    {
      "epoch": 1.4525021204410518,
      "grad_norm": 0.07863391935825348,
      "learning_rate": 1.0317005937234944e-05,
      "loss": 0.2992,
      "step": 27400
    },
    {
      "epoch": 1.4551526717557253,
      "grad_norm": 1.992372751235962,
      "learning_rate": 1.0299335595137123e-05,
      "loss": 0.489,
      "step": 27450
    },
    {
      "epoch": 1.4578032230703988,
      "grad_norm": 0.1873895674943924,
      "learning_rate": 1.0281665253039298e-05,
      "loss": 0.3504,
      "step": 27500
    },
    {
      "epoch": 1.460453774385072,
      "grad_norm": 0.08008167147636414,
      "learning_rate": 1.0263994910941477e-05,
      "loss": 0.1757,
      "step": 27550
    },
    {
      "epoch": 1.4631043256997456,
      "grad_norm": 19.66283416748047,
      "learning_rate": 1.0246324568843652e-05,
      "loss": 0.5927,
      "step": 27600
    },
    {
      "epoch": 1.4657548770144189,
      "grad_norm": 0.18243935704231262,
      "learning_rate": 1.0228654226745831e-05,
      "loss": 0.584,
      "step": 27650
    },
    {
      "epoch": 1.4684054283290924,
      "grad_norm": 0.09142538905143738,
      "learning_rate": 1.0210983884648006e-05,
      "loss": 0.3082,
      "step": 27700
    },
    {
      "epoch": 1.4710559796437659,
      "grad_norm": 0.015386414714157581,
      "learning_rate": 1.0193313542550185e-05,
      "loss": 0.1241,
      "step": 27750
    },
    {
      "epoch": 1.4737065309584394,
      "grad_norm": 63.89597702026367,
      "learning_rate": 1.017564320045236e-05,
      "loss": 0.4781,
      "step": 27800
    },
    {
      "epoch": 1.476357082273113,
      "grad_norm": 0.03959048539400101,
      "learning_rate": 1.0157972858354539e-05,
      "loss": 0.2085,
      "step": 27850
    },
    {
      "epoch": 1.4790076335877862,
      "grad_norm": 0.0401528924703598,
      "learning_rate": 1.0140302516256714e-05,
      "loss": 0.2613,
      "step": 27900
    },
    {
      "epoch": 1.4816581849024597,
      "grad_norm": 0.5214510560035706,
      "learning_rate": 1.0122632174158893e-05,
      "loss": 0.587,
      "step": 27950
    },
    {
      "epoch": 1.4843087362171332,
      "grad_norm": 0.01670663058757782,
      "learning_rate": 1.0104961832061068e-05,
      "loss": 0.0915,
      "step": 28000
    },
    {
      "epoch": 1.4869592875318065,
      "grad_norm": 0.01899544894695282,
      "learning_rate": 1.0087291489963247e-05,
      "loss": 0.3443,
      "step": 28050
    },
    {
      "epoch": 1.48960983884648,
      "grad_norm": 0.17758618295192719,
      "learning_rate": 1.0069621147865422e-05,
      "loss": 0.3165,
      "step": 28100
    },
    {
      "epoch": 1.4922603901611535,
      "grad_norm": 0.0613335445523262,
      "learning_rate": 1.00519508057676e-05,
      "loss": 0.1923,
      "step": 28150
    },
    {
      "epoch": 1.494910941475827,
      "grad_norm": 5.050915241241455,
      "learning_rate": 1.0034280463669776e-05,
      "loss": 0.5996,
      "step": 28200
    },
    {
      "epoch": 1.4975614927905005,
      "grad_norm": 0.021927667781710625,
      "learning_rate": 1.0016610121571954e-05,
      "loss": 0.1352,
      "step": 28250
    },
    {
      "epoch": 1.5002120441051738,
      "grad_norm": 0.14636074006557465,
      "learning_rate": 9.998939779474131e-06,
      "loss": 0.2399,
      "step": 28300
    },
    {
      "epoch": 1.5028625954198473,
      "grad_norm": 0.021431582048535347,
      "learning_rate": 9.981269437376308e-06,
      "loss": 0.3771,
      "step": 28350
    },
    {
      "epoch": 1.5055131467345206,
      "grad_norm": 0.1087261289358139,
      "learning_rate": 9.963599095278485e-06,
      "loss": 0.4868,
      "step": 28400
    },
    {
      "epoch": 1.5081636980491941,
      "grad_norm": 0.04319018870592117,
      "learning_rate": 9.945928753180662e-06,
      "loss": 0.0442,
      "step": 28450
    },
    {
      "epoch": 1.5108142493638677,
      "grad_norm": 0.027004294097423553,
      "learning_rate": 9.92825841108284e-06,
      "loss": 0.3844,
      "step": 28500
    },
    {
      "epoch": 1.5134648006785412,
      "grad_norm": 0.0788475051522255,
      "learning_rate": 9.910588068985016e-06,
      "loss": 0.3332,
      "step": 28550
    },
    {
      "epoch": 1.5161153519932147,
      "grad_norm": 0.3420286476612091,
      "learning_rate": 9.892917726887193e-06,
      "loss": 0.4155,
      "step": 28600
    },
    {
      "epoch": 1.5187659033078882,
      "grad_norm": 0.015834948047995567,
      "learning_rate": 9.87524738478937e-06,
      "loss": 0.2137,
      "step": 28650
    },
    {
      "epoch": 1.5214164546225615,
      "grad_norm": 0.014682110399007797,
      "learning_rate": 9.857577042691547e-06,
      "loss": 0.2411,
      "step": 28700
    },
    {
      "epoch": 1.524067005937235,
      "grad_norm": 0.03659652918577194,
      "learning_rate": 9.839906700593724e-06,
      "loss": 0.3638,
      "step": 28750
    },
    {
      "epoch": 1.5267175572519083,
      "grad_norm": 0.12259943783283234,
      "learning_rate": 9.822236358495901e-06,
      "loss": 0.2511,
      "step": 28800
    },
    {
      "epoch": 1.5293681085665818,
      "grad_norm": 0.40608182549476624,
      "learning_rate": 9.804566016398078e-06,
      "loss": 0.5203,
      "step": 28850
    },
    {
      "epoch": 1.5320186598812553,
      "grad_norm": 0.10547200590372086,
      "learning_rate": 9.786895674300255e-06,
      "loss": 0.314,
      "step": 28900
    },
    {
      "epoch": 1.5346692111959288,
      "grad_norm": 0.0637466311454773,
      "learning_rate": 9.769225332202432e-06,
      "loss": 0.4333,
      "step": 28950
    },
    {
      "epoch": 1.5373197625106023,
      "grad_norm": 0.024367548525333405,
      "learning_rate": 9.751554990104609e-06,
      "loss": 0.3635,
      "step": 29000
    },
    {
      "epoch": 1.5399703138252756,
      "grad_norm": 0.02534978650510311,
      "learning_rate": 9.733884648006786e-06,
      "loss": 0.3677,
      "step": 29050
    },
    {
      "epoch": 1.5426208651399491,
      "grad_norm": 0.3422290086746216,
      "learning_rate": 9.716214305908963e-06,
      "loss": 0.3365,
      "step": 29100
    },
    {
      "epoch": 1.5452714164546224,
      "grad_norm": 36.82525634765625,
      "learning_rate": 9.69854396381114e-06,
      "loss": 0.4207,
      "step": 29150
    },
    {
      "epoch": 1.547921967769296,
      "grad_norm": 0.039956558495759964,
      "learning_rate": 9.680873621713317e-06,
      "loss": 0.3443,
      "step": 29200
    },
    {
      "epoch": 1.5505725190839694,
      "grad_norm": 0.1372595876455307,
      "learning_rate": 9.663203279615494e-06,
      "loss": 0.4879,
      "step": 29250
    },
    {
      "epoch": 1.553223070398643,
      "grad_norm": 18.882240295410156,
      "learning_rate": 9.64553293751767e-06,
      "loss": 0.4004,
      "step": 29300
    },
    {
      "epoch": 1.5558736217133164,
      "grad_norm": 0.03061641938984394,
      "learning_rate": 9.627862595419848e-06,
      "loss": 0.1469,
      "step": 29350
    },
    {
      "epoch": 1.55852417302799,
      "grad_norm": 0.11850590258836746,
      "learning_rate": 9.610192253322025e-06,
      "loss": 0.3622,
      "step": 29400
    },
    {
      "epoch": 1.5611747243426632,
      "grad_norm": 0.0374755859375,
      "learning_rate": 9.592521911224202e-06,
      "loss": 0.3956,
      "step": 29450
    },
    {
      "epoch": 1.5638252756573368,
      "grad_norm": 24.015830993652344,
      "learning_rate": 9.574851569126379e-06,
      "loss": 0.3436,
      "step": 29500
    },
    {
      "epoch": 1.56647582697201,
      "grad_norm": 0.1702558547258377,
      "learning_rate": 9.557181227028556e-06,
      "loss": 0.1624,
      "step": 29550
    },
    {
      "epoch": 1.5691263782866836,
      "grad_norm": 0.01792062073945999,
      "learning_rate": 9.539510884930732e-06,
      "loss": 0.1238,
      "step": 29600
    },
    {
      "epoch": 1.571776929601357,
      "grad_norm": 0.12131380289793015,
      "learning_rate": 9.52184054283291e-06,
      "loss": 0.3977,
      "step": 29650
    },
    {
      "epoch": 1.5744274809160306,
      "grad_norm": 0.032254502177238464,
      "learning_rate": 9.504170200735086e-06,
      "loss": 0.3515,
      "step": 29700
    },
    {
      "epoch": 1.577078032230704,
      "grad_norm": 0.02872856706380844,
      "learning_rate": 9.486499858637263e-06,
      "loss": 0.2741,
      "step": 29750
    },
    {
      "epoch": 1.5797285835453776,
      "grad_norm": 0.17281953990459442,
      "learning_rate": 9.46882951653944e-06,
      "loss": 0.7332,
      "step": 29800
    },
    {
      "epoch": 1.5823791348600509,
      "grad_norm": 0.06349748373031616,
      "learning_rate": 9.451159174441617e-06,
      "loss": 0.3387,
      "step": 29850
    },
    {
      "epoch": 1.5850296861747244,
      "grad_norm": 0.0876411572098732,
      "learning_rate": 9.433488832343794e-06,
      "loss": 0.2549,
      "step": 29900
    },
    {
      "epoch": 1.5876802374893977,
      "grad_norm": 0.16268517076969147,
      "learning_rate": 9.415818490245971e-06,
      "loss": 0.3205,
      "step": 29950
    },
    {
      "epoch": 1.5903307888040712,
      "grad_norm": 6.260638236999512,
      "learning_rate": 9.398148148148148e-06,
      "loss": 0.6691,
      "step": 30000
    },
    {
      "epoch": 1.5929813401187447,
      "grad_norm": 0.19508087635040283,
      "learning_rate": 9.380477806050325e-06,
      "loss": 0.0819,
      "step": 30050
    },
    {
      "epoch": 1.5956318914334182,
      "grad_norm": 0.09240840375423431,
      "learning_rate": 9.362807463952502e-06,
      "loss": 0.5276,
      "step": 30100
    },
    {
      "epoch": 1.5982824427480917,
      "grad_norm": 0.025378666818141937,
      "learning_rate": 9.345137121854679e-06,
      "loss": 0.3949,
      "step": 30150
    },
    {
      "epoch": 1.600932994062765,
      "grad_norm": 0.09110156446695328,
      "learning_rate": 9.327466779756856e-06,
      "loss": 0.1299,
      "step": 30200
    },
    {
      "epoch": 1.6035835453774385,
      "grad_norm": 0.13356296718120575,
      "learning_rate": 9.309796437659033e-06,
      "loss": 0.3724,
      "step": 30250
    },
    {
      "epoch": 1.6062340966921118,
      "grad_norm": 0.019970638677477837,
      "learning_rate": 9.292126095561212e-06,
      "loss": 0.3397,
      "step": 30300
    },
    {
      "epoch": 1.6088846480067853,
      "grad_norm": 0.1689436435699463,
      "learning_rate": 9.274455753463389e-06,
      "loss": 0.3911,
      "step": 30350
    },
    {
      "epoch": 1.6115351993214588,
      "grad_norm": 0.0373455286026001,
      "learning_rate": 9.256785411365566e-06,
      "loss": 0.1621,
      "step": 30400
    },
    {
      "epoch": 1.6141857506361323,
      "grad_norm": 0.11702905595302582,
      "learning_rate": 9.239115069267743e-06,
      "loss": 0.6047,
      "step": 30450
    },
    {
      "epoch": 1.6168363019508059,
      "grad_norm": 0.042264871299266815,
      "learning_rate": 9.22144472716992e-06,
      "loss": 0.3776,
      "step": 30500
    },
    {
      "epoch": 1.6194868532654794,
      "grad_norm": 0.09385214000940323,
      "learning_rate": 9.203774385072096e-06,
      "loss": 0.4162,
      "step": 30550
    },
    {
      "epoch": 1.6221374045801527,
      "grad_norm": 4.203131675720215,
      "learning_rate": 9.186104042974273e-06,
      "loss": 0.414,
      "step": 30600
    },
    {
      "epoch": 1.6247879558948262,
      "grad_norm": 0.0699373334646225,
      "learning_rate": 9.16843370087645e-06,
      "loss": 0.3717,
      "step": 30650
    },
    {
      "epoch": 1.6274385072094995,
      "grad_norm": 0.3899974822998047,
      "learning_rate": 9.150763358778627e-06,
      "loss": 0.333,
      "step": 30700
    },
    {
      "epoch": 1.630089058524173,
      "grad_norm": 0.06421665102243423,
      "learning_rate": 9.133093016680804e-06,
      "loss": 0.3493,
      "step": 30750
    },
    {
      "epoch": 1.6327396098388465,
      "grad_norm": 0.029337875545024872,
      "learning_rate": 9.115422674582981e-06,
      "loss": 0.3505,
      "step": 30800
    },
    {
      "epoch": 1.63539016115352,
      "grad_norm": 0.14663611352443695,
      "learning_rate": 9.097752332485158e-06,
      "loss": 0.5436,
      "step": 30850
    },
    {
      "epoch": 1.6380407124681935,
      "grad_norm": 0.4034942090511322,
      "learning_rate": 9.080081990387335e-06,
      "loss": 0.3523,
      "step": 30900
    },
    {
      "epoch": 1.6406912637828668,
      "grad_norm": 0.08814654499292374,
      "learning_rate": 9.062411648289512e-06,
      "loss": 0.3088,
      "step": 30950
    },
    {
      "epoch": 1.6433418150975403,
      "grad_norm": 0.0781223401427269,
      "learning_rate": 9.04474130619169e-06,
      "loss": 0.1819,
      "step": 31000
    },
    {
      "epoch": 1.6459923664122136,
      "grad_norm": 0.11103615909814835,
      "learning_rate": 9.027070964093866e-06,
      "loss": 0.4784,
      "step": 31050
    },
    {
      "epoch": 1.648642917726887,
      "grad_norm": 0.16234412789344788,
      "learning_rate": 9.009400621996043e-06,
      "loss": 0.388,
      "step": 31100
    },
    {
      "epoch": 1.6512934690415606,
      "grad_norm": 0.03745602071285248,
      "learning_rate": 8.99173027989822e-06,
      "loss": 0.4564,
      "step": 31150
    },
    {
      "epoch": 1.6539440203562341,
      "grad_norm": 115.47515106201172,
      "learning_rate": 8.974059937800397e-06,
      "loss": 0.1043,
      "step": 31200
    },
    {
      "epoch": 1.6565945716709076,
      "grad_norm": 48.15517807006836,
      "learning_rate": 8.956389595702574e-06,
      "loss": 0.4933,
      "step": 31250
    },
    {
      "epoch": 1.6592451229855811,
      "grad_norm": 1.4600380659103394,
      "learning_rate": 8.938719253604751e-06,
      "loss": 0.2235,
      "step": 31300
    },
    {
      "epoch": 1.6618956743002544,
      "grad_norm": 43.67667007446289,
      "learning_rate": 8.921048911506928e-06,
      "loss": 0.2353,
      "step": 31350
    },
    {
      "epoch": 1.664546225614928,
      "grad_norm": 0.012548811733722687,
      "learning_rate": 8.903378569409105e-06,
      "loss": 0.2223,
      "step": 31400
    },
    {
      "epoch": 1.6671967769296012,
      "grad_norm": 0.1653517335653305,
      "learning_rate": 8.885708227311282e-06,
      "loss": 0.1531,
      "step": 31450
    },
    {
      "epoch": 1.6698473282442747,
      "grad_norm": 0.12539063394069672,
      "learning_rate": 8.868037885213459e-06,
      "loss": 0.2863,
      "step": 31500
    },
    {
      "epoch": 1.6724978795589482,
      "grad_norm": 0.021549900993704796,
      "learning_rate": 8.850367543115636e-06,
      "loss": 0.3984,
      "step": 31550
    },
    {
      "epoch": 1.6751484308736218,
      "grad_norm": 0.02284828945994377,
      "learning_rate": 8.832697201017813e-06,
      "loss": 0.0559,
      "step": 31600
    },
    {
      "epoch": 1.6777989821882953,
      "grad_norm": 0.045430272817611694,
      "learning_rate": 8.81502685891999e-06,
      "loss": 0.2238,
      "step": 31650
    },
    {
      "epoch": 1.6804495335029688,
      "grad_norm": 9.807538986206055,
      "learning_rate": 8.797356516822167e-06,
      "loss": 0.3732,
      "step": 31700
    },
    {
      "epoch": 1.683100084817642,
      "grad_norm": 0.06305398046970367,
      "learning_rate": 8.779686174724344e-06,
      "loss": 0.3792,
      "step": 31750
    },
    {
      "epoch": 1.6857506361323156,
      "grad_norm": 0.07683319598436356,
      "learning_rate": 8.76201583262652e-06,
      "loss": 0.1598,
      "step": 31800
    },
    {
      "epoch": 1.6884011874469889,
      "grad_norm": 0.09139282256364822,
      "learning_rate": 8.744345490528698e-06,
      "loss": 0.1928,
      "step": 31850
    },
    {
      "epoch": 1.6910517387616624,
      "grad_norm": 0.4552466571331024,
      "learning_rate": 8.726675148430875e-06,
      "loss": 0.5287,
      "step": 31900
    },
    {
      "epoch": 1.6937022900763359,
      "grad_norm": 0.027807217091321945,
      "learning_rate": 8.709004806333051e-06,
      "loss": 0.2942,
      "step": 31950
    },
    {
      "epoch": 1.6963528413910094,
      "grad_norm": 0.15166237950325012,
      "learning_rate": 8.691334464235228e-06,
      "loss": 0.3535,
      "step": 32000
    },
    {
      "epoch": 1.699003392705683,
      "grad_norm": 0.04590117186307907,
      "learning_rate": 8.673664122137405e-06,
      "loss": 0.2642,
      "step": 32050
    },
    {
      "epoch": 1.7016539440203562,
      "grad_norm": 0.021300623193383217,
      "learning_rate": 8.655993780039582e-06,
      "loss": 0.3036,
      "step": 32100
    },
    {
      "epoch": 1.7043044953350297,
      "grad_norm": 0.040204256772994995,
      "learning_rate": 8.63832343794176e-06,
      "loss": 0.3221,
      "step": 32150
    },
    {
      "epoch": 1.706955046649703,
      "grad_norm": 47.489952087402344,
      "learning_rate": 8.620653095843936e-06,
      "loss": 0.3991,
      "step": 32200
    },
    {
      "epoch": 1.7096055979643765,
      "grad_norm": 4.836695671081543,
      "learning_rate": 8.602982753746113e-06,
      "loss": 0.1228,
      "step": 32250
    },
    {
      "epoch": 1.71225614927905,
      "grad_norm": 0.0401652529835701,
      "learning_rate": 8.58531241164829e-06,
      "loss": 0.3728,
      "step": 32300
    },
    {
      "epoch": 1.7149067005937235,
      "grad_norm": 0.02086852863430977,
      "learning_rate": 8.567642069550467e-06,
      "loss": 0.0628,
      "step": 32350
    },
    {
      "epoch": 1.717557251908397,
      "grad_norm": 0.0938546285033226,
      "learning_rate": 8.549971727452644e-06,
      "loss": 0.3968,
      "step": 32400
    },
    {
      "epoch": 1.7202078032230705,
      "grad_norm": 0.07899650931358337,
      "learning_rate": 8.532301385354821e-06,
      "loss": 0.5659,
      "step": 32450
    },
    {
      "epoch": 1.7228583545377438,
      "grad_norm": 0.1247420385479927,
      "learning_rate": 8.514631043256998e-06,
      "loss": 0.523,
      "step": 32500
    },
    {
      "epoch": 1.7255089058524173,
      "grad_norm": 0.0627526193857193,
      "learning_rate": 8.496960701159175e-06,
      "loss": 0.4052,
      "step": 32550
    },
    {
      "epoch": 1.7281594571670906,
      "grad_norm": 0.3252658545970917,
      "learning_rate": 8.479290359061352e-06,
      "loss": 0.1738,
      "step": 32600
    },
    {
      "epoch": 1.7308100084817641,
      "grad_norm": 0.01899625174701214,
      "learning_rate": 8.461620016963529e-06,
      "loss": 0.4428,
      "step": 32650
    },
    {
      "epoch": 1.7334605597964376,
      "grad_norm": 0.16219918429851532,
      "learning_rate": 8.443949674865706e-06,
      "loss": 0.4157,
      "step": 32700
    },
    {
      "epoch": 1.7361111111111112,
      "grad_norm": 0.05424325913190842,
      "learning_rate": 8.426279332767883e-06,
      "loss": 0.1747,
      "step": 32750
    },
    {
      "epoch": 1.7387616624257847,
      "grad_norm": 0.18378405272960663,
      "learning_rate": 8.40860899067006e-06,
      "loss": 0.3156,
      "step": 32800
    },
    {
      "epoch": 1.7414122137404582,
      "grad_norm": 0.09331854432821274,
      "learning_rate": 8.390938648572237e-06,
      "loss": 0.297,
      "step": 32850
    },
    {
      "epoch": 1.7440627650551315,
      "grad_norm": 0.045339275151491165,
      "learning_rate": 8.373268306474414e-06,
      "loss": 0.2532,
      "step": 32900
    },
    {
      "epoch": 1.7467133163698048,
      "grad_norm": 0.3533534109592438,
      "learning_rate": 8.35559796437659e-06,
      "loss": 0.4235,
      "step": 32950
    },
    {
      "epoch": 1.7493638676844783,
      "grad_norm": 0.19692961871623993,
      "learning_rate": 8.337927622278768e-06,
      "loss": 0.3554,
      "step": 33000
    },
    {
      "epoch": 1.7520144189991518,
      "grad_norm": 0.041876811534166336,
      "learning_rate": 8.320257280180945e-06,
      "loss": 0.2833,
      "step": 33050
    },
    {
      "epoch": 1.7546649703138253,
      "grad_norm": 29.393983840942383,
      "learning_rate": 8.302586938083122e-06,
      "loss": 0.3832,
      "step": 33100
    },
    {
      "epoch": 1.7573155216284988,
      "grad_norm": 0.021512337028980255,
      "learning_rate": 8.284916595985299e-06,
      "loss": 0.2936,
      "step": 33150
    },
    {
      "epoch": 1.7599660729431723,
      "grad_norm": 0.0649576187133789,
      "learning_rate": 8.267246253887477e-06,
      "loss": 0.5903,
      "step": 33200
    },
    {
      "epoch": 1.7626166242578456,
      "grad_norm": 24.532289505004883,
      "learning_rate": 8.249575911789654e-06,
      "loss": 0.3408,
      "step": 33250
    },
    {
      "epoch": 1.765267175572519,
      "grad_norm": 0.42074447870254517,
      "learning_rate": 8.231905569691831e-06,
      "loss": 0.3453,
      "step": 33300
    },
    {
      "epoch": 1.7679177268871924,
      "grad_norm": 0.025715604424476624,
      "learning_rate": 8.214235227594008e-06,
      "loss": 0.3368,
      "step": 33350
    },
    {
      "epoch": 1.770568278201866,
      "grad_norm": 0.04741843044757843,
      "learning_rate": 8.196564885496185e-06,
      "loss": 0.3401,
      "step": 33400
    },
    {
      "epoch": 1.7732188295165394,
      "grad_norm": 39.10630798339844,
      "learning_rate": 8.178894543398362e-06,
      "loss": 0.1924,
      "step": 33450
    },
    {
      "epoch": 1.775869380831213,
      "grad_norm": 0.07177218794822693,
      "learning_rate": 8.161224201300539e-06,
      "loss": 0.1487,
      "step": 33500
    },
    {
      "epoch": 1.7785199321458864,
      "grad_norm": 0.3069717586040497,
      "learning_rate": 8.143553859202716e-06,
      "loss": 0.4808,
      "step": 33550
    },
    {
      "epoch": 1.78117048346056,
      "grad_norm": 0.0977882370352745,
      "learning_rate": 8.125883517104893e-06,
      "loss": 0.2978,
      "step": 33600
    },
    {
      "epoch": 1.7838210347752332,
      "grad_norm": 0.058008305728435516,
      "learning_rate": 8.10821317500707e-06,
      "loss": 0.3031,
      "step": 33650
    },
    {
      "epoch": 1.7864715860899067,
      "grad_norm": 0.10819420218467712,
      "learning_rate": 8.090542832909247e-06,
      "loss": 0.3398,
      "step": 33700
    },
    {
      "epoch": 1.78912213740458,
      "grad_norm": 0.02679566480219364,
      "learning_rate": 8.072872490811424e-06,
      "loss": 0.238,
      "step": 33750
    },
    {
      "epoch": 1.7917726887192535,
      "grad_norm": 0.02042725682258606,
      "learning_rate": 8.0552021487136e-06,
      "loss": 0.2281,
      "step": 33800
    },
    {
      "epoch": 1.794423240033927,
      "grad_norm": 0.0466928705573082,
      "learning_rate": 8.037531806615778e-06,
      "loss": 0.4566,
      "step": 33850
    },
    {
      "epoch": 1.7970737913486006,
      "grad_norm": 15.561620712280273,
      "learning_rate": 8.019861464517955e-06,
      "loss": 0.2379,
      "step": 33900
    },
    {
      "epoch": 1.799724342663274,
      "grad_norm": 0.0322868786752224,
      "learning_rate": 8.002191122420132e-06,
      "loss": 0.3446,
      "step": 33950
    },
    {
      "epoch": 1.8023748939779474,
      "grad_norm": 0.05178465321660042,
      "learning_rate": 7.984520780322309e-06,
      "loss": 0.4176,
      "step": 34000
    },
    {
      "epoch": 1.8050254452926209,
      "grad_norm": 0.018229151144623756,
      "learning_rate": 7.966850438224486e-06,
      "loss": 0.1866,
      "step": 34050
    },
    {
      "epoch": 1.8076759966072942,
      "grad_norm": 0.05542723089456558,
      "learning_rate": 7.949180096126663e-06,
      "loss": 0.5959,
      "step": 34100
    },
    {
      "epoch": 1.8103265479219677,
      "grad_norm": 0.1024579256772995,
      "learning_rate": 7.93150975402884e-06,
      "loss": 0.2844,
      "step": 34150
    },
    {
      "epoch": 1.8129770992366412,
      "grad_norm": 0.27334290742874146,
      "learning_rate": 7.913839411931017e-06,
      "loss": 0.2729,
      "step": 34200
    },
    {
      "epoch": 1.8156276505513147,
      "grad_norm": 0.47809070348739624,
      "learning_rate": 7.896169069833194e-06,
      "loss": 0.2244,
      "step": 34250
    },
    {
      "epoch": 1.8182782018659882,
      "grad_norm": 0.012994138523936272,
      "learning_rate": 7.87849872773537e-06,
      "loss": 0.4325,
      "step": 34300
    },
    {
      "epoch": 1.8209287531806617,
      "grad_norm": 0.021536748856306076,
      "learning_rate": 7.860828385637547e-06,
      "loss": 0.161,
      "step": 34350
    },
    {
      "epoch": 1.823579304495335,
      "grad_norm": 0.05389094725251198,
      "learning_rate": 7.843158043539724e-06,
      "loss": 0.3747,
      "step": 34400
    },
    {
      "epoch": 1.8262298558100085,
      "grad_norm": 0.10826123505830765,
      "learning_rate": 7.825487701441901e-06,
      "loss": 0.1478,
      "step": 34450
    },
    {
      "epoch": 1.8288804071246818,
      "grad_norm": 4.276785850524902,
      "learning_rate": 7.807817359344078e-06,
      "loss": 0.2387,
      "step": 34500
    },
    {
      "epoch": 1.8315309584393553,
      "grad_norm": 0.02701539732515812,
      "learning_rate": 7.790147017246255e-06,
      "loss": 0.2558,
      "step": 34550
    },
    {
      "epoch": 1.8341815097540288,
      "grad_norm": 0.02936258539557457,
      "learning_rate": 7.772476675148432e-06,
      "loss": 0.3451,
      "step": 34600
    },
    {
      "epoch": 1.8368320610687023,
      "grad_norm": 0.06828039139509201,
      "learning_rate": 7.75480633305061e-06,
      "loss": 0.536,
      "step": 34650
    },
    {
      "epoch": 1.8394826123833758,
      "grad_norm": 0.018463531509041786,
      "learning_rate": 7.737135990952786e-06,
      "loss": 0.3625,
      "step": 34700
    },
    {
      "epoch": 1.8421331636980494,
      "grad_norm": 0.10845344513654709,
      "learning_rate": 7.719465648854963e-06,
      "loss": 0.472,
      "step": 34750
    },
    {
      "epoch": 1.8447837150127226,
      "grad_norm": 0.2786794900894165,
      "learning_rate": 7.70179530675714e-06,
      "loss": 0.2234,
      "step": 34800
    },
    {
      "epoch": 1.847434266327396,
      "grad_norm": 0.1454460620880127,
      "learning_rate": 7.684124964659317e-06,
      "loss": 0.3802,
      "step": 34850
    },
    {
      "epoch": 1.8500848176420694,
      "grad_norm": 0.07534562051296234,
      "learning_rate": 7.666454622561494e-06,
      "loss": 0.1947,
      "step": 34900
    },
    {
      "epoch": 1.852735368956743,
      "grad_norm": 0.20620852708816528,
      "learning_rate": 7.648784280463671e-06,
      "loss": 0.4639,
      "step": 34950
    },
    {
      "epoch": 1.8553859202714165,
      "grad_norm": 56.16842269897461,
      "learning_rate": 7.631113938365848e-06,
      "loss": 0.3497,
      "step": 35000
    },
    {
      "epoch": 1.85803647158609,
      "grad_norm": 0.16783909499645233,
      "learning_rate": 7.613443596268024e-06,
      "loss": 0.3649,
      "step": 35050
    },
    {
      "epoch": 1.8606870229007635,
      "grad_norm": 0.14544785022735596,
      "learning_rate": 7.595773254170201e-06,
      "loss": 0.4302,
      "step": 35100
    },
    {
      "epoch": 1.8633375742154368,
      "grad_norm": 0.01717877760529518,
      "learning_rate": 7.578102912072378e-06,
      "loss": 0.1755,
      "step": 35150
    },
    {
      "epoch": 1.8659881255301103,
      "grad_norm": 0.016716809943318367,
      "learning_rate": 7.560432569974555e-06,
      "loss": 0.2397,
      "step": 35200
    },
    {
      "epoch": 1.8686386768447836,
      "grad_norm": 0.016295352950692177,
      "learning_rate": 7.542762227876732e-06,
      "loss": 0.1289,
      "step": 35250
    },
    {
      "epoch": 1.871289228159457,
      "grad_norm": 0.03598950803279877,
      "learning_rate": 7.525091885778909e-06,
      "loss": 0.4994,
      "step": 35300
    },
    {
      "epoch": 1.8739397794741306,
      "grad_norm": 0.09213593602180481,
      "learning_rate": 7.507421543681086e-06,
      "loss": 0.2522,
      "step": 35350
    },
    {
      "epoch": 1.876590330788804,
      "grad_norm": 0.034904301166534424,
      "learning_rate": 7.489751201583263e-06,
      "loss": 0.2408,
      "step": 35400
    },
    {
      "epoch": 1.8792408821034776,
      "grad_norm": 0.2648777663707733,
      "learning_rate": 7.47208085948544e-06,
      "loss": 0.1341,
      "step": 35450
    },
    {
      "epoch": 1.8818914334181511,
      "grad_norm": 0.04758244380354881,
      "learning_rate": 7.454410517387617e-06,
      "loss": 0.1652,
      "step": 35500
    },
    {
      "epoch": 1.8845419847328244,
      "grad_norm": 0.03118365816771984,
      "learning_rate": 7.436740175289794e-06,
      "loss": 0.2123,
      "step": 35550
    },
    {
      "epoch": 1.887192536047498,
      "grad_norm": 76.95175170898438,
      "learning_rate": 7.419069833191971e-06,
      "loss": 0.4301,
      "step": 35600
    },
    {
      "epoch": 1.8898430873621712,
      "grad_norm": 1.110158920288086,
      "learning_rate": 7.401399491094148e-06,
      "loss": 0.2432,
      "step": 35650
    },
    {
      "epoch": 1.8924936386768447,
      "grad_norm": 107.36256408691406,
      "learning_rate": 7.383729148996325e-06,
      "loss": 0.337,
      "step": 35700
    },
    {
      "epoch": 1.8951441899915182,
      "grad_norm": 27.703369140625,
      "learning_rate": 7.3660588068985016e-06,
      "loss": 0.13,
      "step": 35750
    },
    {
      "epoch": 1.8977947413061917,
      "grad_norm": 0.008645285852253437,
      "learning_rate": 7.3483884648006785e-06,
      "loss": 0.3252,
      "step": 35800
    },
    {
      "epoch": 1.9004452926208653,
      "grad_norm": 18.218311309814453,
      "learning_rate": 7.3307181227028555e-06,
      "loss": 0.2465,
      "step": 35850
    },
    {
      "epoch": 1.9030958439355385,
      "grad_norm": 0.26978597044944763,
      "learning_rate": 7.3130477806050325e-06,
      "loss": 0.3455,
      "step": 35900
    },
    {
      "epoch": 1.905746395250212,
      "grad_norm": 0.03582005575299263,
      "learning_rate": 7.2953774385072094e-06,
      "loss": 0.2154,
      "step": 35950
    },
    {
      "epoch": 1.9083969465648853,
      "grad_norm": 0.040377967059612274,
      "learning_rate": 7.277707096409386e-06,
      "loss": 0.433,
      "step": 36000
    },
    {
      "epoch": 1.9110474978795589,
      "grad_norm": 0.5415326952934265,
      "learning_rate": 7.260036754311563e-06,
      "loss": 0.4589,
      "step": 36050
    },
    {
      "epoch": 1.9136980491942324,
      "grad_norm": 36.01585388183594,
      "learning_rate": 7.242366412213742e-06,
      "loss": 0.2353,
      "step": 36100
    },
    {
      "epoch": 1.9163486005089059,
      "grad_norm": 0.11917863041162491,
      "learning_rate": 7.224696070115919e-06,
      "loss": 0.2835,
      "step": 36150
    },
    {
      "epoch": 1.9189991518235794,
      "grad_norm": 155.84495544433594,
      "learning_rate": 7.207025728018096e-06,
      "loss": 0.4448,
      "step": 36200
    },
    {
      "epoch": 1.921649703138253,
      "grad_norm": 3.6776201725006104,
      "learning_rate": 7.189355385920273e-06,
      "loss": 0.3219,
      "step": 36250
    },
    {
      "epoch": 1.9243002544529262,
      "grad_norm": 0.2240094691514969,
      "learning_rate": 7.17168504382245e-06,
      "loss": 0.3975,
      "step": 36300
    },
    {
      "epoch": 1.9269508057675997,
      "grad_norm": 0.0816379189491272,
      "learning_rate": 7.154014701724627e-06,
      "loss": 0.4663,
      "step": 36350
    },
    {
      "epoch": 1.929601357082273,
      "grad_norm": 0.11408308148384094,
      "learning_rate": 7.136344359626804e-06,
      "loss": 0.4652,
      "step": 36400
    },
    {
      "epoch": 1.9322519083969465,
      "grad_norm": 0.08194683492183685,
      "learning_rate": 7.118674017528981e-06,
      "loss": 0.2514,
      "step": 36450
    },
    {
      "epoch": 1.93490245971162,
      "grad_norm": 0.07932306081056595,
      "learning_rate": 7.101003675431158e-06,
      "loss": 0.438,
      "step": 36500
    },
    {
      "epoch": 1.9375530110262935,
      "grad_norm": 0.18853284418582916,
      "learning_rate": 7.083333333333335e-06,
      "loss": 0.2977,
      "step": 36550
    },
    {
      "epoch": 1.940203562340967,
      "grad_norm": 0.02948114089667797,
      "learning_rate": 7.065662991235512e-06,
      "loss": 0.3567,
      "step": 36600
    },
    {
      "epoch": 1.9428541136556405,
      "grad_norm": 0.013449426740407944,
      "learning_rate": 7.047992649137689e-06,
      "loss": 0.2493,
      "step": 36650
    },
    {
      "epoch": 1.9455046649703138,
      "grad_norm": 0.013191234320402145,
      "learning_rate": 7.030322307039866e-06,
      "loss": 0.2408,
      "step": 36700
    },
    {
      "epoch": 1.9481552162849871,
      "grad_norm": 0.05610604211688042,
      "learning_rate": 7.0126519649420425e-06,
      "loss": 0.5857,
      "step": 36750
    },
    {
      "epoch": 1.9508057675996606,
      "grad_norm": 0.1286146640777588,
      "learning_rate": 6.9949816228442195e-06,
      "loss": 0.4832,
      "step": 36800
    },
    {
      "epoch": 1.9534563189143341,
      "grad_norm": 0.11510437726974487,
      "learning_rate": 6.9773112807463965e-06,
      "loss": 0.342,
      "step": 36850
    },
    {
      "epoch": 1.9561068702290076,
      "grad_norm": 0.12286023795604706,
      "learning_rate": 6.9596409386485734e-06,
      "loss": 0.214,
      "step": 36900
    },
    {
      "epoch": 1.9587574215436812,
      "grad_norm": 0.10626755654811859,
      "learning_rate": 6.94197059655075e-06,
      "loss": 0.4911,
      "step": 36950
    },
    {
      "epoch": 1.9614079728583547,
      "grad_norm": 41.25844955444336,
      "learning_rate": 6.924300254452927e-06,
      "loss": 0.1757,
      "step": 37000
    },
    {
      "epoch": 1.964058524173028,
      "grad_norm": 45.12912368774414,
      "learning_rate": 6.906629912355104e-06,
      "loss": 0.3261,
      "step": 37050
    },
    {
      "epoch": 1.9667090754877015,
      "grad_norm": 33.55558395385742,
      "learning_rate": 6.888959570257281e-06,
      "loss": 0.3447,
      "step": 37100
    },
    {
      "epoch": 1.9693596268023748,
      "grad_norm": 0.4125107526779175,
      "learning_rate": 6.871289228159458e-06,
      "loss": 0.1686,
      "step": 37150
    },
    {
      "epoch": 1.9720101781170483,
      "grad_norm": 0.05912161245942116,
      "learning_rate": 6.853618886061635e-06,
      "loss": 0.4601,
      "step": 37200
    },
    {
      "epoch": 1.9746607294317218,
      "grad_norm": 0.18371985852718353,
      "learning_rate": 6.835948543963812e-06,
      "loss": 0.3698,
      "step": 37250
    },
    {
      "epoch": 1.9773112807463953,
      "grad_norm": 46.13671112060547,
      "learning_rate": 6.818278201865989e-06,
      "loss": 0.2125,
      "step": 37300
    },
    {
      "epoch": 1.9799618320610688,
      "grad_norm": 0.017655350267887115,
      "learning_rate": 6.800607859768166e-06,
      "loss": 0.2034,
      "step": 37350
    },
    {
      "epoch": 1.9826123833757423,
      "grad_norm": 0.16794998943805695,
      "learning_rate": 6.782937517670343e-06,
      "loss": 0.4,
      "step": 37400
    },
    {
      "epoch": 1.9852629346904156,
      "grad_norm": 0.15646584331989288,
      "learning_rate": 6.76526717557252e-06,
      "loss": 0.3769,
      "step": 37450
    },
    {
      "epoch": 1.987913486005089,
      "grad_norm": 466.14837646484375,
      "learning_rate": 6.747596833474697e-06,
      "loss": 0.6434,
      "step": 37500
    },
    {
      "epoch": 1.9905640373197624,
      "grad_norm": 0.07985541969537735,
      "learning_rate": 6.729926491376874e-06,
      "loss": 0.0957,
      "step": 37550
    },
    {
      "epoch": 1.993214588634436,
      "grad_norm": 0.023112013936042786,
      "learning_rate": 6.712256149279051e-06,
      "loss": 0.3864,
      "step": 37600
    },
    {
      "epoch": 1.9958651399491094,
      "grad_norm": 3.7269186973571777,
      "learning_rate": 6.694585807181228e-06,
      "loss": 0.0843,
      "step": 37650
    },
    {
      "epoch": 1.998515691263783,
      "grad_norm": 0.05678209289908409,
      "learning_rate": 6.676915465083405e-06,
      "loss": 0.184,
      "step": 37700
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9902871493842477,
      "eval_f1": 0.8503496503496504,
      "eval_loss": 0.19729559123516083,
      "eval_precision": 0.9212121212121213,
      "eval_recall": 0.7896103896103897,
      "eval_runtime": 828.7254,
      "eval_samples_per_second": 39.879,
      "eval_steps_per_second": 4.986,
      "step": 37728
    },
    {
      "epoch": 2.0011662425784564,
      "grad_norm": 0.051621221005916595,
      "learning_rate": 6.659245122985582e-06,
      "loss": 0.4603,
      "step": 37750
    },
    {
      "epoch": 2.00381679389313,
      "grad_norm": 0.01146977860480547,
      "learning_rate": 6.641574780887759e-06,
      "loss": 0.2082,
      "step": 37800
    },
    {
      "epoch": 2.006467345207803,
      "grad_norm": 0.2539227306842804,
      "learning_rate": 6.623904438789936e-06,
      "loss": 0.416,
      "step": 37850
    },
    {
      "epoch": 2.0091178965224765,
      "grad_norm": 0.5157814025878906,
      "learning_rate": 6.606234096692113e-06,
      "loss": 0.3641,
      "step": 37900
    },
    {
      "epoch": 2.01176844783715,
      "grad_norm": 0.0325658805668354,
      "learning_rate": 6.58856375459429e-06,
      "loss": 0.1976,
      "step": 37950
    },
    {
      "epoch": 2.0144189991518235,
      "grad_norm": 0.01837645284831524,
      "learning_rate": 6.570893412496467e-06,
      "loss": 0.2866,
      "step": 38000
    },
    {
      "epoch": 2.017069550466497,
      "grad_norm": 0.014572404325008392,
      "learning_rate": 6.553223070398644e-06,
      "loss": 0.3692,
      "step": 38050
    },
    {
      "epoch": 2.0197201017811706,
      "grad_norm": 39.52498245239258,
      "learning_rate": 6.5355527283008206e-06,
      "loss": 0.1889,
      "step": 38100
    },
    {
      "epoch": 2.022370653095844,
      "grad_norm": 0.011529042385518551,
      "learning_rate": 6.5178823862029975e-06,
      "loss": 0.4051,
      "step": 38150
    },
    {
      "epoch": 2.0250212044105176,
      "grad_norm": 0.07129127532243729,
      "learning_rate": 6.5002120441051745e-06,
      "loss": 0.2012,
      "step": 38200
    },
    {
      "epoch": 2.0276717557251906,
      "grad_norm": 2.0652928352355957,
      "learning_rate": 6.4825417020073515e-06,
      "loss": 0.3724,
      "step": 38250
    },
    {
      "epoch": 2.030322307039864,
      "grad_norm": 0.022370029240846634,
      "learning_rate": 6.464871359909528e-06,
      "loss": 0.2763,
      "step": 38300
    },
    {
      "epoch": 2.0329728583545377,
      "grad_norm": 0.19111785292625427,
      "learning_rate": 6.447201017811705e-06,
      "loss": 0.1841,
      "step": 38350
    },
    {
      "epoch": 2.035623409669211,
      "grad_norm": 0.011590246111154556,
      "learning_rate": 6.429530675713882e-06,
      "loss": 0.2021,
      "step": 38400
    },
    {
      "epoch": 2.0382739609838847,
      "grad_norm": 0.10740862786769867,
      "learning_rate": 6.411860333616059e-06,
      "loss": 0.5417,
      "step": 38450
    },
    {
      "epoch": 2.040924512298558,
      "grad_norm": 0.07634493708610535,
      "learning_rate": 6.394189991518236e-06,
      "loss": 0.1715,
      "step": 38500
    },
    {
      "epoch": 2.0435750636132317,
      "grad_norm": 0.24681678414344788,
      "learning_rate": 6.376519649420413e-06,
      "loss": 0.3593,
      "step": 38550
    },
    {
      "epoch": 2.046225614927905,
      "grad_norm": 0.026356231421232224,
      "learning_rate": 6.35884930732259e-06,
      "loss": 0.2687,
      "step": 38600
    },
    {
      "epoch": 2.0488761662425783,
      "grad_norm": 0.18223297595977783,
      "learning_rate": 6.341178965224767e-06,
      "loss": 0.0911,
      "step": 38650
    },
    {
      "epoch": 2.051526717557252,
      "grad_norm": 0.024795759469270706,
      "learning_rate": 6.323508623126944e-06,
      "loss": 0.3196,
      "step": 38700
    },
    {
      "epoch": 2.0541772688719253,
      "grad_norm": 0.0422467477619648,
      "learning_rate": 6.305838281029121e-06,
      "loss": 0.1644,
      "step": 38750
    },
    {
      "epoch": 2.056827820186599,
      "grad_norm": 0.04137513414025307,
      "learning_rate": 6.288167938931298e-06,
      "loss": 0.4063,
      "step": 38800
    },
    {
      "epoch": 2.0594783715012723,
      "grad_norm": 0.03929143026471138,
      "learning_rate": 6.270497596833475e-06,
      "loss": 0.0462,
      "step": 38850
    },
    {
      "epoch": 2.062128922815946,
      "grad_norm": 0.1257212609052658,
      "learning_rate": 6.252827254735652e-06,
      "loss": 0.4841,
      "step": 38900
    },
    {
      "epoch": 2.0647794741306194,
      "grad_norm": 0.03726501762866974,
      "learning_rate": 6.235156912637829e-06,
      "loss": 0.2837,
      "step": 38950
    },
    {
      "epoch": 2.0674300254452924,
      "grad_norm": 0.029893331229686737,
      "learning_rate": 6.217486570540007e-06,
      "loss": 0.2805,
      "step": 39000
    },
    {
      "epoch": 2.070080576759966,
      "grad_norm": 0.09783867746591568,
      "learning_rate": 6.199816228442184e-06,
      "loss": 0.2769,
      "step": 39050
    },
    {
      "epoch": 2.0727311280746394,
      "grad_norm": 0.048265960067510605,
      "learning_rate": 6.182145886344361e-06,
      "loss": 0.2792,
      "step": 39100
    },
    {
      "epoch": 2.075381679389313,
      "grad_norm": 0.04785327985882759,
      "learning_rate": 6.164475544246538e-06,
      "loss": 0.2578,
      "step": 39150
    },
    {
      "epoch": 2.0780322307039865,
      "grad_norm": 0.015656404197216034,
      "learning_rate": 6.146805202148715e-06,
      "loss": 0.1176,
      "step": 39200
    },
    {
      "epoch": 2.08068278201866,
      "grad_norm": 0.026942556723952293,
      "learning_rate": 6.129134860050892e-06,
      "loss": 0.3168,
      "step": 39250
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.0358874648809433,
      "learning_rate": 6.1114645179530685e-06,
      "loss": 0.3898,
      "step": 39300
    },
    {
      "epoch": 2.085983884648007,
      "grad_norm": 0.09962619841098785,
      "learning_rate": 6.0937941758552455e-06,
      "loss": 0.1525,
      "step": 39350
    },
    {
      "epoch": 2.08863443596268,
      "grad_norm": 137.294677734375,
      "learning_rate": 6.0761238337574225e-06,
      "loss": 0.1969,
      "step": 39400
    },
    {
      "epoch": 2.0912849872773536,
      "grad_norm": 0.06269419938325882,
      "learning_rate": 6.0584534916595994e-06,
      "loss": 0.3589,
      "step": 39450
    },
    {
      "epoch": 2.093935538592027,
      "grad_norm": 0.01357376016676426,
      "learning_rate": 6.040783149561776e-06,
      "loss": 0.2405,
      "step": 39500
    },
    {
      "epoch": 2.0965860899067006,
      "grad_norm": 0.05873414874076843,
      "learning_rate": 6.023112807463953e-06,
      "loss": 0.319,
      "step": 39550
    },
    {
      "epoch": 2.099236641221374,
      "grad_norm": 413.8814392089844,
      "learning_rate": 6.00544246536613e-06,
      "loss": 0.1972,
      "step": 39600
    },
    {
      "epoch": 2.1018871925360476,
      "grad_norm": 9.86931324005127,
      "learning_rate": 5.987772123268307e-06,
      "loss": 0.324,
      "step": 39650
    },
    {
      "epoch": 2.104537743850721,
      "grad_norm": 0.0884992703795433,
      "learning_rate": 5.970101781170484e-06,
      "loss": 0.3009,
      "step": 39700
    },
    {
      "epoch": 2.107188295165394,
      "grad_norm": 0.06373164802789688,
      "learning_rate": 5.952431439072661e-06,
      "loss": 0.4624,
      "step": 39750
    },
    {
      "epoch": 2.1098388464800677,
      "grad_norm": 0.03677923232316971,
      "learning_rate": 5.934761096974838e-06,
      "loss": 0.1577,
      "step": 39800
    },
    {
      "epoch": 2.112489397794741,
      "grad_norm": 0.02462776191532612,
      "learning_rate": 5.917090754877015e-06,
      "loss": 0.1045,
      "step": 39850
    },
    {
      "epoch": 2.1151399491094147,
      "grad_norm": 0.025776375085115433,
      "learning_rate": 5.899420412779192e-06,
      "loss": 0.1239,
      "step": 39900
    },
    {
      "epoch": 2.1177905004240882,
      "grad_norm": 0.04184252768754959,
      "learning_rate": 5.881750070681369e-06,
      "loss": 0.3711,
      "step": 39950
    },
    {
      "epoch": 2.1204410517387617,
      "grad_norm": 0.10808547586202621,
      "learning_rate": 5.864079728583546e-06,
      "loss": 0.1272,
      "step": 40000
    },
    {
      "epoch": 2.1230916030534353,
      "grad_norm": 44.908363342285156,
      "learning_rate": 5.846409386485723e-06,
      "loss": 0.3257,
      "step": 40050
    },
    {
      "epoch": 2.1257421543681088,
      "grad_norm": 0.01996758207678795,
      "learning_rate": 5.8287390443879e-06,
      "loss": 0.1307,
      "step": 40100
    },
    {
      "epoch": 2.128392705682782,
      "grad_norm": 0.03429826349020004,
      "learning_rate": 5.811068702290077e-06,
      "loss": 0.4064,
      "step": 40150
    },
    {
      "epoch": 2.1310432569974553,
      "grad_norm": 0.08811648935079575,
      "learning_rate": 5.793398360192254e-06,
      "loss": 0.249,
      "step": 40200
    },
    {
      "epoch": 2.133693808312129,
      "grad_norm": 0.017527027055621147,
      "learning_rate": 5.775728018094431e-06,
      "loss": 0.2444,
      "step": 40250
    },
    {
      "epoch": 2.1363443596268024,
      "grad_norm": 73.60761260986328,
      "learning_rate": 5.758057675996608e-06,
      "loss": 0.0931,
      "step": 40300
    },
    {
      "epoch": 2.138994910941476,
      "grad_norm": 35.830909729003906,
      "learning_rate": 5.740387333898785e-06,
      "loss": 0.4082,
      "step": 40350
    },
    {
      "epoch": 2.1416454622561494,
      "grad_norm": 0.042205508798360825,
      "learning_rate": 5.722716991800962e-06,
      "loss": 0.3733,
      "step": 40400
    },
    {
      "epoch": 2.144296013570823,
      "grad_norm": 0.02295602113008499,
      "learning_rate": 5.705046649703139e-06,
      "loss": 0.1248,
      "step": 40450
    },
    {
      "epoch": 2.1469465648854964,
      "grad_norm": 34.10614776611328,
      "learning_rate": 5.687376307605316e-06,
      "loss": 0.2253,
      "step": 40500
    },
    {
      "epoch": 2.1495971162001695,
      "grad_norm": 0.03797922283411026,
      "learning_rate": 5.669705965507493e-06,
      "loss": 0.3898,
      "step": 40550
    },
    {
      "epoch": 2.152247667514843,
      "grad_norm": 0.0360754020512104,
      "learning_rate": 5.65203562340967e-06,
      "loss": 0.2021,
      "step": 40600
    },
    {
      "epoch": 2.1548982188295165,
      "grad_norm": 37.00994873046875,
      "learning_rate": 5.6343652813118466e-06,
      "loss": 0.4719,
      "step": 40650
    },
    {
      "epoch": 2.15754877014419,
      "grad_norm": 0.054534513503313065,
      "learning_rate": 5.6166949392140235e-06,
      "loss": 0.3385,
      "step": 40700
    },
    {
      "epoch": 2.1601993214588635,
      "grad_norm": 0.051035258919000626,
      "learning_rate": 5.5990245971162005e-06,
      "loss": 0.278,
      "step": 40750
    },
    {
      "epoch": 2.162849872773537,
      "grad_norm": 0.27737975120544434,
      "learning_rate": 5.5813542550183775e-06,
      "loss": 0.5295,
      "step": 40800
    },
    {
      "epoch": 2.1655004240882105,
      "grad_norm": 31.688129425048828,
      "learning_rate": 5.563683912920554e-06,
      "loss": 0.2746,
      "step": 40850
    },
    {
      "epoch": 2.1681509754028836,
      "grad_norm": 0.01908877305686474,
      "learning_rate": 5.546013570822731e-06,
      "loss": 0.3981,
      "step": 40900
    },
    {
      "epoch": 2.170801526717557,
      "grad_norm": 0.018436964601278305,
      "learning_rate": 5.528343228724908e-06,
      "loss": 0.1822,
      "step": 40950
    },
    {
      "epoch": 2.1734520780322306,
      "grad_norm": 0.019222181290388107,
      "learning_rate": 5.510672886627085e-06,
      "loss": 0.3189,
      "step": 41000
    },
    {
      "epoch": 2.176102629346904,
      "grad_norm": 0.2273835390806198,
      "learning_rate": 5.493002544529262e-06,
      "loss": 0.2072,
      "step": 41050
    },
    {
      "epoch": 2.1787531806615776,
      "grad_norm": 0.03698277473449707,
      "learning_rate": 5.475332202431439e-06,
      "loss": 0.3499,
      "step": 41100
    },
    {
      "epoch": 2.181403731976251,
      "grad_norm": 0.021917816251516342,
      "learning_rate": 5.457661860333616e-06,
      "loss": 0.2695,
      "step": 41150
    },
    {
      "epoch": 2.1840542832909247,
      "grad_norm": 0.028313782066106796,
      "learning_rate": 5.439991518235793e-06,
      "loss": 0.175,
      "step": 41200
    },
    {
      "epoch": 2.186704834605598,
      "grad_norm": 0.014996690675616264,
      "learning_rate": 5.42232117613797e-06,
      "loss": 0.1999,
      "step": 41250
    },
    {
      "epoch": 2.1893553859202712,
      "grad_norm": 0.00986297894269228,
      "learning_rate": 5.404650834040147e-06,
      "loss": 0.1461,
      "step": 41300
    },
    {
      "epoch": 2.1920059372349447,
      "grad_norm": 0.10730037093162537,
      "learning_rate": 5.386980491942324e-06,
      "loss": 0.2336,
      "step": 41350
    },
    {
      "epoch": 2.1946564885496183,
      "grad_norm": 0.8126197457313538,
      "learning_rate": 5.369310149844501e-06,
      "loss": 0.4072,
      "step": 41400
    },
    {
      "epoch": 2.1973070398642918,
      "grad_norm": 0.9636303782463074,
      "learning_rate": 5.351639807746678e-06,
      "loss": 0.4244,
      "step": 41450
    },
    {
      "epoch": 2.1999575911789653,
      "grad_norm": 0.022325895726680756,
      "learning_rate": 5.333969465648855e-06,
      "loss": 0.2066,
      "step": 41500
    },
    {
      "epoch": 2.202608142493639,
      "grad_norm": 0.3739837110042572,
      "learning_rate": 5.316299123551032e-06,
      "loss": 0.1469,
      "step": 41550
    },
    {
      "epoch": 2.2052586938083123,
      "grad_norm": 0.013960572890937328,
      "learning_rate": 5.298628781453209e-06,
      "loss": 0.2878,
      "step": 41600
    },
    {
      "epoch": 2.207909245122986,
      "grad_norm": 0.01941869966685772,
      "learning_rate": 5.280958439355386e-06,
      "loss": 0.1134,
      "step": 41650
    },
    {
      "epoch": 2.210559796437659,
      "grad_norm": 0.008756288327276707,
      "learning_rate": 5.263288097257563e-06,
      "loss": 0.2763,
      "step": 41700
    },
    {
      "epoch": 2.2132103477523324,
      "grad_norm": 0.18707945942878723,
      "learning_rate": 5.24561775515974e-06,
      "loss": 0.2273,
      "step": 41750
    },
    {
      "epoch": 2.215860899067006,
      "grad_norm": 0.06355303525924683,
      "learning_rate": 5.227947413061917e-06,
      "loss": 0.3779,
      "step": 41800
    },
    {
      "epoch": 2.2185114503816794,
      "grad_norm": 51.92646789550781,
      "learning_rate": 5.210277070964094e-06,
      "loss": 0.2714,
      "step": 41850
    },
    {
      "epoch": 2.221162001696353,
      "grad_norm": 0.04248416796326637,
      "learning_rate": 5.1926067288662715e-06,
      "loss": 0.2979,
      "step": 41900
    },
    {
      "epoch": 2.2238125530110264,
      "grad_norm": 54.249717712402344,
      "learning_rate": 5.1749363867684485e-06,
      "loss": 0.1127,
      "step": 41950
    },
    {
      "epoch": 2.2264631043257,
      "grad_norm": 0.13086114823818207,
      "learning_rate": 5.1572660446706254e-06,
      "loss": 0.3426,
      "step": 42000
    },
    {
      "epoch": 2.229113655640373,
      "grad_norm": 0.017273830249905586,
      "learning_rate": 5.139595702572802e-06,
      "loss": 0.2911,
      "step": 42050
    },
    {
      "epoch": 2.2317642069550465,
      "grad_norm": 0.016123656183481216,
      "learning_rate": 5.121925360474979e-06,
      "loss": 0.3784,
      "step": 42100
    },
    {
      "epoch": 2.23441475826972,
      "grad_norm": 0.06626841425895691,
      "learning_rate": 5.104255018377156e-06,
      "loss": 0.2734,
      "step": 42150
    },
    {
      "epoch": 2.2370653095843935,
      "grad_norm": 0.05894693359732628,
      "learning_rate": 5.086584676279333e-06,
      "loss": 0.3188,
      "step": 42200
    },
    {
      "epoch": 2.239715860899067,
      "grad_norm": 0.020653046667575836,
      "learning_rate": 5.06891433418151e-06,
      "loss": 0.2716,
      "step": 42250
    },
    {
      "epoch": 2.2423664122137406,
      "grad_norm": 0.01039215363562107,
      "learning_rate": 5.051243992083687e-06,
      "loss": 0.3776,
      "step": 42300
    },
    {
      "epoch": 2.245016963528414,
      "grad_norm": 0.02632995694875717,
      "learning_rate": 5.033573649985864e-06,
      "loss": 0.122,
      "step": 42350
    },
    {
      "epoch": 2.247667514843087,
      "grad_norm": 0.0879046618938446,
      "learning_rate": 5.015903307888041e-06,
      "loss": 0.235,
      "step": 42400
    },
    {
      "epoch": 2.2503180661577606,
      "grad_norm": 0.004043675493448973,
      "learning_rate": 4.998232965790218e-06,
      "loss": 0.1748,
      "step": 42450
    },
    {
      "epoch": 2.252968617472434,
      "grad_norm": 0.018591461703181267,
      "learning_rate": 4.980562623692395e-06,
      "loss": 0.5131,
      "step": 42500
    },
    {
      "epoch": 2.2556191687871077,
      "grad_norm": 0.0872541293501854,
      "learning_rate": 4.962892281594572e-06,
      "loss": 0.2955,
      "step": 42550
    },
    {
      "epoch": 2.258269720101781,
      "grad_norm": 0.01671317219734192,
      "learning_rate": 4.945221939496749e-06,
      "loss": 0.2762,
      "step": 42600
    },
    {
      "epoch": 2.2609202714164547,
      "grad_norm": 14.592598915100098,
      "learning_rate": 4.927551597398926e-06,
      "loss": 0.1812,
      "step": 42650
    },
    {
      "epoch": 2.263570822731128,
      "grad_norm": 0.04036147892475128,
      "learning_rate": 4.909881255301103e-06,
      "loss": 0.3772,
      "step": 42700
    },
    {
      "epoch": 2.2662213740458017,
      "grad_norm": 0.11798731237649918,
      "learning_rate": 4.89221091320328e-06,
      "loss": 0.3831,
      "step": 42750
    },
    {
      "epoch": 2.268871925360475,
      "grad_norm": 23.49038314819336,
      "learning_rate": 4.874540571105457e-06,
      "loss": 0.3574,
      "step": 42800
    },
    {
      "epoch": 2.2715224766751483,
      "grad_norm": 21.275543212890625,
      "learning_rate": 4.856870229007634e-06,
      "loss": 0.2727,
      "step": 42850
    },
    {
      "epoch": 2.274173027989822,
      "grad_norm": 0.19435326755046844,
      "learning_rate": 4.839199886909811e-06,
      "loss": 0.1758,
      "step": 42900
    },
    {
      "epoch": 2.2768235793044953,
      "grad_norm": 0.036355189979076385,
      "learning_rate": 4.821529544811988e-06,
      "loss": 0.2473,
      "step": 42950
    },
    {
      "epoch": 2.279474130619169,
      "grad_norm": 0.041406288743019104,
      "learning_rate": 4.803859202714165e-06,
      "loss": 0.2808,
      "step": 43000
    },
    {
      "epoch": 2.2821246819338423,
      "grad_norm": 46.306156158447266,
      "learning_rate": 4.786188860616342e-06,
      "loss": 0.0981,
      "step": 43050
    },
    {
      "epoch": 2.284775233248516,
      "grad_norm": 0.1294260323047638,
      "learning_rate": 4.768518518518519e-06,
      "loss": 0.252,
      "step": 43100
    },
    {
      "epoch": 2.2874257845631893,
      "grad_norm": 0.004828636068850756,
      "learning_rate": 4.750848176420696e-06,
      "loss": 0.0444,
      "step": 43150
    },
    {
      "epoch": 2.2900763358778624,
      "grad_norm": 0.7470138072967529,
      "learning_rate": 4.7331778343228726e-06,
      "loss": 0.2631,
      "step": 43200
    },
    {
      "epoch": 2.292726887192536,
      "grad_norm": 0.05728958547115326,
      "learning_rate": 4.7155074922250495e-06,
      "loss": 0.2989,
      "step": 43250
    },
    {
      "epoch": 2.2953774385072094,
      "grad_norm": 0.06251446902751923,
      "learning_rate": 4.6978371501272265e-06,
      "loss": 0.2321,
      "step": 43300
    },
    {
      "epoch": 2.298027989821883,
      "grad_norm": 0.021026330068707466,
      "learning_rate": 4.6801668080294035e-06,
      "loss": 0.2066,
      "step": 43350
    },
    {
      "epoch": 2.3006785411365565,
      "grad_norm": 0.3655586540699005,
      "learning_rate": 4.66249646593158e-06,
      "loss": 0.2749,
      "step": 43400
    },
    {
      "epoch": 2.30332909245123,
      "grad_norm": 0.05008704587817192,
      "learning_rate": 4.644826123833757e-06,
      "loss": 0.1575,
      "step": 43450
    },
    {
      "epoch": 2.3059796437659035,
      "grad_norm": 0.29619643092155457,
      "learning_rate": 4.627155781735934e-06,
      "loss": 0.2986,
      "step": 43500
    },
    {
      "epoch": 2.3086301950805765,
      "grad_norm": 0.011601372621953487,
      "learning_rate": 4.609485439638111e-06,
      "loss": 0.2245,
      "step": 43550
    },
    {
      "epoch": 2.31128074639525,
      "grad_norm": 0.004403224214911461,
      "learning_rate": 4.591815097540288e-06,
      "loss": 0.3049,
      "step": 43600
    },
    {
      "epoch": 2.3139312977099236,
      "grad_norm": 0.003658706322312355,
      "learning_rate": 4.574144755442465e-06,
      "loss": 0.2251,
      "step": 43650
    },
    {
      "epoch": 2.316581849024597,
      "grad_norm": 0.14959906041622162,
      "learning_rate": 4.556474413344642e-06,
      "loss": 0.0187,
      "step": 43700
    },
    {
      "epoch": 2.3192324003392706,
      "grad_norm": 0.15132571756839752,
      "learning_rate": 4.538804071246819e-06,
      "loss": 0.2312,
      "step": 43750
    },
    {
      "epoch": 2.321882951653944,
      "grad_norm": 30.826873779296875,
      "learning_rate": 4.521133729148996e-06,
      "loss": 0.329,
      "step": 43800
    },
    {
      "epoch": 2.3245335029686176,
      "grad_norm": 0.004996544681489468,
      "learning_rate": 4.503463387051173e-06,
      "loss": 0.1704,
      "step": 43850
    },
    {
      "epoch": 2.327184054283291,
      "grad_norm": 0.11154016107320786,
      "learning_rate": 4.48579304495335e-06,
      "loss": 0.3133,
      "step": 43900
    },
    {
      "epoch": 2.3298346055979646,
      "grad_norm": 0.06995473057031631,
      "learning_rate": 4.468122702855527e-06,
      "loss": 0.1882,
      "step": 43950
    },
    {
      "epoch": 2.3324851569126377,
      "grad_norm": 63.44355010986328,
      "learning_rate": 4.450452360757704e-06,
      "loss": 0.3031,
      "step": 44000
    },
    {
      "epoch": 2.335135708227311,
      "grad_norm": 0.04961714893579483,
      "learning_rate": 4.432782018659882e-06,
      "loss": 0.5529,
      "step": 44050
    },
    {
      "epoch": 2.3377862595419847,
      "grad_norm": 3.9565956592559814,
      "learning_rate": 4.415111676562059e-06,
      "loss": 0.2795,
      "step": 44100
    },
    {
      "epoch": 2.3404368108566582,
      "grad_norm": 0.2944599986076355,
      "learning_rate": 4.397441334464236e-06,
      "loss": 0.2767,
      "step": 44150
    },
    {
      "epoch": 2.3430873621713317,
      "grad_norm": 0.016740256920456886,
      "learning_rate": 4.379770992366413e-06,
      "loss": 0.2669,
      "step": 44200
    },
    {
      "epoch": 2.3457379134860052,
      "grad_norm": 0.009703773073852062,
      "learning_rate": 4.36210065026859e-06,
      "loss": 0.3829,
      "step": 44250
    },
    {
      "epoch": 2.3483884648006788,
      "grad_norm": 0.06944382190704346,
      "learning_rate": 4.344430308170767e-06,
      "loss": 0.2768,
      "step": 44300
    },
    {
      "epoch": 2.351039016115352,
      "grad_norm": 0.00779300183057785,
      "learning_rate": 4.3267599660729436e-06,
      "loss": 0.3608,
      "step": 44350
    },
    {
      "epoch": 2.3536895674300253,
      "grad_norm": 0.4754078984260559,
      "learning_rate": 4.3090896239751205e-06,
      "loss": 0.2442,
      "step": 44400
    },
    {
      "epoch": 2.356340118744699,
      "grad_norm": 0.009640480391681194,
      "learning_rate": 4.2914192818772975e-06,
      "loss": 0.5115,
      "step": 44450
    },
    {
      "epoch": 2.3589906700593724,
      "grad_norm": 0.1609724909067154,
      "learning_rate": 4.2737489397794745e-06,
      "loss": 0.3809,
      "step": 44500
    },
    {
      "epoch": 2.361641221374046,
      "grad_norm": 0.3012579083442688,
      "learning_rate": 4.2560785976816514e-06,
      "loss": 0.2598,
      "step": 44550
    },
    {
      "epoch": 2.3642917726887194,
      "grad_norm": 0.01830531284213066,
      "learning_rate": 4.238408255583828e-06,
      "loss": 0.1167,
      "step": 44600
    },
    {
      "epoch": 2.366942324003393,
      "grad_norm": 0.0048593091778457165,
      "learning_rate": 4.220737913486005e-06,
      "loss": 0.2315,
      "step": 44650
    },
    {
      "epoch": 2.369592875318066,
      "grad_norm": 210.6036376953125,
      "learning_rate": 4.203067571388182e-06,
      "loss": 0.3071,
      "step": 44700
    },
    {
      "epoch": 2.3722434266327395,
      "grad_norm": 0.10114198178052902,
      "learning_rate": 4.185397229290359e-06,
      "loss": 0.3315,
      "step": 44750
    },
    {
      "epoch": 2.374893977947413,
      "grad_norm": 0.2644461393356323,
      "learning_rate": 4.167726887192536e-06,
      "loss": 0.2668,
      "step": 44800
    },
    {
      "epoch": 2.3775445292620865,
      "grad_norm": 0.13994736969470978,
      "learning_rate": 4.150056545094713e-06,
      "loss": 0.313,
      "step": 44850
    },
    {
      "epoch": 2.38019508057676,
      "grad_norm": 0.017885789275169373,
      "learning_rate": 4.13238620299689e-06,
      "loss": 0.1964,
      "step": 44900
    },
    {
      "epoch": 2.3828456318914335,
      "grad_norm": 0.14357733726501465,
      "learning_rate": 4.114715860899067e-06,
      "loss": 0.1892,
      "step": 44950
    },
    {
      "epoch": 2.385496183206107,
      "grad_norm": 0.07374341785907745,
      "learning_rate": 4.097045518801244e-06,
      "loss": 0.4002,
      "step": 45000
    },
    {
      "epoch": 2.38814673452078,
      "grad_norm": 0.15665505826473236,
      "learning_rate": 4.079375176703421e-06,
      "loss": 0.2376,
      "step": 45050
    },
    {
      "epoch": 2.3907972858354536,
      "grad_norm": 0.020054280757904053,
      "learning_rate": 4.061704834605598e-06,
      "loss": 0.1626,
      "step": 45100
    },
    {
      "epoch": 2.393447837150127,
      "grad_norm": 0.9381484389305115,
      "learning_rate": 4.044034492507775e-06,
      "loss": 0.152,
      "step": 45150
    },
    {
      "epoch": 2.3960983884648006,
      "grad_norm": 160.5794219970703,
      "learning_rate": 4.026364150409952e-06,
      "loss": 0.274,
      "step": 45200
    },
    {
      "epoch": 2.398748939779474,
      "grad_norm": 441.2203369140625,
      "learning_rate": 4.008693808312129e-06,
      "loss": 0.0206,
      "step": 45250
    },
    {
      "epoch": 2.4013994910941476,
      "grad_norm": 0.23355479538440704,
      "learning_rate": 3.991023466214306e-06,
      "loss": 0.4266,
      "step": 45300
    },
    {
      "epoch": 2.404050042408821,
      "grad_norm": 0.015979351475834846,
      "learning_rate": 3.973353124116483e-06,
      "loss": 0.337,
      "step": 45350
    },
    {
      "epoch": 2.4067005937234947,
      "grad_norm": 0.058181848376989365,
      "learning_rate": 3.95568278201866e-06,
      "loss": 0.3824,
      "step": 45400
    },
    {
      "epoch": 2.409351145038168,
      "grad_norm": 0.2762390077114105,
      "learning_rate": 3.938012439920837e-06,
      "loss": 0.234,
      "step": 45450
    },
    {
      "epoch": 2.4120016963528412,
      "grad_norm": 0.019367849454283714,
      "learning_rate": 3.920342097823015e-06,
      "loss": 0.1127,
      "step": 45500
    },
    {
      "epoch": 2.4146522476675147,
      "grad_norm": 0.03264880180358887,
      "learning_rate": 3.9026717557251916e-06,
      "loss": 0.3362,
      "step": 45550
    },
    {
      "epoch": 2.4173027989821882,
      "grad_norm": 0.013183511793613434,
      "learning_rate": 3.8850014136273685e-06,
      "loss": 0.1686,
      "step": 45600
    },
    {
      "epoch": 2.4199533502968618,
      "grad_norm": 0.004663737490773201,
      "learning_rate": 3.8673310715295455e-06,
      "loss": 0.2088,
      "step": 45650
    },
    {
      "epoch": 2.4226039016115353,
      "grad_norm": 0.08362767100334167,
      "learning_rate": 3.8496607294317224e-06,
      "loss": 0.5291,
      "step": 45700
    },
    {
      "epoch": 2.425254452926209,
      "grad_norm": 1.0585070848464966,
      "learning_rate": 3.831990387333899e-06,
      "loss": 0.1012,
      "step": 45750
    },
    {
      "epoch": 2.4279050042408823,
      "grad_norm": 0.038539621978998184,
      "learning_rate": 3.8143200452360764e-06,
      "loss": 0.4172,
      "step": 45800
    },
    {
      "epoch": 2.4305555555555554,
      "grad_norm": 0.044161565601825714,
      "learning_rate": 3.7966497031382533e-06,
      "loss": 0.1721,
      "step": 45850
    },
    {
      "epoch": 2.433206106870229,
      "grad_norm": 0.6151674389839172,
      "learning_rate": 3.7789793610404303e-06,
      "loss": 0.4033,
      "step": 45900
    },
    {
      "epoch": 2.4358566581849024,
      "grad_norm": 0.027241002768278122,
      "learning_rate": 3.7613090189426073e-06,
      "loss": 0.3283,
      "step": 45950
    },
    {
      "epoch": 2.438507209499576,
      "grad_norm": 0.017374420538544655,
      "learning_rate": 3.7436386768447842e-06,
      "loss": 0.0361,
      "step": 46000
    },
    {
      "epoch": 2.4411577608142494,
      "grad_norm": 0.21263723075389862,
      "learning_rate": 3.725968334746961e-06,
      "loss": 0.1395,
      "step": 46050
    },
    {
      "epoch": 2.443808312128923,
      "grad_norm": 0.08700945973396301,
      "learning_rate": 3.708297992649138e-06,
      "loss": 0.4313,
      "step": 46100
    },
    {
      "epoch": 2.4464588634435964,
      "grad_norm": 48.11107635498047,
      "learning_rate": 3.690627650551315e-06,
      "loss": 0.3384,
      "step": 46150
    },
    {
      "epoch": 2.4491094147582695,
      "grad_norm": 0.030835935845971107,
      "learning_rate": 3.672957308453492e-06,
      "loss": 0.2306,
      "step": 46200
    },
    {
      "epoch": 2.451759966072943,
      "grad_norm": 0.4360988140106201,
      "learning_rate": 3.655286966355669e-06,
      "loss": 0.3539,
      "step": 46250
    },
    {
      "epoch": 2.4544105173876165,
      "grad_norm": 0.16512365639209747,
      "learning_rate": 3.637616624257846e-06,
      "loss": 0.406,
      "step": 46300
    },
    {
      "epoch": 2.45706106870229,
      "grad_norm": 0.23241358995437622,
      "learning_rate": 3.619946282160023e-06,
      "loss": 0.356,
      "step": 46350
    },
    {
      "epoch": 2.4597116200169635,
      "grad_norm": 0.05555103346705437,
      "learning_rate": 3.6022759400622e-06,
      "loss": 0.0176,
      "step": 46400
    },
    {
      "epoch": 2.462362171331637,
      "grad_norm": 0.007635306101292372,
      "learning_rate": 3.584605597964377e-06,
      "loss": 0.2376,
      "step": 46450
    },
    {
      "epoch": 2.4650127226463106,
      "grad_norm": 26.774274826049805,
      "learning_rate": 3.566935255866554e-06,
      "loss": 0.1559,
      "step": 46500
    },
    {
      "epoch": 2.467663273960984,
      "grad_norm": 0.02833842858672142,
      "learning_rate": 3.549264913768731e-06,
      "loss": 0.1536,
      "step": 46550
    },
    {
      "epoch": 2.4703138252756576,
      "grad_norm": 0.038015980273485184,
      "learning_rate": 3.531594571670908e-06,
      "loss": 0.243,
      "step": 46600
    },
    {
      "epoch": 2.4729643765903306,
      "grad_norm": 0.02976522035896778,
      "learning_rate": 3.5139242295730848e-06,
      "loss": 0.2036,
      "step": 46650
    },
    {
      "epoch": 2.475614927905004,
      "grad_norm": 0.009387715719640255,
      "learning_rate": 3.4962538874752617e-06,
      "loss": 0.2633,
      "step": 46700
    },
    {
      "epoch": 2.4782654792196777,
      "grad_norm": 0.07378463447093964,
      "learning_rate": 3.4785835453774387e-06,
      "loss": 0.1213,
      "step": 46750
    },
    {
      "epoch": 2.480916030534351,
      "grad_norm": 0.025069188326597214,
      "learning_rate": 3.4609132032796156e-06,
      "loss": 0.3913,
      "step": 46800
    },
    {
      "epoch": 2.4835665818490247,
      "grad_norm": 0.28365427255630493,
      "learning_rate": 3.4432428611817926e-06,
      "loss": 0.3508,
      "step": 46850
    },
    {
      "epoch": 2.486217133163698,
      "grad_norm": 0.01617727242410183,
      "learning_rate": 3.4255725190839696e-06,
      "loss": 0.0012,
      "step": 46900
    },
    {
      "epoch": 2.4888676844783717,
      "grad_norm": 0.04379690811038017,
      "learning_rate": 3.407902176986147e-06,
      "loss": 0.1925,
      "step": 46950
    },
    {
      "epoch": 2.4915182357930448,
      "grad_norm": 0.1604217141866684,
      "learning_rate": 3.390231834888324e-06,
      "loss": 0.3322,
      "step": 47000
    },
    {
      "epoch": 2.4941687871077183,
      "grad_norm": 156.59603881835938,
      "learning_rate": 3.372561492790501e-06,
      "loss": 0.2176,
      "step": 47050
    },
    {
      "epoch": 2.496819338422392,
      "grad_norm": 0.014459223486483097,
      "learning_rate": 3.354891150692678e-06,
      "loss": 0.2271,
      "step": 47100
    },
    {
      "epoch": 2.4994698897370653,
      "grad_norm": 0.009987058117985725,
      "learning_rate": 3.337220808594855e-06,
      "loss": 0.2331,
      "step": 47150
    },
    {
      "epoch": 2.502120441051739,
      "grad_norm": 40.77153778076172,
      "learning_rate": 3.3195504664970318e-06,
      "loss": 0.2963,
      "step": 47200
    },
    {
      "epoch": 2.5047709923664123,
      "grad_norm": 0.006909497547894716,
      "learning_rate": 3.3018801243992087e-06,
      "loss": 0.1479,
      "step": 47250
    },
    {
      "epoch": 2.507421543681086,
      "grad_norm": 0.08026730269193649,
      "learning_rate": 3.2842097823013857e-06,
      "loss": 0.1588,
      "step": 47300
    },
    {
      "epoch": 2.510072094995759,
      "grad_norm": 0.0045691318809986115,
      "learning_rate": 3.2665394402035627e-06,
      "loss": 0.2315,
      "step": 47350
    },
    {
      "epoch": 2.5127226463104324,
      "grad_norm": 0.014764505438506603,
      "learning_rate": 3.2488690981057396e-06,
      "loss": 0.5483,
      "step": 47400
    },
    {
      "epoch": 2.515373197625106,
      "grad_norm": 0.009500568732619286,
      "learning_rate": 3.2311987560079166e-06,
      "loss": 0.125,
      "step": 47450
    },
    {
      "epoch": 2.5180237489397794,
      "grad_norm": 0.04180070012807846,
      "learning_rate": 3.2135284139100936e-06,
      "loss": 0.2586,
      "step": 47500
    },
    {
      "epoch": 2.520674300254453,
      "grad_norm": 0.009041118435561657,
      "learning_rate": 3.1958580718122705e-06,
      "loss": 0.3262,
      "step": 47550
    },
    {
      "epoch": 2.5233248515691264,
      "grad_norm": 0.01068719383329153,
      "learning_rate": 3.1781877297144475e-06,
      "loss": 0.1068,
      "step": 47600
    },
    {
      "epoch": 2.5259754028838,
      "grad_norm": 0.02309485152363777,
      "learning_rate": 3.1605173876166245e-06,
      "loss": 0.2162,
      "step": 47650
    },
    {
      "epoch": 2.528625954198473,
      "grad_norm": 0.035896554589271545,
      "learning_rate": 3.1428470455188014e-06,
      "loss": 0.1188,
      "step": 47700
    },
    {
      "epoch": 2.531276505513147,
      "grad_norm": 0.01378297246992588,
      "learning_rate": 3.1251767034209784e-06,
      "loss": 0.4409,
      "step": 47750
    },
    {
      "epoch": 2.53392705682782,
      "grad_norm": 0.024355918169021606,
      "learning_rate": 3.1075063613231553e-06,
      "loss": 0.2236,
      "step": 47800
    },
    {
      "epoch": 2.5365776081424936,
      "grad_norm": 0.06777732819318771,
      "learning_rate": 3.0898360192253323e-06,
      "loss": 0.163,
      "step": 47850
    },
    {
      "epoch": 2.539228159457167,
      "grad_norm": 0.026598405092954636,
      "learning_rate": 3.0721656771275093e-06,
      "loss": 0.5143,
      "step": 47900
    },
    {
      "epoch": 2.5418787107718406,
      "grad_norm": 0.009312737733125687,
      "learning_rate": 3.0544953350296862e-06,
      "loss": 0.2208,
      "step": 47950
    },
    {
      "epoch": 2.544529262086514,
      "grad_norm": 0.06340575218200684,
      "learning_rate": 3.036824992931863e-06,
      "loss": 0.1155,
      "step": 48000
    },
    {
      "epoch": 2.5471798134011876,
      "grad_norm": 0.040221694856882095,
      "learning_rate": 3.01915465083404e-06,
      "loss": 0.1421,
      "step": 48050
    },
    {
      "epoch": 2.549830364715861,
      "grad_norm": 0.09584059566259384,
      "learning_rate": 3.001484308736217e-06,
      "loss": 0.4596,
      "step": 48100
    },
    {
      "epoch": 2.552480916030534,
      "grad_norm": 0.015180809423327446,
      "learning_rate": 2.983813966638394e-06,
      "loss": 0.2576,
      "step": 48150
    },
    {
      "epoch": 2.5551314673452077,
      "grad_norm": 0.07419339567422867,
      "learning_rate": 2.966143624540571e-06,
      "loss": 0.174,
      "step": 48200
    },
    {
      "epoch": 2.557782018659881,
      "grad_norm": 0.00591614656150341,
      "learning_rate": 2.948473282442748e-06,
      "loss": 0.0284,
      "step": 48250
    },
    {
      "epoch": 2.5604325699745547,
      "grad_norm": 0.05603177100419998,
      "learning_rate": 2.930802940344925e-06,
      "loss": 0.5698,
      "step": 48300
    },
    {
      "epoch": 2.563083121289228,
      "grad_norm": 0.10669079422950745,
      "learning_rate": 2.913132598247102e-06,
      "loss": 0.2558,
      "step": 48350
    },
    {
      "epoch": 2.5657336726039017,
      "grad_norm": 64.50703430175781,
      "learning_rate": 2.8954622561492798e-06,
      "loss": 0.2185,
      "step": 48400
    },
    {
      "epoch": 2.5683842239185752,
      "grad_norm": 0.017614861950278282,
      "learning_rate": 2.8777919140514567e-06,
      "loss": 0.0282,
      "step": 48450
    },
    {
      "epoch": 2.5710347752332483,
      "grad_norm": 0.0740945041179657,
      "learning_rate": 2.8601215719536337e-06,
      "loss": 0.2476,
      "step": 48500
    },
    {
      "epoch": 2.573685326547922,
      "grad_norm": 0.03542185202240944,
      "learning_rate": 2.8424512298558106e-06,
      "loss": 0.1656,
      "step": 48550
    },
    {
      "epoch": 2.5763358778625953,
      "grad_norm": 0.009066980332136154,
      "learning_rate": 2.8247808877579876e-06,
      "loss": 0.0892,
      "step": 48600
    },
    {
      "epoch": 2.578986429177269,
      "grad_norm": 0.07497242838144302,
      "learning_rate": 2.8071105456601646e-06,
      "loss": 0.2948,
      "step": 48650
    },
    {
      "epoch": 2.5816369804919423,
      "grad_norm": 0.0041803643107414246,
      "learning_rate": 2.7894402035623415e-06,
      "loss": 0.2442,
      "step": 48700
    },
    {
      "epoch": 2.584287531806616,
      "grad_norm": 0.02011338621377945,
      "learning_rate": 2.7717698614645185e-06,
      "loss": 0.1013,
      "step": 48750
    },
    {
      "epoch": 2.5869380831212894,
      "grad_norm": 0.050740133970975876,
      "learning_rate": 2.7540995193666955e-06,
      "loss": 0.2418,
      "step": 48800
    },
    {
      "epoch": 2.5895886344359624,
      "grad_norm": 0.20892931520938873,
      "learning_rate": 2.7364291772688724e-06,
      "loss": 0.3471,
      "step": 48850
    },
    {
      "epoch": 2.5922391857506364,
      "grad_norm": 0.038831792771816254,
      "learning_rate": 2.7187588351710494e-06,
      "loss": 0.1248,
      "step": 48900
    },
    {
      "epoch": 2.5948897370653095,
      "grad_norm": 0.004905086476355791,
      "learning_rate": 2.7010884930732264e-06,
      "loss": 0.191,
      "step": 48950
    },
    {
      "epoch": 2.597540288379983,
      "grad_norm": 1.078922152519226,
      "learning_rate": 2.6834181509754033e-06,
      "loss": 0.057,
      "step": 49000
    },
    {
      "epoch": 2.6001908396946565,
      "grad_norm": 0.020025312900543213,
      "learning_rate": 2.6657478088775803e-06,
      "loss": 0.482,
      "step": 49050
    },
    {
      "epoch": 2.60284139100933,
      "grad_norm": 24.97553825378418,
      "learning_rate": 2.6480774667797572e-06,
      "loss": 0.1552,
      "step": 49100
    },
    {
      "epoch": 2.6054919423240035,
      "grad_norm": 0.16508077085018158,
      "learning_rate": 2.6304071246819342e-06,
      "loss": 0.0853,
      "step": 49150
    },
    {
      "epoch": 2.608142493638677,
      "grad_norm": 0.013472712598741055,
      "learning_rate": 2.612736782584111e-06,
      "loss": 0.2434,
      "step": 49200
    },
    {
      "epoch": 2.6107930449533505,
      "grad_norm": 0.015330761671066284,
      "learning_rate": 2.595066440486288e-06,
      "loss": 0.5492,
      "step": 49250
    },
    {
      "epoch": 2.6134435962680236,
      "grad_norm": 0.005404579918831587,
      "learning_rate": 2.577396098388465e-06,
      "loss": 0.286,
      "step": 49300
    },
    {
      "epoch": 2.616094147582697,
      "grad_norm": 0.06485947966575623,
      "learning_rate": 2.559725756290642e-06,
      "loss": 0.1925,
      "step": 49350
    },
    {
      "epoch": 2.6187446988973706,
      "grad_norm": 0.014577696099877357,
      "learning_rate": 2.542055414192819e-06,
      "loss": 0.2312,
      "step": 49400
    },
    {
      "epoch": 2.621395250212044,
      "grad_norm": 0.21076613664627075,
      "learning_rate": 2.524385072094996e-06,
      "loss": 0.1591,
      "step": 49450
    },
    {
      "epoch": 2.6240458015267176,
      "grad_norm": 0.13250315189361572,
      "learning_rate": 2.506714729997173e-06,
      "loss": 0.163,
      "step": 49500
    },
    {
      "epoch": 2.626696352841391,
      "grad_norm": 0.02966940775513649,
      "learning_rate": 2.48904438789935e-06,
      "loss": 0.5107,
      "step": 49550
    },
    {
      "epoch": 2.6293469041560646,
      "grad_norm": 0.07351765781641006,
      "learning_rate": 2.471374045801527e-06,
      "loss": 0.1773,
      "step": 49600
    },
    {
      "epoch": 2.6319974554707377,
      "grad_norm": 0.05586524307727814,
      "learning_rate": 2.453703703703704e-06,
      "loss": 0.103,
      "step": 49650
    },
    {
      "epoch": 2.6346480067854112,
      "grad_norm": 0.006933751981705427,
      "learning_rate": 2.436033361605881e-06,
      "loss": 0.3181,
      "step": 49700
    },
    {
      "epoch": 2.6372985581000847,
      "grad_norm": 0.01946369931101799,
      "learning_rate": 2.4183630195080578e-06,
      "loss": 0.1915,
      "step": 49750
    },
    {
      "epoch": 2.6399491094147582,
      "grad_norm": 0.9627262949943542,
      "learning_rate": 2.4006926774102347e-06,
      "loss": 0.3567,
      "step": 49800
    },
    {
      "epoch": 2.6425996607294318,
      "grad_norm": 0.004750799387693405,
      "learning_rate": 2.3830223353124117e-06,
      "loss": 0.3042,
      "step": 49850
    },
    {
      "epoch": 2.6452502120441053,
      "grad_norm": 0.13410085439682007,
      "learning_rate": 2.3653519932145887e-06,
      "loss": 0.1643,
      "step": 49900
    },
    {
      "epoch": 2.6479007633587788,
      "grad_norm": 0.08744339644908905,
      "learning_rate": 2.3476816511167656e-06,
      "loss": 0.2572,
      "step": 49950
    },
    {
      "epoch": 2.650551314673452,
      "grad_norm": 0.006858881562948227,
      "learning_rate": 2.3300113090189426e-06,
      "loss": 0.2149,
      "step": 50000
    },
    {
      "epoch": 2.653201865988126,
      "grad_norm": 0.06479284912347794,
      "learning_rate": 2.3123409669211196e-06,
      "loss": 0.1377,
      "step": 50050
    },
    {
      "epoch": 2.655852417302799,
      "grad_norm": 0.9510939121246338,
      "learning_rate": 2.2946706248232965e-06,
      "loss": 0.1516,
      "step": 50100
    },
    {
      "epoch": 2.6585029686174724,
      "grad_norm": 0.5029467940330505,
      "learning_rate": 2.2770002827254735e-06,
      "loss": 0.1297,
      "step": 50150
    },
    {
      "epoch": 2.661153519932146,
      "grad_norm": 0.04946158081293106,
      "learning_rate": 2.2593299406276505e-06,
      "loss": 0.1769,
      "step": 50200
    },
    {
      "epoch": 2.6638040712468194,
      "grad_norm": 262.9523620605469,
      "learning_rate": 2.241659598529828e-06,
      "loss": 0.397,
      "step": 50250
    },
    {
      "epoch": 2.666454622561493,
      "grad_norm": 0.04957671836018562,
      "learning_rate": 2.223989256432005e-06,
      "loss": 0.1001,
      "step": 50300
    },
    {
      "epoch": 2.669105173876166,
      "grad_norm": 0.015519264154136181,
      "learning_rate": 2.2063189143341818e-06,
      "loss": 0.2207,
      "step": 50350
    },
    {
      "epoch": 2.67175572519084,
      "grad_norm": 0.02375371940433979,
      "learning_rate": 2.1886485722363587e-06,
      "loss": 0.2815,
      "step": 50400
    },
    {
      "epoch": 2.674406276505513,
      "grad_norm": 0.03748305141925812,
      "learning_rate": 2.1709782301385357e-06,
      "loss": 0.331,
      "step": 50450
    },
    {
      "epoch": 2.6770568278201865,
      "grad_norm": 0.012336062267422676,
      "learning_rate": 2.1533078880407127e-06,
      "loss": 0.2089,
      "step": 50500
    },
    {
      "epoch": 2.67970737913486,
      "grad_norm": 0.009110638871788979,
      "learning_rate": 2.1356375459428896e-06,
      "loss": 0.2157,
      "step": 50550
    },
    {
      "epoch": 2.6823579304495335,
      "grad_norm": 0.029629193246364594,
      "learning_rate": 2.1179672038450666e-06,
      "loss": 0.101,
      "step": 50600
    },
    {
      "epoch": 2.685008481764207,
      "grad_norm": 0.005403661634773016,
      "learning_rate": 2.1002968617472435e-06,
      "loss": 0.1915,
      "step": 50650
    },
    {
      "epoch": 2.6876590330788805,
      "grad_norm": 50.39435958862305,
      "learning_rate": 2.0826265196494205e-06,
      "loss": 0.442,
      "step": 50700
    },
    {
      "epoch": 2.690309584393554,
      "grad_norm": 0.009637676179409027,
      "learning_rate": 2.0649561775515975e-06,
      "loss": 0.304,
      "step": 50750
    },
    {
      "epoch": 2.692960135708227,
      "grad_norm": 0.11193748563528061,
      "learning_rate": 2.0472858354537744e-06,
      "loss": 0.2966,
      "step": 50800
    },
    {
      "epoch": 2.6956106870229006,
      "grad_norm": 0.01330887246876955,
      "learning_rate": 2.0296154933559514e-06,
      "loss": 0.0967,
      "step": 50850
    },
    {
      "epoch": 2.698261238337574,
      "grad_norm": 0.2346898764371872,
      "learning_rate": 2.0119451512581284e-06,
      "loss": 0.3548,
      "step": 50900
    },
    {
      "epoch": 2.7009117896522477,
      "grad_norm": 3.763275623321533,
      "learning_rate": 1.9942748091603058e-06,
      "loss": 0.3939,
      "step": 50950
    },
    {
      "epoch": 2.703562340966921,
      "grad_norm": 0.009109617210924625,
      "learning_rate": 1.9766044670624827e-06,
      "loss": 0.0969,
      "step": 51000
    },
    {
      "epoch": 2.7062128922815947,
      "grad_norm": 0.03502148017287254,
      "learning_rate": 1.9589341249646597e-06,
      "loss": 0.1254,
      "step": 51050
    },
    {
      "epoch": 2.708863443596268,
      "grad_norm": 0.021681727841496468,
      "learning_rate": 1.9412637828668366e-06,
      "loss": 0.2243,
      "step": 51100
    },
    {
      "epoch": 2.7115139949109412,
      "grad_norm": 0.03870411589741707,
      "learning_rate": 1.9235934407690136e-06,
      "loss": 0.2237,
      "step": 51150
    },
    {
      "epoch": 2.714164546225615,
      "grad_norm": 0.08258649706840515,
      "learning_rate": 1.9059230986711904e-06,
      "loss": 0.2851,
      "step": 51200
    },
    {
      "epoch": 2.7168150975402883,
      "grad_norm": 0.018047329038381577,
      "learning_rate": 1.8882527565733673e-06,
      "loss": 0.279,
      "step": 51250
    },
    {
      "epoch": 2.719465648854962,
      "grad_norm": 0.08855485916137695,
      "learning_rate": 1.8705824144755445e-06,
      "loss": 0.3055,
      "step": 51300
    },
    {
      "epoch": 2.7221162001696353,
      "grad_norm": 0.10871858894824982,
      "learning_rate": 1.8529120723777215e-06,
      "loss": 0.1612,
      "step": 51350
    },
    {
      "epoch": 2.724766751484309,
      "grad_norm": 0.006872645113617182,
      "learning_rate": 1.8352417302798984e-06,
      "loss": 0.493,
      "step": 51400
    },
    {
      "epoch": 2.7274173027989823,
      "grad_norm": 32.63124084472656,
      "learning_rate": 1.8175713881820754e-06,
      "loss": 0.284,
      "step": 51450
    },
    {
      "epoch": 2.7300678541136554,
      "grad_norm": 0.043781839311122894,
      "learning_rate": 1.7999010460842524e-06,
      "loss": 0.2538,
      "step": 51500
    },
    {
      "epoch": 2.7327184054283293,
      "grad_norm": 0.015194633044302464,
      "learning_rate": 1.7822307039864293e-06,
      "loss": 0.311,
      "step": 51550
    },
    {
      "epoch": 2.7353689567430024,
      "grad_norm": 0.23554185032844543,
      "learning_rate": 1.7645603618886063e-06,
      "loss": 0.1675,
      "step": 51600
    },
    {
      "epoch": 2.738019508057676,
      "grad_norm": 0.21235868334770203,
      "learning_rate": 1.7468900197907835e-06,
      "loss": 0.2605,
      "step": 51650
    },
    {
      "epoch": 2.7406700593723494,
      "grad_norm": 0.03275177255272865,
      "learning_rate": 1.7292196776929604e-06,
      "loss": 0.325,
      "step": 51700
    },
    {
      "epoch": 2.743320610687023,
      "grad_norm": 0.028667835518717766,
      "learning_rate": 1.7115493355951374e-06,
      "loss": 0.2317,
      "step": 51750
    },
    {
      "epoch": 2.7459711620016964,
      "grad_norm": 0.02048511616885662,
      "learning_rate": 1.6938789934973143e-06,
      "loss": 0.344,
      "step": 51800
    },
    {
      "epoch": 2.74862171331637,
      "grad_norm": 0.0771854892373085,
      "learning_rate": 1.6762086513994913e-06,
      "loss": 0.259,
      "step": 51850
    },
    {
      "epoch": 2.7512722646310435,
      "grad_norm": 51.76516342163086,
      "learning_rate": 1.6585383093016683e-06,
      "loss": 0.2481,
      "step": 51900
    },
    {
      "epoch": 2.7539228159457165,
      "grad_norm": 26.951345443725586,
      "learning_rate": 1.6408679672038452e-06,
      "loss": 0.2367,
      "step": 51950
    },
    {
      "epoch": 2.75657336726039,
      "grad_norm": 0.08944348245859146,
      "learning_rate": 1.6231976251060222e-06,
      "loss": 0.2577,
      "step": 52000
    },
    {
      "epoch": 2.7592239185750635,
      "grad_norm": 0.06325562298297882,
      "learning_rate": 1.6055272830081992e-06,
      "loss": 0.0018,
      "step": 52050
    },
    {
      "epoch": 2.761874469889737,
      "grad_norm": 0.16882827877998352,
      "learning_rate": 1.5878569409103761e-06,
      "loss": 0.2926,
      "step": 52100
    },
    {
      "epoch": 2.7645250212044106,
      "grad_norm": 0.05400090664625168,
      "learning_rate": 1.570186598812553e-06,
      "loss": 0.3732,
      "step": 52150
    },
    {
      "epoch": 2.767175572519084,
      "grad_norm": 0.0581783652305603,
      "learning_rate": 1.55251625671473e-06,
      "loss": 0.065,
      "step": 52200
    },
    {
      "epoch": 2.7698261238337576,
      "grad_norm": 0.04785124585032463,
      "learning_rate": 1.534845914616907e-06,
      "loss": 0.4997,
      "step": 52250
    },
    {
      "epoch": 2.7724766751484307,
      "grad_norm": 0.062265269458293915,
      "learning_rate": 1.517175572519084e-06,
      "loss": 0.2048,
      "step": 52300
    },
    {
      "epoch": 2.775127226463104,
      "grad_norm": 0.147780641913414,
      "learning_rate": 1.499505230421261e-06,
      "loss": 0.1466,
      "step": 52350
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.2188960611820221,
      "learning_rate": 1.4818348883234381e-06,
      "loss": 0.2718,
      "step": 52400
    },
    {
      "epoch": 2.780428329092451,
      "grad_norm": 0.01500143762677908,
      "learning_rate": 1.464164546225615e-06,
      "loss": 0.176,
      "step": 52450
    },
    {
      "epoch": 2.7830788804071247,
      "grad_norm": 0.02180403657257557,
      "learning_rate": 1.446494204127792e-06,
      "loss": 0.4514,
      "step": 52500
    },
    {
      "epoch": 2.785729431721798,
      "grad_norm": 0.0064352890476584435,
      "learning_rate": 1.428823862029969e-06,
      "loss": 0.1591,
      "step": 52550
    },
    {
      "epoch": 2.7883799830364717,
      "grad_norm": 0.01532136369496584,
      "learning_rate": 1.411153519932146e-06,
      "loss": 0.4518,
      "step": 52600
    },
    {
      "epoch": 2.791030534351145,
      "grad_norm": 0.011985830962657928,
      "learning_rate": 1.393483177834323e-06,
      "loss": 0.3032,
      "step": 52650
    },
    {
      "epoch": 2.7936810856658187,
      "grad_norm": 50.825008392333984,
      "learning_rate": 1.3758128357365e-06,
      "loss": 0.3334,
      "step": 52700
    },
    {
      "epoch": 2.796331636980492,
      "grad_norm": 0.1081944927573204,
      "learning_rate": 1.3581424936386769e-06,
      "loss": 0.1136,
      "step": 52750
    },
    {
      "epoch": 2.7989821882951653,
      "grad_norm": 0.019842475652694702,
      "learning_rate": 1.3404721515408538e-06,
      "loss": 0.1118,
      "step": 52800
    },
    {
      "epoch": 2.801632739609839,
      "grad_norm": 49.35643768310547,
      "learning_rate": 1.3228018094430308e-06,
      "loss": 0.3638,
      "step": 52850
    },
    {
      "epoch": 2.8042832909245123,
      "grad_norm": 0.03872879967093468,
      "learning_rate": 1.3051314673452078e-06,
      "loss": 0.1692,
      "step": 52900
    },
    {
      "epoch": 2.806933842239186,
      "grad_norm": 97.9501724243164,
      "learning_rate": 1.2874611252473847e-06,
      "loss": 0.3251,
      "step": 52950
    },
    {
      "epoch": 2.8095843935538594,
      "grad_norm": 0.6049317121505737,
      "learning_rate": 1.2697907831495617e-06,
      "loss": 0.1702,
      "step": 53000
    },
    {
      "epoch": 2.812234944868533,
      "grad_norm": 0.025629425421357155,
      "learning_rate": 1.2521204410517387e-06,
      "loss": 0.498,
      "step": 53050
    },
    {
      "epoch": 2.814885496183206,
      "grad_norm": 0.04781040549278259,
      "learning_rate": 1.2344500989539158e-06,
      "loss": 0.1926,
      "step": 53100
    },
    {
      "epoch": 2.8175360474978794,
      "grad_norm": 0.019333722069859505,
      "learning_rate": 1.2167797568560928e-06,
      "loss": 0.1888,
      "step": 53150
    },
    {
      "epoch": 2.820186598812553,
      "grad_norm": 0.2696612775325775,
      "learning_rate": 1.1991094147582698e-06,
      "loss": 0.1366,
      "step": 53200
    },
    {
      "epoch": 2.8228371501272265,
      "grad_norm": 182.69126892089844,
      "learning_rate": 1.1814390726604467e-06,
      "loss": 0.1483,
      "step": 53250
    },
    {
      "epoch": 2.8254877014419,
      "grad_norm": 64.90017700195312,
      "learning_rate": 1.163768730562624e-06,
      "loss": 0.3043,
      "step": 53300
    },
    {
      "epoch": 2.8281382527565735,
      "grad_norm": 0.9608699679374695,
      "learning_rate": 1.1460983884648009e-06,
      "loss": 0.385,
      "step": 53350
    },
    {
      "epoch": 2.830788804071247,
      "grad_norm": 0.007957246154546738,
      "learning_rate": 1.1284280463669778e-06,
      "loss": 0.0261,
      "step": 53400
    },
    {
      "epoch": 2.83343935538592,
      "grad_norm": 0.2563164532184601,
      "learning_rate": 1.1107577042691548e-06,
      "loss": 0.1407,
      "step": 53450
    },
    {
      "epoch": 2.8360899067005936,
      "grad_norm": 0.023604752495884895,
      "learning_rate": 1.0930873621713318e-06,
      "loss": 0.4075,
      "step": 53500
    },
    {
      "epoch": 2.838740458015267,
      "grad_norm": 0.11308515071868896,
      "learning_rate": 1.0754170200735087e-06,
      "loss": 0.0227,
      "step": 53550
    },
    {
      "epoch": 2.8413910093299406,
      "grad_norm": 0.01924251765012741,
      "learning_rate": 1.0577466779756857e-06,
      "loss": 0.4658,
      "step": 53600
    },
    {
      "epoch": 2.844041560644614,
      "grad_norm": 0.06127028167247772,
      "learning_rate": 1.0400763358778626e-06,
      "loss": 0.3607,
      "step": 53650
    },
    {
      "epoch": 2.8466921119592876,
      "grad_norm": 1.0229753255844116,
      "learning_rate": 1.0224059937800396e-06,
      "loss": 0.2429,
      "step": 53700
    },
    {
      "epoch": 2.849342663273961,
      "grad_norm": 0.06281954795122147,
      "learning_rate": 1.0047356516822168e-06,
      "loss": 0.465,
      "step": 53750
    },
    {
      "epoch": 2.851993214588634,
      "grad_norm": 0.10031890869140625,
      "learning_rate": 9.870653095843937e-07,
      "loss": 0.1931,
      "step": 53800
    },
    {
      "epoch": 2.854643765903308,
      "grad_norm": 0.17651036381721497,
      "learning_rate": 9.693949674865707e-07,
      "loss": 0.4781,
      "step": 53850
    },
    {
      "epoch": 2.857294317217981,
      "grad_norm": 0.021420108154416084,
      "learning_rate": 9.517246253887476e-07,
      "loss": 0.131,
      "step": 53900
    },
    {
      "epoch": 2.8599448685326547,
      "grad_norm": 0.1601933240890503,
      "learning_rate": 9.340542832909245e-07,
      "loss": 0.2331,
      "step": 53950
    },
    {
      "epoch": 2.8625954198473282,
      "grad_norm": 0.1284058690071106,
      "learning_rate": 9.163839411931015e-07,
      "loss": 0.259,
      "step": 54000
    },
    {
      "epoch": 2.8652459711620017,
      "grad_norm": 0.5682544708251953,
      "learning_rate": 8.987135990952786e-07,
      "loss": 0.4473,
      "step": 54050
    },
    {
      "epoch": 2.8678965224766753,
      "grad_norm": 0.19626355171203613,
      "learning_rate": 8.810432569974555e-07,
      "loss": 0.3177,
      "step": 54100
    },
    {
      "epoch": 2.8705470737913483,
      "grad_norm": 0.007014076691120863,
      "learning_rate": 8.633729148996325e-07,
      "loss": 0.0905,
      "step": 54150
    },
    {
      "epoch": 2.8731976251060223,
      "grad_norm": 0.07108209282159805,
      "learning_rate": 8.457025728018095e-07,
      "loss": 0.034,
      "step": 54200
    },
    {
      "epoch": 2.8758481764206953,
      "grad_norm": 0.04190313443541527,
      "learning_rate": 8.280322307039864e-07,
      "loss": 0.0109,
      "step": 54250
    },
    {
      "epoch": 2.878498727735369,
      "grad_norm": 0.021650001406669617,
      "learning_rate": 8.103618886061635e-07,
      "loss": 0.2838,
      "step": 54300
    },
    {
      "epoch": 2.8811492790500424,
      "grad_norm": 35.25545120239258,
      "learning_rate": 7.926915465083405e-07,
      "loss": 0.3021,
      "step": 54350
    },
    {
      "epoch": 2.883799830364716,
      "grad_norm": 0.2427210956811905,
      "learning_rate": 7.750212044105175e-07,
      "loss": 0.0885,
      "step": 54400
    },
    {
      "epoch": 2.8864503816793894,
      "grad_norm": 0.05088252201676369,
      "learning_rate": 7.573508623126945e-07,
      "loss": 0.3025,
      "step": 54450
    },
    {
      "epoch": 2.889100932994063,
      "grad_norm": 0.0347592793405056,
      "learning_rate": 7.396805202148715e-07,
      "loss": 0.1904,
      "step": 54500
    },
    {
      "epoch": 2.8917514843087364,
      "grad_norm": 0.005135198123753071,
      "learning_rate": 7.220101781170484e-07,
      "loss": 0.5574,
      "step": 54550
    },
    {
      "epoch": 2.8944020356234095,
      "grad_norm": 0.1205877885222435,
      "learning_rate": 7.043398360192254e-07,
      "loss": 0.1821,
      "step": 54600
    },
    {
      "epoch": 2.897052586938083,
      "grad_norm": 0.045958928763866425,
      "learning_rate": 6.866694939214023e-07,
      "loss": 0.2081,
      "step": 54650
    },
    {
      "epoch": 2.8997031382527565,
      "grad_norm": 0.013201822526752949,
      "learning_rate": 6.689991518235793e-07,
      "loss": 0.0239,
      "step": 54700
    },
    {
      "epoch": 2.90235368956743,
      "grad_norm": 0.02664763107895851,
      "learning_rate": 6.513288097257564e-07,
      "loss": 0.2803,
      "step": 54750
    },
    {
      "epoch": 2.9050042408821035,
      "grad_norm": 0.013175291009247303,
      "learning_rate": 6.336584676279333e-07,
      "loss": 0.1012,
      "step": 54800
    },
    {
      "epoch": 2.907654792196777,
      "grad_norm": 48.16825485229492,
      "learning_rate": 6.159881255301103e-07,
      "loss": 0.2854,
      "step": 54850
    },
    {
      "epoch": 2.9103053435114505,
      "grad_norm": 0.020117534324526787,
      "learning_rate": 5.983177834322873e-07,
      "loss": 0.3821,
      "step": 54900
    },
    {
      "epoch": 2.9129558948261236,
      "grad_norm": 0.04208745062351227,
      "learning_rate": 5.806474413344642e-07,
      "loss": 0.2454,
      "step": 54950
    },
    {
      "epoch": 2.9156064461407976,
      "grad_norm": 0.1271325796842575,
      "learning_rate": 5.629770992366412e-07,
      "loss": 0.2637,
      "step": 55000
    },
    {
      "epoch": 2.9182569974554706,
      "grad_norm": 0.039756979793310165,
      "learning_rate": 5.453067571388183e-07,
      "loss": 0.1984,
      "step": 55050
    },
    {
      "epoch": 2.920907548770144,
      "grad_norm": 0.030366024002432823,
      "learning_rate": 5.276364150409952e-07,
      "loss": 0.1284,
      "step": 55100
    },
    {
      "epoch": 2.9235581000848176,
      "grad_norm": 0.006215744186192751,
      "learning_rate": 5.099660729431722e-07,
      "loss": 0.3744,
      "step": 55150
    },
    {
      "epoch": 2.926208651399491,
      "grad_norm": 0.03464251756668091,
      "learning_rate": 4.922957308453493e-07,
      "loss": 0.4434,
      "step": 55200
    },
    {
      "epoch": 2.9288592027141647,
      "grad_norm": 0.010831748135387897,
      "learning_rate": 4.746253887475262e-07,
      "loss": 0.3629,
      "step": 55250
    },
    {
      "epoch": 2.9315097540288377,
      "grad_norm": 0.12591183185577393,
      "learning_rate": 4.569550466497032e-07,
      "loss": 0.2987,
      "step": 55300
    },
    {
      "epoch": 2.9341603053435117,
      "grad_norm": 0.11982528120279312,
      "learning_rate": 4.3928470455188015e-07,
      "loss": 0.2934,
      "step": 55350
    },
    {
      "epoch": 2.9368108566581848,
      "grad_norm": 0.16707631945610046,
      "learning_rate": 4.2161436245405717e-07,
      "loss": 0.2789,
      "step": 55400
    },
    {
      "epoch": 2.9394614079728583,
      "grad_norm": 0.3071018159389496,
      "learning_rate": 4.0394402035623413e-07,
      "loss": 0.1095,
      "step": 55450
    },
    {
      "epoch": 2.9421119592875318,
      "grad_norm": 0.10665421932935715,
      "learning_rate": 3.862736782584111e-07,
      "loss": 0.0306,
      "step": 55500
    },
    {
      "epoch": 2.9447625106022053,
      "grad_norm": 46.21521759033203,
      "learning_rate": 3.686033361605881e-07,
      "loss": 0.3386,
      "step": 55550
    },
    {
      "epoch": 2.947413061916879,
      "grad_norm": 23.596006393432617,
      "learning_rate": 3.509329940627651e-07,
      "loss": 0.218,
      "step": 55600
    },
    {
      "epoch": 2.9500636132315523,
      "grad_norm": 0.0882434993982315,
      "learning_rate": 3.3326265196494204e-07,
      "loss": 0.5095,
      "step": 55650
    },
    {
      "epoch": 2.952714164546226,
      "grad_norm": 0.29154589772224426,
      "learning_rate": 3.15592309867119e-07,
      "loss": 0.1002,
      "step": 55700
    },
    {
      "epoch": 2.955364715860899,
      "grad_norm": 0.5508960485458374,
      "learning_rate": 2.97921967769296e-07,
      "loss": 0.1852,
      "step": 55750
    },
    {
      "epoch": 2.9580152671755724,
      "grad_norm": 0.035696644335985184,
      "learning_rate": 2.8025162567147304e-07,
      "loss": 0.1038,
      "step": 55800
    },
    {
      "epoch": 2.960665818490246,
      "grad_norm": 0.013949032872915268,
      "learning_rate": 2.6258128357365e-07,
      "loss": 0.3847,
      "step": 55850
    },
    {
      "epoch": 2.9633163698049194,
      "grad_norm": 6.583769798278809,
      "learning_rate": 2.44910941475827e-07,
      "loss": 0.133,
      "step": 55900
    },
    {
      "epoch": 2.965966921119593,
      "grad_norm": 32.31511688232422,
      "learning_rate": 2.2724059937800396e-07,
      "loss": 0.0869,
      "step": 55950
    },
    {
      "epoch": 2.9686174724342664,
      "grad_norm": 0.01598994806408882,
      "learning_rate": 2.0957025728018097e-07,
      "loss": 0.2983,
      "step": 56000
    },
    {
      "epoch": 2.97126802374894,
      "grad_norm": 0.059933338314294815,
      "learning_rate": 1.9189991518235796e-07,
      "loss": 0.2726,
      "step": 56050
    },
    {
      "epoch": 2.973918575063613,
      "grad_norm": 0.01302984356880188,
      "learning_rate": 1.7422957308453493e-07,
      "loss": 0.2414,
      "step": 56100
    },
    {
      "epoch": 2.9765691263782865,
      "grad_norm": 0.17928718030452728,
      "learning_rate": 1.5655923098671192e-07,
      "loss": 0.045,
      "step": 56150
    },
    {
      "epoch": 2.97921967769296,
      "grad_norm": 0.07702534645795822,
      "learning_rate": 1.3888888888888888e-07,
      "loss": 0.0593,
      "step": 56200
    },
    {
      "epoch": 2.9818702290076335,
      "grad_norm": 0.012038804590702057,
      "learning_rate": 1.212185467910659e-07,
      "loss": 0.2206,
      "step": 56250
    },
    {
      "epoch": 2.984520780322307,
      "grad_norm": 0.01750953681766987,
      "learning_rate": 1.0354820469324287e-07,
      "loss": 0.4153,
      "step": 56300
    },
    {
      "epoch": 2.9871713316369806,
      "grad_norm": 0.02866327203810215,
      "learning_rate": 8.587786259541986e-08,
      "loss": 0.2589,
      "step": 56350
    },
    {
      "epoch": 2.989821882951654,
      "grad_norm": 0.16988694667816162,
      "learning_rate": 6.820752049759684e-08,
      "loss": 0.2701,
      "step": 56400
    },
    {
      "epoch": 2.992472434266327,
      "grad_norm": 0.014944195747375488,
      "learning_rate": 5.0537178399773824e-08,
      "loss": 0.0893,
      "step": 56450
    },
    {
      "epoch": 2.995122985581001,
      "grad_norm": 99.50379180908203,
      "learning_rate": 3.286683630195081e-08,
      "loss": 0.5114,
      "step": 56500
    },
    {
      "epoch": 2.997773536895674,
      "grad_norm": 0.01087021641433239,
      "learning_rate": 1.519649420412779e-08,
      "loss": 0.3459,
      "step": 56550
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9916185058549427,
      "eval_f1": 0.8733424782807498,
      "eval_loss": 0.16318584978580475,
      "eval_precision": 0.9253875968992248,
      "eval_recall": 0.8268398268398268,
      "eval_runtime": 835.668,
      "eval_samples_per_second": 39.548,
      "eval_steps_per_second": 4.945,
      "step": 56592
    }
  ],
  "logging_steps": 50,
  "max_steps": 56592,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1282423231567712e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
